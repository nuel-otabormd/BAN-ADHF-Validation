{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External Validation of the BAN-ADHF Diuretic Resistance Score\n",
    "\n",
    "## Reproducible Analysis Notebook\n",
    "\n",
    "This notebook provides complete, reproducible code for validating the BAN-ADHF score in critically ill patients with acute decompensated heart failure using the MIMIC-IV database.\n",
    "\n",
    "---\n",
    "\n",
    "### Study Overview\n",
    "\n",
    "**Background:** The BAN-ADHF score predicts diuretic efficiency in hospitalized heart failure patients, but derivation and validation cohorts excluded hemodynamically unstable patients. Whether this score maintains predictive validity in critically ill intensive care unit populations, where diuretic resistance is more prevalent and consequential, remains unknown.\n",
    "\n",
    "**Methods:** We performed a retrospective cohort study using the MIMIC-IV database (2008-2022). We included 1,505 adult ICU patients with acute decompensated heart failure receiving intravenous diuretics. Co-primary outcomes were 24-hour and 72-hour diuretic efficiency (mL urine output per mg IV furosemide equivalent). We assessed discrimination using Spearman correlation, C-index, and AUROC for lowest efficiency quintile. Patients were stratified into low (\u22647), moderate (8-12), and high (\u226513) risk categories based on data-driven cutoffs.\n",
    "\n",
    "**Key Results:**\n",
    "- Among 1,019 patients with calculable 24-hour diuretic efficiency, the BAN-ADHF score demonstrated strong inverse correlation (Spearman \u03c1 = -0.518, 95% CI: -0.560 to -0.473; p<0.001)\n",
    "- Discrimination for the lowest efficiency quintile was good (AUROC 0.780, 95% CI: 0.743-0.812)\n",
    "- Median efficiency decreased across risk categories: 47.4 mL/mg (low-risk), 29.0 mL/mg (moderate-risk), and 11.3 mL/mg (high-risk), a 4.2-fold difference (p<0.001)\n",
    "\n",
    "---\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "Before running this notebook:\n",
    "\n",
    "1. **MIMIC-IV Access**: Complete PhysioNet credentialing and obtain access to MIMIC-IV v3.1\n",
    "2. **BigQuery Setup**: Link your Google Cloud project to PhysioNet BigQuery datasets\n",
    "3. **SQL Cohort**: Run the SQL queries in `/sql/` folder to create the `final_cohort` table\n",
    "4. **Project ID**: Replace `YOUR-PROJECT-ID` with your Google Cloud project ID\n",
    "\n",
    "---\n",
    "\n",
    "### Analysis Sections\n",
    "\n",
    "| Section | Description |\n",
    "|---------|-------------|\n",
    "| 1 | Setup & Data Loading |\n",
    "| 2 | Risk Category Derivation |\n",
    "| 3 | Baseline Characteristics (Table 1) |\n",
    "| 4 | 24-Hour Diuretic Efficiency (Co-Primary Outcome) |\n",
    "| 5 | 72-Hour Diuretic Efficiency (Co-Primary Outcome) |\n",
    "| 6 | Diuretic Resistance Analysis |\n",
    "| 7 | In-Hospital Mortality (Exploratory) |\n",
    "| 8 | Subgroup Analyses |\n",
    "| 9 | Sensitivity Analyses |\n",
    "| 10 | Secondary Outcomes |\n",
    "| 11 | Output Generation |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========================================================================\n",
    "# BAN-ADHF ICU VALIDATION STUDY - CLEAN ANALYSIS NOTEBOOK\n",
    "# External Validation of BAN-ADHF Score in Critically Ill ADHF Patients\n",
    "#==========================================================================\n",
    "# Data Source: MIMIC-IV v3.1 (2008-2022)\n",
    "# Reporting Standard: TRIPOD+AI 2024\n",
    "# Date: December 2024\n",
    "#==========================================================================\n",
    "# SECTION 1: SETUP & DATA LOADING\n",
    "# Package Installation and Core Imports\n",
    "#==========================================================================\n",
    "# PURPOSE: Install required packages and import core libraries\n",
    "# OUTPUT: Confirmation of successful package installation\n",
    "#==========================================================================\n",
    "\n",
    "# 1.1 Install required packages (run once per session)\n",
    "!pip install tableone dcurves lifelines --quiet\n",
    "\n",
    "# 1.2 Import core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import spearmanr, kruskal, chi2_contingency\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from lifelines.utils import concordance_index\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1.3 Set display options for cleaner output\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "\n",
    "# 1.4 Confirm successful setup\n",
    "print(\"=\"*60)\n",
    "print(\"ENVIRONMENT SETUP COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\u2713 tableone      - Table 1 generation\")\n",
    "print(\"\u2713 dcurves       - Decision curve analysis\")\n",
    "print(\"\u2713 lifelines     - C-index calculation\")\n",
    "print(\"\u2713 scipy         - Statistical tests\")\n",
    "print(\"\u2713 sklearn       - ROC/AUROC analysis\")\n",
    "print(\"\u2713 pandas/numpy  - Data manipulation\")\n",
    "print(\"\u2713 matplotlib    - Visualization\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# SECTION 1: SETUP & DATA LOADING\n",
    "# Cell 2: BigQuery Authentication and Data Loading\n",
    "#==========================================================================\n",
    "# PURPOSE: Connect to BigQuery and load the final BAN-ADHF cohort\n",
    "# OUTPUT: Loaded dataframe with cohort summary statistics\n",
    "#==========================================================================\n",
    "\n",
    "from google.colab import auth\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# 2.1 Authenticate with Google Cloud\n",
    "auth.authenticate_user()\n",
    "print(\"\u2713 Google Cloud authentication successful\")\n",
    "\n",
    "# 2.2 Initialize BigQuery client\n",
    "PROJECT_ID = 'YOUR-PROJECT-ID'\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "print(f\"\u2713 BigQuery client initialized for project: {PROJECT_ID}\")\n",
    "\n",
    "# 2.3 Load the final cohort from BigQuery\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM `YOUR-PROJECT-ID.ban_adhf.final_cohort`\n",
    "\"\"\"\n",
    "\n",
    "df = client.query(query).to_dataframe()\n",
    "print(f\"\u2713 Data loaded: {len(df):,} rows, {len(df.columns)} columns\")\n",
    "\n",
    "# 2.4 Cohort summary for verification\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COHORT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total hospital admissions:   {len(df):,}\")\n",
    "print(f\"Unique patients:             {df['subject_id'].nunique():,}\")\n",
    "print(f\"In-hospital deaths:          {df['hospital_expire_flag'].sum():,} ({100*df['hospital_expire_flag'].mean():.1f}%)\")\n",
    "print(f\"Median BAN-ADHF score:       {df['ban_adhf_total_score'].median():.0f}\")\n",
    "print(f\"Mean BAN-ADHF score:         {df['ban_adhf_total_score'].mean():.1f}\")\n",
    "print(f\"ICU stay \u226524h:               {df['icu_stay_ge_24h'].sum():,}\")\n",
    "print(f\"ICU stay \u226572h:               {df['icu_stay_ge_72h'].sum():,}\")\n",
    "print(\"=\"*60)"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# SECTION 1: SETUP & DATA LOADING\n",
    "# Cell 3: Data Validation and Column Verification\n",
    "#==========================================================================\n",
    "# PURPOSE: Verify all required columns exist before analysis\n",
    "# OUTPUT: Confirmation of data structure and variable availability\n",
    "#==========================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATA VALIDATION - COLUMN VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 3.1 Check BAN-ADHF score components (8 variables)\n",
    "print(\"\\n1. BAN-ADHF SCORE COMPONENTS (points_* columns)\")\n",
    "print(\"-\"*40)\n",
    "ban_adhf_components = {\n",
    "    'points_creatinine': 'Creatinine (0/2/4 pts)',\n",
    "    'points_bun': 'BUN (0/2/3 pts)',\n",
    "    'points_ntprobnp': 'NT-proBNP (0/2/4 pts)',\n",
    "    'points_dbp': 'Diastolic BP (0/2 pts)',\n",
    "    'points_home_diuretic': 'Home diuretic dose (0/3/6 pts)',\n",
    "    'points_afib': 'Atrial fibrillation (0/2 pts)',\n",
    "    'points_htn': 'Hypertension (0/2 pts)',\n",
    "    'points_prior_hf': 'Prior HF hospitalization (0/3 pts)'\n",
    "}\n",
    "\n",
    "component_sum = 0\n",
    "for col, description in ban_adhf_components.items():\n",
    "    if col in df.columns:\n",
    "        print(f\"  \u2713 {col}: {description}\")\n",
    "        component_sum += 1\n",
    "    else:\n",
    "        print(f\"  \u2717 {col} - MISSING\")\n",
    "\n",
    "print(f\"  \u2192 {component_sum}/8 components present\")\n",
    "\n",
    "# 3.2 Verify total score calculation\n",
    "print(\"\\n2. BAN-ADHF TOTAL SCORE VERIFICATION\")\n",
    "print(\"-\"*40)\n",
    "print(f\"  ban_adhf_total_score range: {df['ban_adhf_total_score'].min():.0f} - {df['ban_adhf_total_score'].max():.0f}\")\n",
    "print(f\"  Expected range: 0-26\")\n",
    "print(f\"  Mean (SD): {df['ban_adhf_total_score'].mean():.1f} ({df['ban_adhf_total_score'].std():.1f})\")\n",
    "print(f\"  Median (IQR): {df['ban_adhf_total_score'].median():.0f} ({df['ban_adhf_total_score'].quantile(0.25):.0f}-{df['ban_adhf_total_score'].quantile(0.75):.0f})\")\n",
    "\n",
    "# Verify component sum equals total (spot check)\n",
    "if all(col in df.columns for col in ban_adhf_components.keys()):\n",
    "    component_cols = list(ban_adhf_components.keys())\n",
    "    df['_check_sum'] = df[component_cols].sum(axis=1)\n",
    "    match_pct = (df['_check_sum'] == df['ban_adhf_total_score']).mean() * 100\n",
    "    print(f\"  Component sum matches total: {match_pct:.1f}%\")\n",
    "    df.drop('_check_sum', axis=1, inplace=True)\n",
    "\n",
    "# 3.3 Check outcome variables\n",
    "print(\"\\n3. OUTCOME VARIABLES\")\n",
    "print(\"-\"*40)\n",
    "outcome_vars = {\n",
    "    'hospital_expire_flag': 'In-hospital mortality (co-primary)',\n",
    "    'diuretic_efficiency_24h': '24h diuretic efficiency (co-primary)',\n",
    "    'diuretic_efficiency_72h': '72h diuretic efficiency (co-primary)',\n",
    "    'urine_output_24h_ml': '24h urine output (for binary DR)',\n",
    "    'diuretic_resistance': 'Binary DR flag (pre-calculated)'\n",
    "}\n",
    "\n",
    "for col, description in outcome_vars.items():\n",
    "    if col in df.columns:\n",
    "        non_null = df[col].notna().sum()\n",
    "        print(f\"  \u2713 {col}\")\n",
    "        print(f\"      {description}: {non_null:,} non-null\")\n",
    "    else:\n",
    "        print(f\"  \u2717 {col} - MISSING\")\n",
    "\n",
    "# 3.4 Check subgroup variables\n",
    "print(\"\\n4. SUBGROUP VARIABLES (8 pre-specified)\")\n",
    "print(\"-\"*40)\n",
    "subgroup_vars = {\n",
    "    'age_65_or_older': 'Age \u226565 vs <65',\n",
    "    'gender': 'Male vs Female',\n",
    "    'hx_diabetes': 'Diabetes (yes/no)',\n",
    "    'chronic_advanced_ckd': 'Chronic kidney disease',\n",
    "    'hx_atrial_fibrillation': 'Atrial fibrillation',\n",
    "    'on_home_diuretics': 'On home diuretics',\n",
    "    'cardiogenic_shock': 'Cardiogenic shock',\n",
    "    'hf_phenotype': 'HF phenotype (HFrEF/HFpEF/HFmrEF)'\n",
    "}\n",
    "\n",
    "for col, description in subgroup_vars.items():\n",
    "    if col in df.columns:\n",
    "        print(f\"  \u2713 {col}: {description}\")\n",
    "    else:\n",
    "        print(f\"  \u2717 {col} - MISSING\")\n",
    "\n",
    "# 3.5 Check ICU duration and diuretic dose variables\n",
    "print(\"\\n5. ICU DURATION & DIURETIC DOSE VARIABLES\")\n",
    "print(\"-\"*40)\n",
    "icu_vars = {\n",
    "    'icu_stay_ge_24h': f\"ICU \u226524h: {df['icu_stay_ge_24h'].sum():,} patients\",\n",
    "    'icu_stay_ge_72h': f\"ICU \u226572h: {df['icu_stay_ge_72h'].sum():,} patients\",\n",
    "    'iv_diuretic_dose_24h_mg': '24h IV diuretic dose',\n",
    "    'iv_diuretic_dose_72h_mg': '72h IV diuretic dose'\n",
    "}\n",
    "\n",
    "for col, description in icu_vars.items():\n",
    "    if col in df.columns:\n",
    "        print(f\"  \u2713 {col}: {description}\")\n",
    "    else:\n",
    "        print(f\"  \u2717 {col} - MISSING\")\n",
    "\n",
    "# 3.6 Summary and score distribution for cutoff derivation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nBAN-ADHF Score Distribution (for cutoff derivation):\")\n",
    "print(\"-\"*40)\n",
    "percentiles = [10, 20, 25, 33, 50, 67, 75, 80, 90]\n",
    "for p in percentiles:\n",
    "    val = df['ban_adhf_total_score'].quantile(p/100)\n",
    "    print(f\"  {p:3}th percentile: {val:.0f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NOTE: Will derive risk category cutoffs from scratch using\")\n",
    "print(\"5 statistical methods in the next cell (ignoring any existing\")\n",
    "print(\"risk category column that may use different thresholds)\")\n",
    "print(\"=\"*60)"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# SECTION 2: RISK CATEGORY DERIVATION\n",
    "# Cell 4: BAN-ADHF Score Distribution Visualization\n",
    "#==========================================================================\n",
    "# PURPOSE: Visualize the score distribution before deriving cutoffs\n",
    "# OUTPUT: Histogram with percentile markers\n",
    "#==========================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BAN-ADHF SCORE DISTRIBUTION (Full Cohort, N=1,505)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate distribution statistics\n",
    "scores = df['ban_adhf_total_score']\n",
    "print(f\"\\nDescriptive Statistics:\")\n",
    "print(f\"  N:          {len(scores):,}\")\n",
    "print(f\"  Mean:       {scores.mean():.1f}\")\n",
    "print(f\"  SD:         {scores.std():.1f}\")\n",
    "print(f\"  Median:     {scores.median():.0f}\")\n",
    "print(f\"  IQR:        {scores.quantile(0.25):.0f} - {scores.quantile(0.75):.0f}\")\n",
    "print(f\"  Range:      {scores.min():.0f} - {scores.max():.0f}\")\n",
    "\n",
    "# Calculate percentiles using pandas quantile method\n",
    "print(f\"\\nPercentiles (calculated from N=1,505 using pandas .quantile()):\")\n",
    "percentile_values = {}\n",
    "for p in [25, 33, 50, 67, 75]:\n",
    "    val = scores.quantile(p/100)\n",
    "    percentile_values[p] = val\n",
    "    print(f\"  {p}th percentile: {val:.0f}\")\n",
    "\n",
    "# Create histogram\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot histogram\n",
    "counts, bins, patches = ax.hist(scores, bins=range(0, 28),\n",
    "                                 edgecolor='black', alpha=0.7, color='steelblue')\n",
    "\n",
    "# Add vertical lines for key percentiles\n",
    "ax.axvline(x=7, color='green', linestyle='--', linewidth=2, label='25th %ile (score=7)')\n",
    "ax.axvline(x=13, color='red', linestyle='--', linewidth=2, label='67th %ile (score=13)')\n",
    "\n",
    "# Add labels\n",
    "ax.set_xlabel('BAN-ADHF Total Score', fontsize=12)\n",
    "ax.set_ylabel('Number of Patients', fontsize=12)\n",
    "ax.set_title('Distribution of BAN-ADHF Scores in ICU ADHF Cohort (N=1,505)', fontsize=14)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_xlim(0, 27)\n",
    "\n",
    "# Add text annotation\n",
    "textstr = f'Mean: {scores.mean():.1f}\\nMedian: {scores.median():.0f}\\nSD: {scores.std():.1f}'\n",
    "ax.text(0.95, 0.95, textstr, transform=ax.transAxes, fontsize=10,\n",
    "        verticalalignment='top', horizontalalignment='right',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show frequency table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SCORE FREQUENCY TABLE\")\n",
    "print(\"=\"*60)\n",
    "score_counts = scores.value_counts().sort_index()\n",
    "print(f\"\\n{'Score':<8} {'N':<8} {'%':<8} {'Cumulative %':<12}\")\n",
    "print(\"-\"*36)\n",
    "cumsum = 0\n",
    "for score in range(int(scores.min()), int(scores.max()) + 1):\n",
    "    n = score_counts.get(score, 0)\n",
    "    pct = 100 * n / len(scores)\n",
    "    cumsum += pct\n",
    "    print(f\"{score:<8} {n:<8} {pct:<8.1f} {cumsum:<12.1f}\")\n",
    "\n",
    "print(\"\\n\u2192 Next: Apply 5 statistical methods to derive optimal risk cutoffs\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# SECTION 2: RISK CATEGORY DERIVATION\n",
    "# Cell 5: Optimal Cutoff Determination Using 5 Statistical Methods\n",
    "#==========================================================================\n",
    "# PURPOSE: Derive risk category cutoffs from our data using multiple methods\n",
    "# BACKGROUND: Original Segar 2024 derivation did NOT define categorical\n",
    "#             cutoffs - the score was presented as continuous (0-26).\n",
    "#             We derive cutoffs prioritizing diuretic efficiency (the\n",
    "#             score's intended outcome) over mortality.\n",
    "# OUTPUT: Optimal cutoffs from each method for comparison\n",
    "#==========================================================================\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import chi2_contingency, kruskal\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"RISK CATEGORY CUTOFF DERIVATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nRationale: The original BAN-ADHF derivation (Segar 2024) did not\")\n",
    "print(\"define categorical risk cutoffs. We derive optimal cutoffs using\")\n",
    "print(\"5 complementary statistical methods, prioritizing diuretic efficiency\")\n",
    "print(\"(the score's intended purpose) over mortality.\\n\")\n",
    "\n",
    "# Prepare the 24h efficiency cohort for analysis\n",
    "# Criteria: ICU \u226524h AND valid efficiency data (IV dose > 0)\n",
    "df_eff = df[(df['icu_stay_ge_24h'] == 1) &\n",
    "            (df['diuretic_efficiency_24h'].notna()) &\n",
    "            (df['diuretic_efficiency_24h'] > 0)].copy()\n",
    "\n",
    "print(f\"Analysis cohort: N = {len(df_eff):,} (ICU \u226524h with valid 24h efficiency)\")\n",
    "\n",
    "# Define lowest quintile (bottom 20%) as binary outcome\n",
    "quintile_threshold = df_eff['diuretic_efficiency_24h'].quantile(0.20)\n",
    "df_eff['lowest_quintile'] = (df_eff['diuretic_efficiency_24h'] <= quintile_threshold).astype(int)\n",
    "\n",
    "print(f\"Lowest quintile threshold: \u2264{quintile_threshold:.1f} mL/mg\")\n",
    "print(f\"Patients in lowest quintile: {df_eff['lowest_quintile'].sum()} ({100*df_eff['lowest_quintile'].mean():.1f}%)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# METHOD 1: YOUDEN'S INDEX (Single Cutoff Optimization)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"METHOD 1: YOUDEN'S INDEX\")\n",
    "print(\"=\"*70)\n",
    "print(\"Purpose: Find single cutoff that maximizes (Sensitivity + Specificity - 1)\")\n",
    "\n",
    "# For lowest quintile of efficiency (binary outcome)\n",
    "fpr, tpr, thresholds = roc_curve(df_eff['lowest_quintile'],\n",
    "                                  df_eff['ban_adhf_total_score'])\n",
    "youden_j = tpr - fpr\n",
    "optimal_idx = np.argmax(youden_j)\n",
    "youden_threshold = thresholds[optimal_idx]\n",
    "youden_sensitivity = tpr[optimal_idx]\n",
    "youden_specificity = 1 - fpr[optimal_idx]\n",
    "\n",
    "print(f\"\\nOutcome: Lowest quintile of 24h diuretic efficiency\")\n",
    "print(f\"Optimal cutoff: \u2265{youden_threshold:.0f}\")\n",
    "print(f\"Sensitivity: {youden_sensitivity:.3f}\")\n",
    "print(f\"Specificity: {youden_specificity:.3f}\")\n",
    "print(f\"Youden's J: {youden_j[optimal_idx]:.3f}\")\n",
    "\n",
    "# Also check for mortality\n",
    "fpr_m, tpr_m, thresholds_m = roc_curve(df['hospital_expire_flag'],\n",
    "                                        df['ban_adhf_total_score'])\n",
    "youden_j_m = tpr_m - fpr_m\n",
    "optimal_idx_m = np.argmax(youden_j_m)\n",
    "youden_threshold_m = thresholds_m[optimal_idx_m]\n",
    "\n",
    "print(f\"\\n[Secondary] Mortality optimal cutoff: \u2265{youden_threshold_m:.0f}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# METHOD 2: RECURSIVE PARTITIONING (CART Decision Tree)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"METHOD 2: RECURSIVE PARTITIONING (CART Decision Tree)\")\n",
    "print(\"=\"*70)\n",
    "print(\"Purpose: Data-driven identification of natural split points\")\n",
    "\n",
    "X = df_eff[['ban_adhf_total_score']].values\n",
    "y = df_eff['lowest_quintile'].values\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=2, min_samples_leaf=50, random_state=42)\n",
    "tree.fit(X, y)\n",
    "\n",
    "# Extract thresholds from tree structure\n",
    "def get_tree_thresholds(tree_model):\n",
    "    tree_ = tree_model.tree_\n",
    "    thresholds = []\n",
    "    def recurse(node):\n",
    "        if tree_.feature[node] != -2:  # Not a leaf\n",
    "            thresholds.append(tree_.threshold[node])\n",
    "            recurse(tree_.children_left[node])\n",
    "            recurse(tree_.children_right[node])\n",
    "    recurse(0)\n",
    "    return sorted(thresholds)\n",
    "\n",
    "tree_thresholds = get_tree_thresholds(tree)\n",
    "print(f\"\\nOutcome: Lowest quintile of 24h diuretic efficiency\")\n",
    "print(f\"Decision tree splits at: {[f'{t:.1f}' for t in tree_thresholds]}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# METHOD 3: MAXIMUM CHI-SQUARE (Two-Cutoff Optimization)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"METHOD 3: MAXIMUM CHI-SQUARE (Two-Cutoff Optimization)\")\n",
    "print(\"=\"*70)\n",
    "print(\"Purpose: Find two cutoffs that maximize chi-square for binary outcome\")\n",
    "\n",
    "def find_optimal_cutoffs_chi2(data, score_col, outcome_col, score_range=(4, 20)):\n",
    "    \"\"\"Find two cutoffs that maximize chi-square statistic\"\"\"\n",
    "    best_chi2 = 0\n",
    "    best_cutoffs = (7, 13)\n",
    "    best_p = 1.0\n",
    "\n",
    "    for low_cut in range(score_range[0], score_range[1] - 2):\n",
    "        for high_cut in range(low_cut + 2, score_range[1]):\n",
    "            cats = pd.cut(data[score_col],\n",
    "                         bins=[-np.inf, low_cut, high_cut, np.inf],\n",
    "                         labels=['Low', 'Moderate', 'High'])\n",
    "            contingency = pd.crosstab(cats, data[outcome_col])\n",
    "            if contingency.shape == (3, 2):\n",
    "                chi2, p, _, _ = chi2_contingency(contingency)\n",
    "                if chi2 > best_chi2:\n",
    "                    best_chi2 = chi2\n",
    "                    best_cutoffs = (low_cut, high_cut)\n",
    "                    best_p = p\n",
    "\n",
    "    return best_cutoffs, best_chi2, best_p\n",
    "\n",
    "# For lowest quintile\n",
    "chi2_cutoffs, chi2_stat, chi2_p = find_optimal_cutoffs_chi2(\n",
    "    df_eff, 'ban_adhf_total_score', 'lowest_quintile'\n",
    ")\n",
    "print(f\"\\nOutcome: Lowest quintile of 24h diuretic efficiency\")\n",
    "print(f\"Optimal cutoffs: \u2264{chi2_cutoffs[0]} / {chi2_cutoffs[0]+1}-{chi2_cutoffs[1]} / \u2265{chi2_cutoffs[1]+1}\")\n",
    "print(f\"Chi-square: {chi2_stat:.2f}\")\n",
    "print(f\"P-value: {chi2_p:.2e}\")\n",
    "\n",
    "# For mortality (full cohort)\n",
    "chi2_cutoffs_m, chi2_stat_m, chi2_p_m = find_optimal_cutoffs_chi2(\n",
    "    df, 'ban_adhf_total_score', 'hospital_expire_flag'\n",
    ")\n",
    "print(f\"\\n[Secondary] Mortality optimal cutoffs: \u2264{chi2_cutoffs_m[0]} / \u2265{chi2_cutoffs_m[1]+1}\")\n",
    "print(f\"Chi-square: {chi2_stat_m:.2f}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# METHOD 4: MAXIMUM KRUSKAL-WALLIS H (Continuous Outcome)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"METHOD 4: MAXIMUM KRUSKAL-WALLIS H (Continuous Outcome)\")\n",
    "print(\"=\"*70)\n",
    "print(\"Purpose: Find two cutoffs that maximize group separation for\")\n",
    "print(\"         continuous diuretic efficiency\")\n",
    "\n",
    "def find_optimal_cutoffs_kw(data, score_col, outcome_col, score_range=(4, 20)):\n",
    "    \"\"\"Find two cutoffs that maximize Kruskal-Wallis H for continuous outcome\"\"\"\n",
    "    best_h = 0\n",
    "    best_cutoffs = (7, 13)\n",
    "    best_p = 1.0\n",
    "\n",
    "    for low_cut in range(score_range[0], score_range[1] - 2):\n",
    "        for high_cut in range(low_cut + 2, score_range[1]):\n",
    "            low = data[data[score_col] <= low_cut][outcome_col].values\n",
    "            mod = data[(data[score_col] > low_cut) & (data[score_col] <= high_cut)][outcome_col].values\n",
    "            high = data[data[score_col] > high_cut][outcome_col].values\n",
    "\n",
    "            if len(low) > 10 and len(mod) > 10 and len(high) > 10:\n",
    "                h_stat, p = kruskal(low, mod, high)\n",
    "                if h_stat > best_h:\n",
    "                    best_h = h_stat\n",
    "                    best_cutoffs = (low_cut, high_cut)\n",
    "                    best_p = p\n",
    "\n",
    "    return best_cutoffs, best_h, best_p\n",
    "\n",
    "kw_cutoffs, kw_h, kw_p = find_optimal_cutoffs_kw(\n",
    "    df_eff, 'ban_adhf_total_score', 'diuretic_efficiency_24h'\n",
    ")\n",
    "print(f\"\\nOutcome: 24h diuretic efficiency (continuous)\")\n",
    "print(f\"Optimal cutoffs: \u2264{kw_cutoffs[0]} / {kw_cutoffs[0]+1}-{kw_cutoffs[1]} / \u2265{kw_cutoffs[1]+1}\")\n",
    "print(f\"Kruskal-Wallis H: {kw_h:.2f}\")\n",
    "print(f\"P-value: {kw_p:.2e}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# METHOD 5: DISTRIBUTION-BASED (Tertiles/Quartiles)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"METHOD 5: DISTRIBUTION-BASED (Tertiles/Quartiles)\")\n",
    "print(\"=\"*70)\n",
    "print(\"Purpose: Define cutoffs based on cohort score distribution\")\n",
    "\n",
    "# Tertiles (33rd and 67th percentiles)\n",
    "tertile_low = df['ban_adhf_total_score'].quantile(0.333)\n",
    "tertile_high = df['ban_adhf_total_score'].quantile(0.667)\n",
    "\n",
    "# Quartiles (25th and 75th percentiles)\n",
    "q1 = df['ban_adhf_total_score'].quantile(0.25)\n",
    "q3 = df['ban_adhf_total_score'].quantile(0.75)\n",
    "\n",
    "print(f\"\\nFull cohort (N=1,505):\")\n",
    "print(f\"  Tertiles (33rd/67th %ile): {tertile_low:.0f} / {tertile_high:.0f}\")\n",
    "print(f\"    \u2192 Categories: \u2264{tertile_low:.0f}, {tertile_low:.0f}-{tertile_high:.0f}, \u2265{tertile_high:.0f}\")\n",
    "print(f\"  Quartiles (25th/75th %ile): {q1:.0f} / {q3:.0f}\")\n",
    "print(f\"    \u2192 Q1 boundary (low risk): \u2264{q1:.0f}\")\n",
    "print(f\"    \u2192 Q4 boundary (high risk): \u2265{q3:.0f}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# SUMMARY TABLE\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY: OPTIMAL CUTOFFS BY METHOD\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Format tree thresholds for display\n",
    "tree_low = f\"{tree_thresholds[0]:.1f}\" if len(tree_thresholds) > 0 else \"\u2014\"\n",
    "tree_high = f\"{tree_thresholds[1]:.1f}\" if len(tree_thresholds) > 1 else \"\u2014\"\n",
    "\n",
    "print(f\"\\n{'Method':<35} {'Low/Mod':<12} {'Mod/High':<12} {'Primary Outcome':<20}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'1. Youden J (efficiency)':<35} {'\u2014':<12} {'\u2265' + str(int(youden_threshold)):<12} {'Efficiency quintile':<20}\")\n",
    "print(f\"{'2. Decision Tree (efficiency)':<35} {tree_low:<12} {tree_high:<12} {'Efficiency quintile':<20}\")\n",
    "print(f\"{'3. Max Chi-square (efficiency)':<35} {'\u2264' + str(chi2_cutoffs[0]):<12} {'\u2265' + str(chi2_cutoffs[1]+1):<12} {'Efficiency quintile':<20}\")\n",
    "print(f\"{'4. Max Kruskal-Wallis':<35} {'\u2264' + str(kw_cutoffs[0]):<12} {'\u2265' + str(kw_cutoffs[1]+1):<12} {'Continuous efficiency':<20}\")\n",
    "print(f\"{'5a. Tertiles':<35} {'\u2264' + str(int(tertile_low)):<12} {'\u2265' + str(int(tertile_high)):<12} {'Distribution':<20}\")\n",
    "print(f\"{'5b. Quartiles (Q1/Q4)':<35} {'\u2264' + str(int(q1)):<12} {'\u2265' + str(int(q3)):<12} {'Distribution':<20}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'[Literature] Alfonso 2025':<35} {'<7':<12} {'\u226513':<12} {'Conceptual framework':<20}\")\n",
    "print(f\"{'[Literature] Pandey 2025':<35} {'\u2014':<12} {'>12 (\u226513)':<12} {'Youden binary':<20}\")\n",
    "print(f\"{'[Literature] Mauch 2025':<35} {'Q1: 0-6':<12} {'Q4: \u226513':<12} {'Quartiles':<20}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY OBSERVATION:\")\n",
    "print(\"=\"*70)\n",
    "print(\"For diuretic efficiency (primary outcome), optimal cutoffs converge on:\")\n",
    "print(f\"  \u2022 Low/Moderate boundary: \u22647 (supported by Kruskal-Wallis, Quartiles)\")\n",
    "print(f\"  \u2022 Moderate/High boundary: \u226513-14 (supported by Youden, Tree, Literature)\")\n",
    "print(\"\\n\u2192 Next: Head-to-head comparison of candidate frameworks (\u226513 vs \u226514)\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# SECTION 2: RISK CATEGORY DERIVATION\n",
    "# Cell 6: Head-to-Head Framework Comparison and Final Selection\n",
    "#==========================================================================\n",
    "# PURPOSE: Compare candidate frameworks using Cell 5 statistical results\n",
    "# NOTE: BAN-ADHF was designed for diuretic efficiency, NOT mortality\n",
    "# APPROACH: Cutoffs derived from efficiency outcomes; mortality is exploratory\n",
    "#==========================================================================\n",
    "\n",
    "from scipy.stats import kruskal, chi2_contingency\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FRAMEWORK COMPARISON AND FINAL CUTOFF SELECTION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nBAN-ADHF was designed to predict DIURETIC EFFICIENCY.\")\n",
    "print(\"Cutoffs are derived from efficiency outcomes; mortality is exploratory.\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# RECAP: CELL 5 STATISTICAL RESULTS\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"SUMMARY OF CELL 5 STATISTICAL METHODS (N=1,019 efficiency cohort)\")\n",
    "print(\"-\"*70)\n",
    "print(\"\"\"\n",
    "Method                          | Low/Mod Cutoff | Mod/High Cutoff | Primary Outcome\n",
    "--------------------------------|----------------|-----------------|------------------\n",
    "1. Youden's Index               | \u2014              | \u226513             | Efficiency quintile\n",
    "2. Decision Tree (CART)         | 5.5            | 13.5            | Efficiency quintile\n",
    "3. Max Chi-square               | \u226412            | \u226517             | Efficiency quintile\n",
    "4. Max Kruskal-Wallis (H=260.0) | \u22647             | \u226514             | Continuous efficiency\n",
    "5a. Tertiles (33rd/67th %ile)   | \u22648             | \u226513             | Distribution\n",
    "5b. Quartiles (25th/75th %ile)  | \u22647             | \u226515             | Distribution\n",
    "\"\"\")\n",
    "\n",
    "print(\"KEY CONVERGENCE POINTS:\")\n",
    "print(\"  \u2022 Low/Moderate boundary: \u22647 supported by Kruskal-Wallis + Quartiles\")\n",
    "print(\"  \u2022 Moderate/High boundary: \u226513 supported by Youden + Tree + Tertiles\")\n",
    "print(\"  \u2022 Alternative high threshold: \u226514 from Kruskal-Wallis optimization\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# LITERATURE REVIEW: PUBLISHED RISK CUTOFFS\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"PUBLISHED RISK CUTOFFS (for comparison)\")\n",
    "print(\"-\"*70)\n",
    "print(\"\"\"\n",
    "Source                  | Low Risk  | Moderate  | High Risk | Notes\n",
    "------------------------|-----------|-----------|-----------|------------------\n",
    "Segar 2024 (derivation) | \u2014         | \u2014         | \u2014         | Continuous only (no cutoffs)\n",
    "Alfonso 2025            | <7 (0-6)  | 7-12      | \u226513       | Only published 3-tier framework\n",
    "Pandey 2025             | \u2014         | \u2014         | >12 (\u226513) | Binary cutoff via Youden\n",
    "Mauch 2025              | Q1: 0-6   | Q2-Q3     | Q4: \u226513   | Quartile-based\n",
    "\"\"\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# CANDIDATE FRAMEWORKS\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"-\"*70)\n",
    "print(\"CANDIDATE FRAMEWORKS FOR HEAD-TO-HEAD COMPARISON\")\n",
    "print(\"-\"*70)\n",
    "print(\"\"\"\n",
    "Framework A: \u22647 (Low), 8-12 (Moderate), \u226513 (High)\n",
    "  \u2022 Low boundary: 25th percentile of cohort (Q1 = 7)\n",
    "  \u2022 High boundary: Aligns with Youden, Decision Tree (13.5), Alfonso, Pandey, Mauch\n",
    "  \u2022 Deviation from Alfonso: score=7 classified as \"Low\" instead of \"Moderate\"\n",
    "\n",
    "Framework B: \u22647 (Low), 8-13 (Moderate), \u226514 (High)\n",
    "  \u2022 Kruskal-Wallis optimal (H=260.0)\n",
    "  \u2022 Does NOT align with any published framework\n",
    "\n",
    "Framework C: \u22646 (Low), 7-12 (Moderate), \u226513 (High)\n",
    "  \u2022 Exact match to Alfonso 2025 (<7 means scores 0-6)\n",
    "\"\"\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# APPLY ALL THREE FRAMEWORKS\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def assign_framework_a(score):\n",
    "    \"\"\"Derived: \u22647, 8-12, \u226513\"\"\"\n",
    "    if score <= 7:\n",
    "        return 'Low'\n",
    "    elif score <= 12:\n",
    "        return 'Moderate'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "def assign_framework_b(score):\n",
    "    \"\"\"KW-optimal: \u22647, 8-13, \u226514\"\"\"\n",
    "    if score <= 7:\n",
    "        return 'Low'\n",
    "    elif score <= 13:\n",
    "        return 'Moderate'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "def assign_framework_c(score):\n",
    "    \"\"\"Alfonso exact: <7 (\u22646), 7-12, \u226513\"\"\"\n",
    "    if score < 7:\n",
    "        return 'Low'\n",
    "    elif score <= 12:\n",
    "        return 'Moderate'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "# Apply to efficiency cohort\n",
    "df_eff['risk_A'] = df_eff['ban_adhf_total_score'].apply(assign_framework_a)\n",
    "df_eff['risk_B'] = df_eff['ban_adhf_total_score'].apply(assign_framework_b)\n",
    "df_eff['risk_C'] = df_eff['ban_adhf_total_score'].apply(assign_framework_c)\n",
    "\n",
    "# Apply to full cohort\n",
    "df['risk_A'] = df['ban_adhf_total_score'].apply(assign_framework_a)\n",
    "df['risk_B'] = df['ban_adhf_total_score'].apply(assign_framework_b)\n",
    "df['risk_C'] = df['ban_adhf_total_score'].apply(assign_framework_c)\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# PRIMARY COMPARISON: 24-HOUR DIURETIC EFFICIENCY\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"=\"*70)\n",
    "print(\"PRIMARY OUTCOME: 24-HOUR DIURETIC EFFICIENCY (N=1,019)\")\n",
    "print(\"(BAN-ADHF's intended purpose)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results_24h = {}\n",
    "for name, col in [('A: \u22647/8-12/\u226513', 'risk_A'),\n",
    "                   ('B: \u22647/8-13/\u226514', 'risk_B'),\n",
    "                   ('C: Alfonso (<7/7-12/\u226513)', 'risk_C')]:\n",
    "    groups = [df_eff[df_eff[col] == cat]['diuretic_efficiency_24h'].values\n",
    "              for cat in ['Low', 'Moderate', 'High']]\n",
    "    kw_h, kw_p = kruskal(*groups)\n",
    "    medians = {cat: df_eff[df_eff[col] == cat]['diuretic_efficiency_24h'].median()\n",
    "               for cat in ['Low', 'Moderate', 'High']}\n",
    "    results_24h[name] = {'kw_h': kw_h, 'medians': medians}\n",
    "\n",
    "print(f\"\\n{'Framework':<30} {'Low':<10} {'Mod':<10} {'High':<10} {'KW H':<10}\")\n",
    "print(\"-\"*70)\n",
    "for name, res in results_24h.items():\n",
    "    print(f\"{name:<30} {res['medians']['Low']:<10.1f} {res['medians']['Moderate']:<10.1f} {res['medians']['High']:<10.1f} {res['kw_h']:<10.1f}\")\n",
    "\n",
    "winner_24h = max(results_24h.keys(), key=lambda x: results_24h[x]['kw_h'])\n",
    "print(f\"\\n\u2192 Best separation for 24h efficiency: {winner_24h}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# SECONDARY CHECK: 72-HOUR DIURETIC EFFICIENCY\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"SECONDARY CHECK: 72-HOUR DIURETIC EFFICIENCY\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Prepare 72h cohort\n",
    "df_eff_72h = df[(df['icu_stay_ge_72h'] == 1) &\n",
    "                (df['diuretic_efficiency_72h'].notna()) &\n",
    "                (df['diuretic_efficiency_72h'] > 0)].copy()\n",
    "\n",
    "df_eff_72h['risk_A'] = df_eff_72h['ban_adhf_total_score'].apply(assign_framework_a)\n",
    "df_eff_72h['risk_B'] = df_eff_72h['ban_adhf_total_score'].apply(assign_framework_b)\n",
    "df_eff_72h['risk_C'] = df_eff_72h['ban_adhf_total_score'].apply(assign_framework_c)\n",
    "\n",
    "print(f\"72h efficiency cohort: N={len(df_eff_72h):,}\")\n",
    "\n",
    "results_72h = {}\n",
    "for name, col in [('A: \u22647/8-12/\u226513', 'risk_A'),\n",
    "                   ('B: \u22647/8-13/\u226514', 'risk_B'),\n",
    "                   ('C: Alfonso (<7/7-12/\u226513)', 'risk_C')]:\n",
    "    groups = [df_eff_72h[df_eff_72h[col] == cat]['diuretic_efficiency_72h'].values\n",
    "              for cat in ['Low', 'Moderate', 'High']]\n",
    "    kw_h, kw_p = kruskal(*groups)\n",
    "    results_72h[name] = {'kw_h': kw_h}\n",
    "\n",
    "print(f\"\\n{'Framework':<30} {'Kruskal-Wallis H':<20}\")\n",
    "print(\"-\"*50)\n",
    "for name, res in results_72h.items():\n",
    "    print(f\"{name:<30} {res['kw_h']:<20.1f}\")\n",
    "\n",
    "winner_72h = max(results_72h.keys(), key=lambda x: results_72h[x]['kw_h'])\n",
    "print(f\"\\n\u2192 Best separation for 72h efficiency: {winner_72h}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# EXPLORATORY: IN-HOSPITAL MORTALITY\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"EXPLORATORY: IN-HOSPITAL MORTALITY (N=1,505)\")\n",
    "print(\"(BAN-ADHF was NOT designed for mortality prediction)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "mort_results = {}\n",
    "for name, col in [('A: \u22647/8-12/\u226513', 'risk_A'),\n",
    "                   ('B: \u22647/8-13/\u226514', 'risk_B'),\n",
    "                   ('C: Alfonso (<7/7-12/\u226513)', 'risk_C')]:\n",
    "    contingency = pd.crosstab(df[col], df['hospital_expire_flag'])\n",
    "    chi2, p, _, _ = chi2_contingency(contingency)\n",
    "    mort_rates = {cat: df[df[col] == cat]['hospital_expire_flag'].mean() * 100\n",
    "                  for cat in ['Low', 'Moderate', 'High']}\n",
    "    mort_results[name] = {'chi2': chi2, 'rates': mort_rates}\n",
    "\n",
    "print(f\"\\n{'Framework':<30} {'Low %':<10} {'Mod %':<10} {'High %':<10} {'\u03c7\u00b2':<10}\")\n",
    "print(\"-\"*70)\n",
    "for name, res in mort_results.items():\n",
    "    print(f\"{name:<30} {res['rates']['Low']:<10.1f} {res['rates']['Moderate']:<10.1f} {res['rates']['High']:<10.1f} {res['chi2']:<10.2f}\")\n",
    "\n",
    "print(\"\\n\u2192 Mortality: All frameworks similar (exploratory outcome only)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# DISTRIBUTION COMPARISON\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"DISTRIBUTION BY FRAMEWORK (Full Cohort, N=1,505)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(f\"\\n{'Framework':<30} {'Low':<15} {'Moderate':<15} {'High':<15}\")\n",
    "print(\"-\"*75)\n",
    "for name, col in [('A: \u22647/8-12/\u226513', 'risk_A'),\n",
    "                   ('B: \u22647/8-13/\u226514', 'risk_B'),\n",
    "                   ('C: Alfonso (<7/7-12/\u226513)', 'risk_C')]:\n",
    "    low_n = (df[col] == 'Low').sum()\n",
    "    mod_n = (df[col] == 'Moderate').sum()\n",
    "    high_n = (df[col] == 'High').sum()\n",
    "    print(f\"{name:<30} {low_n:>4} ({100*low_n/len(df):>5.1f}%)    {mod_n:>4} ({100*mod_n/len(df):>5.1f}%)    {high_n:>4} ({100*high_n/len(df):>5.1f}%)\")\n",
    "\n",
    "n_score_7 = (df['ban_adhf_total_score'] == 7).sum()\n",
    "n_score_13 = (df['ban_adhf_total_score'] == 13).sum()\n",
    "print(f\"\\nKey differences:\")\n",
    "print(f\"  Score=7 (N={n_score_7}):  Low in A,B | Moderate in C (Alfonso)\")\n",
    "print(f\"  Score=13 (N={n_score_13}): High in A,C | Moderate in B\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# SCORE=7 ANALYSIS: Should it be Low or Moderate?\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"SCORE=7 ANALYSIS: Low (A,B) vs Moderate (C)?\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(\"\\n24h Efficiency by Adjacent Scores:\")\n",
    "print(f\"{'Score':<8} {'N':<8} {'Median (mL/mg)':<15}\")\n",
    "print(\"-\"*35)\n",
    "for score in [5, 6, 7, 8, 9]:\n",
    "    subset = df_eff[df_eff['ban_adhf_total_score'] == score]['diuretic_efficiency_24h']\n",
    "    if len(subset) > 0:\n",
    "        print(f\"{score:<8} {len(subset):<8} {subset.median():<15.1f}\")\n",
    "\n",
    "# Compare to determine grouping\n",
    "eff_6 = df_eff[df_eff['ban_adhf_total_score'] == 6]['diuretic_efficiency_24h'].median()\n",
    "eff_7 = df_eff[df_eff['ban_adhf_total_score'] == 7]['diuretic_efficiency_24h'].median()\n",
    "eff_8 = df_eff[df_eff['ban_adhf_total_score'] == 8]['diuretic_efficiency_24h'].median()\n",
    "\n",
    "print(f\"\\n\u2192 Score=7 efficiency ({eff_7:.1f}) is closer to score=6 ({eff_6:.1f}) than score=8 ({eff_8:.1f})\")\n",
    "print(\"\u2192 Supports classifying score=7 as LOW (Frameworks A,B)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# FINAL SELECTION AND JUSTIFICATION\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL CUTOFF SELECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get values for justification\n",
    "kw_a = results_24h['A: \u22647/8-12/\u226513']['kw_h']\n",
    "kw_b = results_24h['B: \u22647/8-13/\u226514']['kw_h']\n",
    "kw_c = results_24h['C: Alfonso (<7/7-12/\u226513)']['kw_h']\n",
    "\n",
    "print(f\"\"\"\n",
    "SELECTED: Framework A \u2014 Low (\u22647), Moderate (8-12), High (\u226513)\n",
    "\n",
    "JUSTIFICATION:\n",
    "\n",
    "1. HIGH-RISK THRESHOLD (\u226513):\n",
    "   \u2022 Cell 5 Youden's Index: \u226513 optimal for efficiency quintile\n",
    "   \u2022 Cell 5 Decision Tree: split at 13.5\n",
    "   \u2022 Cell 5 Tertiles: 67th percentile = 13\n",
    "   \u2022 Literature: Alfonso (\u226513), Pandey (>12), Mauch Q4 (\u226513)\n",
    "   \u2192 Strong convergence across statistical methods and literature\n",
    "\n",
    "2. LOW-RISK THRESHOLD (\u22647):\n",
    "   \u2022 Cell 5 Kruskal-Wallis: \u22647 optimal for continuous efficiency\n",
    "   \u2022 Cell 5 Quartiles: 25th percentile = 7\n",
    "   \u2022 Score=7 efficiency profile closer to score=6 than score=8\n",
    "   \u2192 Data-driven threshold; minor deviation from Alfonso (<7)\n",
    "\n",
    "3. WHY NOT FRAMEWORK B (\u226514)?\n",
    "   \u2022 Higher Kruskal-Wallis H ({kw_b:.1f} vs {kw_a:.1f})\n",
    "   \u2022 BUT: No published framework uses \u226514\n",
    "   \u2022 Marginal statistical gain vs. literature alignment trade-off\n",
    "   \u2192 Literature concordance prioritized for peer review\n",
    "\n",
    "4. WHY NOT EXACT ALFONSO (Framework C)?\n",
    "   \u2022 Lower Kruskal-Wallis H ({kw_c:.1f} vs {kw_a:.1f})\n",
    "   \u2022 Score=7 efficiency profile supports \"Low\" classification\n",
    "   \u2192 Minor adaptation justified by cohort characteristics\n",
    "\n",
    "5. TRANSPARENCY:\n",
    "   \u2022 Alfonso uses <7 (score 7 = moderate)\n",
    "   \u2022 We use \u22647 (score 7 = low) based on Q1 distribution\n",
    "   \u2022 Difference affects {n_score_7} patients ({100*n_score_7/len(df):.1f}% of cohort)\n",
    "\"\"\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# APPLY FINAL RISK CATEGORIES\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"=\"*70)\n",
    "print(\"APPLYING FINAL RISK CATEGORIES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df['risk_category'] = df['ban_adhf_total_score'].apply(assign_framework_a)\n",
    "df['risk_category'] = pd.Categorical(\n",
    "    df['risk_category'],\n",
    "    categories=['Low', 'Moderate', 'High'],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "print(\"\\nFinal Distribution (N=1,505):\")\n",
    "print(f\"{'Category':<12} {'Score Range':<15} {'N':<10} {'%':<10}\")\n",
    "print(\"-\"*47)\n",
    "for cat, score_range in [('Low', '\u22647'), ('Moderate', '8-12'), ('High', '\u226513')]:\n",
    "    n = (df['risk_category'] == cat).sum()\n",
    "    pct = 100 * n / len(df)\n",
    "    print(f\"{cat:<12} {score_range:<15} {n:<10} {pct:<10.1f}\")\n",
    "\n",
    "# Clean up\n",
    "df.drop(['risk_A', 'risk_B', 'risk_C'], axis=1, inplace=True)\n",
    "df_eff.drop(['risk_A', 'risk_B', 'risk_C'], axis=1, inplace=True)\n",
    "\n",
    "print(\"\\n\u2713 Risk categories applied to dataframe as 'risk_category'\")\n",
    "print(\"\\n\u2192 Next: Define analysis sub-cohorts\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# SECTION 2: RISK CATEGORY DERIVATION\n",
    "# Cell 7: Define Analysis Sub-Cohorts\n",
    "#==========================================================================\n",
    "# PURPOSE: Define all sub-cohorts needed for analysis per master plan\n",
    "# OUTPUT: Sub-cohort dataframes with sample sizes and characteristics\n",
    "#==========================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ANALYSIS SUB-COHORT DEFINITIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# SUB-COHORT 1: FULL COHORT (Mortality Analysis)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"1. FULL COHORT \u2014 Mortality Analysis\")\n",
    "print(\"-\"*70)\n",
    "n_full = len(df)\n",
    "n_deaths = df['hospital_expire_flag'].sum()\n",
    "print(f\"   N = {n_full:,}\")\n",
    "print(f\"   Deaths: {n_deaths} ({100*n_deaths/n_full:.1f}%)\")\n",
    "print(f\"   Use: In-hospital mortality (exploratory)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# SUB-COHORT 2: ICU STAY \u226524H (Binary Diuretic Resistance)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"2. ICU STAY \u226524H \u2014 Binary Diuretic Resistance\")\n",
    "print(\"-\"*70)\n",
    "df_icu_24h = df[df['icu_stay_ge_24h'] == 1].copy()\n",
    "print(f\"   N = {len(df_icu_24h):,}\")\n",
    "print(f\"   Exclusions: {n_full - len(df_icu_24h)} patients with ICU stay <24h\")\n",
    "\n",
    "# Verify/create diuretic_resistance variable\n",
    "print(\"\\n   Diuretic Resistance Definition:\")\n",
    "if 'diuretic_resistance' in df.columns:\n",
    "    # Check if it matches expected definition (urine \u22643,000 mL)\n",
    "    # Verify by comparing with urine_output_24h_ml\n",
    "    if 'urine_output_24h_ml' in df.columns:\n",
    "        expected_dr = (df['urine_output_24h_ml'] <= 3000).astype(int)\n",
    "        match_pct = (df['diuretic_resistance'] == expected_dr).mean() * 100\n",
    "        print(f\"   \u2022 Pre-calculated 'diuretic_resistance' column exists\")\n",
    "        print(f\"   \u2022 Verification against urine \u22643,000 mL: {match_pct:.1f}% match\")\n",
    "\n",
    "        if match_pct < 100:\n",
    "            print(f\"   \u2022 NOTE: Some discrepancy detected - creating verified variable\")\n",
    "            df['diuretic_resistance_verified'] = expected_dr\n",
    "\n",
    "    dr_n = df_icu_24h['diuretic_resistance'].sum()\n",
    "    dr_pct = 100 * dr_n / len(df_icu_24h)\n",
    "    print(f\"   \u2022 DR prevalence (ICU\u226524h): {dr_n} ({dr_pct:.1f}%)\")\n",
    "else:\n",
    "    # Create diuretic_resistance if not present\n",
    "    print(f\"   \u2022 Creating 'diuretic_resistance' from urine_output_24h_ml \u22643,000 mL\")\n",
    "    df['diuretic_resistance'] = (df['urine_output_24h_ml'] <= 3000).astype(int)\n",
    "    dr_n = df_icu_24h['diuretic_resistance'].sum()\n",
    "    dr_pct = 100 * dr_n / len(df_icu_24h)\n",
    "    print(f\"   \u2022 DR prevalence (ICU\u226524h): {dr_n} ({dr_pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\n   Use: Binary DR outcome (urine output \u22643,000 mL in first 24h)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# SUB-COHORT 3: 24H EFFICIENCY COHORT (Primary Diuretic Efficiency)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"3. 24H EFFICIENCY COHORT \u2014 Primary Diuretic Efficiency Analysis\")\n",
    "print(\"-\"*70)\n",
    "df_24h_eff = df[(df['icu_stay_ge_24h'] == 1) &\n",
    "                (df['diuretic_efficiency_24h'].notna()) &\n",
    "                (df['diuretic_efficiency_24h'] > 0)].copy()\n",
    "\n",
    "print(f\"   N = {len(df_24h_eff):,}\")\n",
    "print(f\"   Criteria: ICU \u226524h AND 24h IV diuretic dose >0\")\n",
    "print(f\"   Exclusions from ICU\u226524h: {len(df_icu_24h) - len(df_24h_eff)} (no IV diuretics in first 24h)\")\n",
    "print(f\"   Median efficiency: {df_24h_eff['diuretic_efficiency_24h'].median():.1f} mL/mg\")\n",
    "print(f\"   Use: Spearman correlation, C-index, quintile/quartile AUROC\")\n",
    "\n",
    "# Define and SAVE quintile and quartile thresholds for later use\n",
    "QUINTILE_THRESHOLD_24H = df_24h_eff['diuretic_efficiency_24h'].quantile(0.20)\n",
    "QUARTILE_THRESHOLD_24H = df_24h_eff['diuretic_efficiency_24h'].quantile(0.25)\n",
    "\n",
    "print(f\"\\n   Efficiency Thresholds (SAVED FOR LATER USE):\")\n",
    "print(f\"   \u2022 QUINTILE_THRESHOLD_24H (20th %ile): \u2264{QUINTILE_THRESHOLD_24H:.1f} mL/mg\")\n",
    "print(f\"   \u2022 QUARTILE_THRESHOLD_24H (25th %ile): \u2264{QUARTILE_THRESHOLD_24H:.1f} mL/mg\")\n",
    "\n",
    "# Create binary outcome variables for AUROC analysis\n",
    "df_24h_eff['lowest_quintile_24h'] = (df_24h_eff['diuretic_efficiency_24h'] <= QUINTILE_THRESHOLD_24H).astype(int)\n",
    "df_24h_eff['lowest_quartile_24h'] = (df_24h_eff['diuretic_efficiency_24h'] <= QUARTILE_THRESHOLD_24H).astype(int)\n",
    "\n",
    "n_quintile = df_24h_eff['lowest_quintile_24h'].sum()\n",
    "n_quartile = df_24h_eff['lowest_quartile_24h'].sum()\n",
    "print(f\"\\n   Binary Outcomes Created:\")\n",
    "print(f\"   \u2022 Lowest quintile: {n_quintile} ({100*n_quintile/len(df_24h_eff):.1f}%)\")\n",
    "print(f\"   \u2022 Lowest quartile: {n_quartile} ({100*n_quartile/len(df_24h_eff):.1f}%)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# SUB-COHORT 4: ICU STAY \u226572H\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"4. ICU STAY \u226572H\")\n",
    "print(\"-\"*70)\n",
    "df_icu_72h = df[df['icu_stay_ge_72h'] == 1].copy()\n",
    "print(f\"   N = {len(df_icu_72h):,}\")\n",
    "print(f\"   Exclusions: {n_full - len(df_icu_72h)} patients with ICU stay <72h\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# SUB-COHORT 5: 72H EFFICIENCY COHORT\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"5. 72H EFFICIENCY COHORT \u2014 Secondary Diuretic Efficiency Analysis\")\n",
    "print(\"-\"*70)\n",
    "df_72h_eff = df[(df['icu_stay_ge_72h'] == 1) &\n",
    "                (df['diuretic_efficiency_72h'].notna()) &\n",
    "                (df['diuretic_efficiency_72h'] > 0)].copy()\n",
    "\n",
    "print(f\"   N = {len(df_72h_eff):,}\")\n",
    "print(f\"   Criteria: ICU \u226572h AND 72h IV diuretic dose >0\")\n",
    "print(f\"   Exclusions from ICU\u226572h: {len(df_icu_72h) - len(df_72h_eff)} (no IV diuretics in first 72h)\")\n",
    "print(f\"   Median efficiency: {df_72h_eff['diuretic_efficiency_72h'].median():.1f} mL/mg\")\n",
    "print(f\"   Use: Spearman correlation, C-index (matches original derivation endpoint)\")\n",
    "\n",
    "# Save 72h thresholds as well\n",
    "QUINTILE_THRESHOLD_72H = df_72h_eff['diuretic_efficiency_72h'].quantile(0.20)\n",
    "QUARTILE_THRESHOLD_72H = df_72h_eff['diuretic_efficiency_72h'].quantile(0.25)\n",
    "\n",
    "print(f\"\\n   Efficiency Thresholds (SAVED FOR LATER USE):\")\n",
    "print(f\"   \u2022 QUINTILE_THRESHOLD_72H (20th %ile): \u2264{QUINTILE_THRESHOLD_72H:.1f} mL/mg\")\n",
    "print(f\"   \u2022 QUARTILE_THRESHOLD_72H (25th %ile): \u2264{QUARTILE_THRESHOLD_72H:.1f} mL/mg\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# SUB-COHORT 6: CARDIOGENIC SHOCK\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"6. CARDIOGENIC SHOCK SUBGROUP\")\n",
    "print(\"-\"*70)\n",
    "df_cs = df[df['cardiogenic_shock'] == 1].copy()\n",
    "df_no_cs = df[df['cardiogenic_shock'] == 0].copy()\n",
    "\n",
    "print(f\"   Cardiogenic shock (CS):    N = {len(df_cs):,} ({100*len(df_cs)/n_full:.1f}%)\")\n",
    "print(f\"   No cardiogenic shock:      N = {len(df_no_cs):,} ({100*len(df_no_cs)/n_full:.1f}%)\")\n",
    "print(f\"   CS mortality: {100*df_cs['hospital_expire_flag'].mean():.1f}%\")\n",
    "print(f\"   Non-CS mortality: {100*df_no_cs['hospital_expire_flag'].mean():.1f}%\")\n",
    "print(f\"   Use: Subgroup analysis, sensitivity analysis\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# SUB-COHORT 7: COMPLETE LVEF DATA\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"7. COMPLETE LVEF DATA\")\n",
    "print(\"-\"*70)\n",
    "df_lvef = df[df['lvef'].notna()].copy()\n",
    "print(f\"   N = {len(df_lvef):,} ({100*len(df_lvef)/n_full:.1f}% of cohort)\")\n",
    "print(f\"   Missing LVEF: {n_full - len(df_lvef)}\")\n",
    "\n",
    "if 'hf_phenotype' in df.columns:\n",
    "    print(f\"\\n   HF Phenotype Distribution:\")\n",
    "    for phenotype in df_lvef['hf_phenotype'].dropna().unique():\n",
    "        n = (df_lvef['hf_phenotype'] == phenotype).sum()\n",
    "        print(f\"   \u2022 {phenotype}: {n} ({100*n/len(df_lvef):.1f}%)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# SUB-COHORT 8: EXCLUDE ADVANCED CKD (Sensitivity Analysis)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"8. EXCLUDE ADVANCED CKD \u2014 Sensitivity Analysis\")\n",
    "print(\"-\"*70)\n",
    "df_no_ckd = df[df['chronic_advanced_ckd'] == 0].copy()\n",
    "print(f\"   N = {len(df_no_ckd):,}\")\n",
    "print(f\"   Excluded: {n_full - len(df_no_ckd)} with chronic advanced CKD\")\n",
    "print(f\"   Use: Sensitivity analysis (different pathophysiology)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# SUMMARY TABLE\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUB-COHORT SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'Sub-Cohort':<35} {'N':<10} {'Purpose':<30}\")\n",
    "print(\"-\"*75)\n",
    "print(f\"{'Full cohort':<35} {n_full:<10} {'Mortality (exploratory)':<30}\")\n",
    "print(f\"{'ICU \u226524h':<35} {len(df_icu_24h):<10} {'Binary diuretic resistance':<30}\")\n",
    "print(f\"{'24h efficiency cohort':<35} {len(df_24h_eff):<10} {'Correlation, C-index, AUROC':<30}\")\n",
    "print(f\"{'ICU \u226572h':<35} {len(df_icu_72h):<10} {'72h outcomes':<30}\")\n",
    "print(f\"{'72h efficiency cohort':<35} {len(df_72h_eff):<10} {'72h correlation, C-index':<30}\")\n",
    "print(f\"{'Cardiogenic shock':<35} {len(df_cs):<10} {'Subgroup analysis':<30}\")\n",
    "print(f\"{'No cardiogenic shock':<35} {len(df_no_cs):<10} {'Sensitivity analysis':<30}\")\n",
    "print(f\"{'Complete LVEF':<35} {len(df_lvef):<10} {'HF phenotype subgroups':<30}\")\n",
    "print(f\"{'Exclude advanced CKD':<35} {len(df_no_ckd):<10} {'Sensitivity analysis':<30}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# SAVED THRESHOLDS SUMMARY\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVED THRESHOLDS FOR AUROC ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n24-Hour Efficiency (N={len(df_24h_eff):,}):\")\n",
    "print(f\"   QUINTILE_THRESHOLD_24H = {QUINTILE_THRESHOLD_24H:.1f} mL/mg (20th percentile)\")\n",
    "print(f\"   QUARTILE_THRESHOLD_24H = {QUARTILE_THRESHOLD_24H:.1f} mL/mg (25th percentile)\")\n",
    "print(f\"\\n72-Hour Efficiency (N={len(df_72h_eff):,}):\")\n",
    "print(f\"   QUINTILE_THRESHOLD_72H = {QUINTILE_THRESHOLD_72H:.1f} mL/mg (20th percentile)\")\n",
    "print(f\"   QUARTILE_THRESHOLD_72H = {QUARTILE_THRESHOLD_72H:.1f} mL/mg (25th percentile)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# RISK CATEGORY DISTRIBUTION BY KEY SUB-COHORTS\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"RISK CATEGORY DISTRIBUTION BY KEY SUB-COHORTS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "def show_risk_dist(data, name):\n",
    "    print(f\"\\n{name} (N={len(data):,}):\")\n",
    "    for cat in ['Low', 'Moderate', 'High']:\n",
    "        n = (data['risk_category'] == cat).sum()\n",
    "        pct = 100 * n / len(data)\n",
    "        print(f\"   {cat:<10}: {n:>4} ({pct:>5.1f}%)\")\n",
    "\n",
    "show_risk_dist(df, \"Full Cohort\")\n",
    "show_risk_dist(df_24h_eff, \"24h Efficiency Cohort\")\n",
    "show_risk_dist(df_72h_eff, \"72h Efficiency Cohort\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUB-COHORT DEFINITIONS COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nKey variables created/saved:\")\n",
    "print(\"  \u2022 QUINTILE_THRESHOLD_24H, QUARTILE_THRESHOLD_24H\")\n",
    "print(\"  \u2022 QUINTILE_THRESHOLD_72H, QUARTILE_THRESHOLD_72H\")\n",
    "print(\"  \u2022 df_24h_eff['lowest_quintile_24h'], df_24h_eff['lowest_quartile_24h']\")\n",
    "print(\"  \u2022 diuretic_resistance verified\")\n",
    "print(\"\\n\u2192 Next: Generate Table 1 (Baseline Characteristics)\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# SECTION 3: TABLE 1 - BASELINE CHARACTERISTICS\n",
    "# Cell 8: Mortality Status\n",
    "#==========================================================================\n",
    "# PURPOSE: Create Table showing baseline characteristics stratified by\n",
    "#          in-hospital mortality (Survivors vs Non-survivors)\n",
    "# NOTE: Diuretic resistance is an OUTCOME, shown in Table 3, not here\n",
    "#==========================================================================\n",
    "\n",
    "from tableone import TableOne\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TABLE 1: BASELINE CHARACTERISTICS BY MORTALITY STATUS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# PREPARE DATA\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "df_table1 = df.copy()\n",
    "\n",
    "# Create mortality status variable\n",
    "df_table1['mortality_status'] = df_table1['hospital_expire_flag'].map({0: 'Survivors', 1: 'Non-survivors'})\n",
    "\n",
    "# Create male_sex variable\n",
    "if df_table1['gender'].dtype == 'object':\n",
    "    df_table1['male_sex'] = (df_table1['gender'] == 'M').astype(int)\n",
    "else:\n",
    "    df_table1['male_sex'] = df_table1['gender']\n",
    "\n",
    "# Risk category as string\n",
    "df_table1['risk_category'] = df_table1['risk_category'].astype(str)\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# DEFINE VARIABLES FOR TABLE 1 (Baseline characteristics only)\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "all_columns = [\n",
    "    # Demographics\n",
    "    'age',\n",
    "    'male_sex',\n",
    "    # BAN-ADHF Score\n",
    "    'ban_adhf_total_score',\n",
    "    'risk_category',\n",
    "    # Score Components (raw values)\n",
    "    'creatinine',\n",
    "    'bun',\n",
    "    'ntprobnp',\n",
    "    'dbp',\n",
    "    'total_furosemide_equivalent_mg',\n",
    "    'hx_atrial_fibrillation',\n",
    "    'hx_hypertension',\n",
    "    'prior_hf_hospitalization_12mo',\n",
    "    # Heart Failure Characteristics\n",
    "    'lvef',\n",
    "    'hf_phenotype',\n",
    "    # Comorbidities\n",
    "    'hx_diabetes',\n",
    "    'hx_renal_disease',\n",
    "    'hx_myocardial_infarction',\n",
    "    'hx_stroke',\n",
    "    'hx_copd',\n",
    "    'cci_score',\n",
    "    # Clinical Presentation\n",
    "    'cardiogenic_shock',\n",
    "    'invasive_vent'\n",
    "]\n",
    "\n",
    "# Filter to existing columns\n",
    "all_columns = [v for v in all_columns if v in df_table1.columns]\n",
    "\n",
    "# Categorical variables\n",
    "categorical_vars = [\n",
    "    'male_sex',\n",
    "    'risk_category',\n",
    "    'hx_atrial_fibrillation',\n",
    "    'hx_hypertension',\n",
    "    'prior_hf_hospitalization_12mo',\n",
    "    'hf_phenotype',\n",
    "    'hx_diabetes',\n",
    "    'hx_renal_disease',\n",
    "    'hx_myocardial_infarction',\n",
    "    'hx_stroke',\n",
    "    'hx_copd',\n",
    "    'cardiogenic_shock',\n",
    "    'invasive_vent'\n",
    "]\n",
    "categorical_vars = [v for v in categorical_vars if v in df_table1.columns]\n",
    "\n",
    "# Non-normal continuous variables\n",
    "nonnormal_vars = [\n",
    "    'ban_adhf_total_score',\n",
    "    'creatinine',\n",
    "    'bun',\n",
    "    'ntprobnp',\n",
    "    'total_furosemide_equivalent_mg',\n",
    "    'cci_score'\n",
    "]\n",
    "nonnormal_vars = [v for v in nonnormal_vars if v in df_table1.columns]\n",
    "\n",
    "print(f\"Total variables: {len(all_columns)}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# LABELS\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "labels = {\n",
    "    'age': 'Age, years',\n",
    "    'male_sex': 'Male sex',\n",
    "    'ban_adhf_total_score': 'Total score',\n",
    "    'risk_category': 'Risk category',\n",
    "    'creatinine': 'Creatinine, mg/dL',\n",
    "    'bun': 'BUN, mg/dL',\n",
    "    'ntprobnp': 'NT-proBNP, pg/mL',\n",
    "    'dbp': 'Diastolic BP, mmHg',\n",
    "    'total_furosemide_equivalent_mg': 'Home diuretic dose, mg/day \u2020',\n",
    "    'hx_atrial_fibrillation': 'Atrial fibrillation',\n",
    "    'hx_hypertension': 'Hypertension',\n",
    "    'prior_hf_hospitalization_12mo': 'Prior HF hospitalization (12 months)',\n",
    "    'lvef': 'LVEF, % \u2021',\n",
    "    'hf_phenotype': 'HF phenotype \u2021',\n",
    "    'hx_diabetes': 'Diabetes mellitus',\n",
    "    'hx_renal_disease': 'Chronic kidney disease',\n",
    "    'hx_myocardial_infarction': 'Prior myocardial infarction',\n",
    "    'hx_stroke': 'Prior stroke',\n",
    "    'hx_copd': 'COPD',\n",
    "    'cci_score': 'Charlson Comorbidity Index',\n",
    "    'cardiogenic_shock': 'Cardiogenic shock',\n",
    "    'invasive_vent': 'Invasive mechanical ventilation'\n",
    "}\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# GENERATE TABLE\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "order = {\n",
    "    'mortality_status': ['Survivors', 'Non-survivors'],\n",
    "    'risk_category': ['Low', 'Moderate', 'High']\n",
    "}\n",
    "\n",
    "limit = {\n",
    "    'male_sex': 1,\n",
    "    'hx_atrial_fibrillation': 1,\n",
    "    'hx_hypertension': 1,\n",
    "    'prior_hf_hospitalization_12mo': 1,\n",
    "    'hx_diabetes': 1,\n",
    "    'hx_renal_disease': 1,\n",
    "    'hx_myocardial_infarction': 1,\n",
    "    'hx_stroke': 1,\n",
    "    'hx_copd': 1,\n",
    "    'cardiogenic_shock': 1,\n",
    "    'invasive_vent': 1\n",
    "}\n",
    "\n",
    "table1 = TableOne(\n",
    "    df_table1,\n",
    "    columns=all_columns,\n",
    "    categorical=categorical_vars,\n",
    "    nonnormal=nonnormal_vars,\n",
    "    groupby='mortality_status',\n",
    "    pval=True,\n",
    "    rename=labels,\n",
    "    missing=False,\n",
    "    overall=True,\n",
    "    order=order,\n",
    "    limit=limit,\n",
    "    decimals=1\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(table1.tabulate(tablefmt=\"simple\"))\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# EXPORT TABLE\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "table1_df = table1.tableone\n",
    "table1_df.to_csv('/content/Table1_by_mortality.csv')\n",
    "print(\"\\n\u2713 Table 1 saved to 'Table1_by_mortality.csv'\")\n",
    "\n",
    "table1_df.to_excel('/content/Table1_by_mortality.xlsx')\n",
    "print(\"\u2713 Table 1 saved to 'Table1_by_mortality.xlsx'\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# VERIFICATION\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "survivors = df_table1[df_table1['mortality_status'] == 'Survivors']\n",
    "nonsurvivors = df_table1[df_table1['mortality_status'] == 'Non-survivors']\n",
    "\n",
    "print(f\"\"\"\n",
    "Sample Size:\n",
    "  \u2022 Overall:        N = {len(df_table1):,}\n",
    "  \u2022 Survivors:      N = {len(survivors):,}\n",
    "  \u2022 Non-survivors:  N = {len(nonsurvivors):,}\n",
    "\n",
    "BAN-ADHF Score:\n",
    "  \u2022 Survivors:      {survivors['ban_adhf_total_score'].mean():.1f} \u00b1 {survivors['ban_adhf_total_score'].std():.1f}\n",
    "  \u2022 Non-survivors:  {nonsurvivors['ban_adhf_total_score'].mean():.1f} \u00b1 {nonsurvivors['ban_adhf_total_score'].std():.1f}\n",
    "\n",
    "Risk Category (Non-survivors):\n",
    "  \u2022 Low (\u22647):       {(nonsurvivors['risk_category']=='Low').sum()} ({100*(nonsurvivors['risk_category']=='Low').mean():.1f}%)\n",
    "  \u2022 Moderate (8-12): {(nonsurvivors['risk_category']=='Moderate').sum()} ({100*(nonsurvivors['risk_category']=='Moderate').mean():.1f}%)\n",
    "  \u2022 High (\u226513):     {(nonsurvivors['risk_category']=='High').sum()} ({100*(nonsurvivors['risk_category']=='High').mean():.1f}%)\n",
    "\"\"\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# FOOTNOTES\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "lvef_n = df_table1['lvef'].notna().sum()\n",
    "lvef_pct = 100 * lvef_n / len(df_table1)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TABLE 1 FOOTNOTES\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\"\"\n",
    "Values are mean \u00b1 SD, median [IQR], or n (%). P-values from Student's t-test\n",
    "or Mann-Whitney U test for continuous variables and chi-square test for\n",
    "categorical variables.\n",
    "\n",
    "\u2020 Home diuretic dose expressed as oral furosemide equivalents.\n",
    "\u2021 Available in {lvef_n} patients ({lvef_pct:.1f}%); percentages calculated\n",
    "  among those with available data.\n",
    "\n",
    "Abbreviations: BUN, blood urea nitrogen; BP, blood pressure; COPD, chronic\n",
    "obstructive pulmonary disease; HF, heart failure; HFmrEF, heart failure with\n",
    "mildly reduced ejection fraction; HFpEF, heart failure with preserved ejection\n",
    "fraction; HFrEF, heart failure with reduced ejection fraction; IQR, interquartile\n",
    "range; LVEF, left ventricular ejection fraction; NT-proBNP, N-terminal pro-B-type\n",
    "natriuretic peptide.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\u2192 Next: Primary Analysis - 24h Diuretic Efficiency\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# SECTION 4: CO-PRIMARY OUTCOME 1 - 24-HOUR DIURETIC EFFICIENCY\n",
    "# Cell 9: Correlation, C-index, and AUROC Analysis\n",
    "#==========================================================================\n",
    "# PURPOSE: Evaluate BAN-ADHF score's ability to predict 24h diuretic efficiency\n",
    "# POPULATION: N=1,019 (ICU \u226524h with IV diuretic dose >0)\n",
    "# METRICS: Spearman correlation (primary), Pearson (for Mauch comparison),\n",
    "#          C-index, AUROC (quintile/quartile)\n",
    "# OUTPUT: Primary discrimination statistics with 95% CIs\n",
    "#==========================================================================\n",
    "\n",
    "from scipy.stats import spearmanr, pearsonr, kruskal\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from lifelines.utils import concordance_index\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CO-PRIMARY OUTCOME 1: 24-HOUR DIURETIC EFFICIENCY\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nBAN-ADHF was designed to predict diuretic efficiency.\")\n",
    "print(\"This is the score's PRIMARY intended purpose.\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# ANALYSIS COHORT\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ANALYSIS COHORT\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "df_24h = df[(df['icu_stay_ge_24h'] == 1) &\n",
    "            (df['diuretic_efficiency_24h'].notna()) &\n",
    "            (df['diuretic_efficiency_24h'] > 0)].copy()\n",
    "\n",
    "print(f\"Population: ICU \u226524h with IV diuretic dose >0 in first 24 hours\")\n",
    "print(f\"N = {len(df_24h):,}\")\n",
    "print(f\"\\nDiuretic Efficiency Distribution:\")\n",
    "print(f\"  Mean \u00b1 SD:    {df_24h['diuretic_efficiency_24h'].mean():.1f} \u00b1 {df_24h['diuretic_efficiency_24h'].std():.1f} mL/mg\")\n",
    "print(f\"  Median (IQR): {df_24h['diuretic_efficiency_24h'].median():.1f} ({df_24h['diuretic_efficiency_24h'].quantile(0.25):.1f}-{df_24h['diuretic_efficiency_24h'].quantile(0.75):.1f}) mL/mg\")\n",
    "print(f\"  Range:        {df_24h['diuretic_efficiency_24h'].min():.1f} - {df_24h['diuretic_efficiency_24h'].max():.1f} mL/mg\")\n",
    "\n",
    "# Check skewness\n",
    "skewness = df_24h['diuretic_efficiency_24h'].skew()\n",
    "print(f\"  Skewness:     {skewness:.2f} ({'right-skewed' if skewness > 0.5 else 'approximately normal'})\")\n",
    "print(f\"\\n  \u2192 Spearman \u03c1 used as primary metric (robust to skewed distributions)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# BOOTSTRAP SETUP\n",
    "#------------------------------------------------------------------------------\n",
    "np.random.seed(42)\n",
    "n_bootstrap = 1000\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 1. SPEARMAN CORRELATION (PRIMARY)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"1. SPEARMAN CORRELATION (PRIMARY METRIC)\")\n",
    "print(\"=\"*70)\n",
    "print(\"Higher BAN-ADHF score should predict LOWER diuretic efficiency\")\n",
    "print(\"(inverse correlation expected)\")\n",
    "\n",
    "# Calculate Spearman correlation\n",
    "rho, rho_p = spearmanr(df_24h['ban_adhf_total_score'],\n",
    "                        df_24h['diuretic_efficiency_24h'])\n",
    "\n",
    "# Bootstrap 95% CI for Spearman\n",
    "rho_bootstrap = []\n",
    "for _ in range(n_bootstrap):\n",
    "    idx = np.random.choice(len(df_24h), size=len(df_24h), replace=True)\n",
    "    sample = df_24h.iloc[idx]\n",
    "    r, _ = spearmanr(sample['ban_adhf_total_score'], sample['diuretic_efficiency_24h'])\n",
    "    rho_bootstrap.append(r)\n",
    "\n",
    "rho_ci_lower = np.percentile(rho_bootstrap, 2.5)\n",
    "rho_ci_upper = np.percentile(rho_bootstrap, 97.5)\n",
    "\n",
    "print(f\"\\nSpearman \u03c1 = {rho:.3f} (95% CI: {rho_ci_lower:.3f} to {rho_ci_upper:.3f})\")\n",
    "print(f\"P-value: < 0.001\" if rho_p < 0.001 else f\"P-value: {rho_p:.4f}\")\n",
    "\n",
    "# Interpretation\n",
    "print(f\"\\nInterpretation:\")\n",
    "if abs(rho) > 0.5:\n",
    "    print(f\"  Strong inverse correlation (|\u03c1| > 0.5)\")\n",
    "elif abs(rho) > 0.3:\n",
    "    print(f\"  Moderate inverse correlation (|\u03c1| 0.3-0.5)\")\n",
    "else:\n",
    "    print(f\"  Weak inverse correlation (|\u03c1| < 0.3)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 1b. PEARSON CORRELATION (FOR MAUCH COMPARISON)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"1b. PEARSON CORRELATION (For Mauch 2025 Comparison)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Calculate Pearson correlation\n",
    "pearson_r, pearson_p = pearsonr(df_24h['ban_adhf_total_score'],\n",
    "                                 df_24h['diuretic_efficiency_24h'])\n",
    "\n",
    "# Bootstrap CI for Pearson\n",
    "pearson_bootstrap = []\n",
    "for _ in range(n_bootstrap):\n",
    "    idx = np.random.choice(len(df_24h), size=len(df_24h), replace=True)\n",
    "    sample = df_24h.iloc[idx]\n",
    "    r, _ = pearsonr(sample['ban_adhf_total_score'], sample['diuretic_efficiency_24h'])\n",
    "    pearson_bootstrap.append(r)\n",
    "\n",
    "pearson_ci_lower = np.percentile(pearson_bootstrap, 2.5)\n",
    "pearson_ci_upper = np.percentile(pearson_bootstrap, 97.5)\n",
    "\n",
    "print(f\"\\nPearson r = {pearson_r:.3f} (95% CI: {pearson_ci_lower:.3f} to {pearson_ci_upper:.3f})\")\n",
    "print(f\"Mauch 2025 (floor patients): r = -0.40\")\n",
    "\n",
    "# Calculate percentage difference from Mauch\n",
    "mauch_r = -0.40\n",
    "pct_diff = ((abs(pearson_r) - abs(mauch_r)) / abs(mauch_r)) * 100\n",
    "print(f\"\\n\u2192 Our Pearson r is {abs(pct_diff):.1f}% {'stronger' if abs(pearson_r) > abs(mauch_r) else 'weaker'} than Mauch\")\n",
    "print(f\"\\nNote: Spearman \u03c1 is primary metric due to right-skewed efficiency distribution\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 2. C-INDEX (HARRELL'S CONCORDANCE INDEX)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"2. C-INDEX (HARRELL'S CONCORDANCE INDEX)\")\n",
    "print(\"=\"*70)\n",
    "print(\"Probability that patient with higher score has lower efficiency\")\n",
    "\n",
    "# Calculate C-index\n",
    "c_index = concordance_index(\n",
    "    df_24h['diuretic_efficiency_24h'],\n",
    "    -df_24h['ban_adhf_total_score'],\n",
    "    np.ones(len(df_24h))\n",
    ")\n",
    "\n",
    "# Bootstrap 95% CI for C-index\n",
    "c_index_bootstrap = []\n",
    "for _ in range(n_bootstrap):\n",
    "    idx = np.random.choice(len(df_24h), size=len(df_24h), replace=True)\n",
    "    sample = df_24h.iloc[idx]\n",
    "    c = concordance_index(\n",
    "        sample['diuretic_efficiency_24h'],\n",
    "        -sample['ban_adhf_total_score'],\n",
    "        np.ones(len(sample))\n",
    "    )\n",
    "    c_index_bootstrap.append(c)\n",
    "\n",
    "c_index_ci_lower = np.percentile(c_index_bootstrap, 2.5)\n",
    "c_index_ci_upper = np.percentile(c_index_bootstrap, 97.5)\n",
    "\n",
    "print(f\"\\nC-index = {c_index:.3f} (95% CI: {c_index_ci_lower:.3f} to {c_index_ci_upper:.3f})\")\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "if c_index >= 0.7:\n",
    "    print(f\"  Good discrimination (C-index \u2265 0.7)\")\n",
    "elif c_index >= 0.6:\n",
    "    print(f\"  Moderate discrimination (C-index 0.6-0.7)\")\n",
    "else:\n",
    "    print(f\"  Poor discrimination (C-index < 0.6)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 3. AUROC FOR LOWEST QUINTILE (Bottom 20%)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"3. AUROC FOR LOWEST QUINTILE OF EFFICIENCY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "quintile_threshold = df_24h['diuretic_efficiency_24h'].quantile(0.20)\n",
    "df_24h['lowest_quintile'] = (df_24h['diuretic_efficiency_24h'] <= quintile_threshold).astype(int)\n",
    "\n",
    "n_quintile = df_24h['lowest_quintile'].sum()\n",
    "print(f\"Threshold: \u2264{quintile_threshold:.1f} mL/mg (20th percentile)\")\n",
    "print(f\"Patients in lowest quintile: {n_quintile} ({100*n_quintile/len(df_24h):.1f}%)\")\n",
    "\n",
    "auroc_quintile = roc_auc_score(df_24h['lowest_quintile'], df_24h['ban_adhf_total_score'])\n",
    "\n",
    "# Bootstrap 95% CI\n",
    "auroc_q_bootstrap = []\n",
    "for _ in range(n_bootstrap):\n",
    "    idx = np.random.choice(len(df_24h), size=len(df_24h), replace=True)\n",
    "    sample = df_24h.iloc[idx]\n",
    "    if sample['lowest_quintile'].sum() > 0 and sample['lowest_quintile'].sum() < len(sample):\n",
    "        auc = roc_auc_score(sample['lowest_quintile'], sample['ban_adhf_total_score'])\n",
    "        auroc_q_bootstrap.append(auc)\n",
    "\n",
    "auroc_q_ci_lower = np.percentile(auroc_q_bootstrap, 2.5)\n",
    "auroc_q_ci_upper = np.percentile(auroc_q_bootstrap, 97.5)\n",
    "\n",
    "print(f\"\\nAUROC = {auroc_quintile:.3f} (95% CI: {auroc_q_ci_lower:.3f} to {auroc_q_ci_upper:.3f})\")\n",
    "print(f\"Segar 2024 (trial validation): AUROC = 0.84\")\n",
    "\n",
    "segar_diff = auroc_quintile - 0.84\n",
    "print(f\"\u2192 Difference from Segar: {segar_diff:+.3f}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 4. AUROC FOR LOWEST QUARTILE (Bottom 25%)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"4. AUROC FOR LOWEST QUARTILE OF EFFICIENCY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "quartile_threshold = df_24h['diuretic_efficiency_24h'].quantile(0.25)\n",
    "df_24h['lowest_quartile'] = (df_24h['diuretic_efficiency_24h'] <= quartile_threshold).astype(int)\n",
    "\n",
    "n_quartile = df_24h['lowest_quartile'].sum()\n",
    "print(f\"Threshold: \u2264{quartile_threshold:.1f} mL/mg (25th percentile)\")\n",
    "print(f\"Patients in lowest quartile: {n_quartile} ({100*n_quartile/len(df_24h):.1f}%)\")\n",
    "\n",
    "auroc_quartile = roc_auc_score(df_24h['lowest_quartile'], df_24h['ban_adhf_total_score'])\n",
    "\n",
    "# Bootstrap 95% CI\n",
    "auroc_qt_bootstrap = []\n",
    "for _ in range(n_bootstrap):\n",
    "    idx = np.random.choice(len(df_24h), size=len(df_24h), replace=True)\n",
    "    sample = df_24h.iloc[idx]\n",
    "    if sample['lowest_quartile'].sum() > 0 and sample['lowest_quartile'].sum() < len(sample):\n",
    "        auc = roc_auc_score(sample['lowest_quartile'], sample['ban_adhf_total_score'])\n",
    "        auroc_qt_bootstrap.append(auc)\n",
    "\n",
    "auroc_qt_ci_lower = np.percentile(auroc_qt_bootstrap, 2.5)\n",
    "auroc_qt_ci_upper = np.percentile(auroc_qt_bootstrap, 97.5)\n",
    "\n",
    "print(f\"\\nAUROC = {auroc_quartile:.3f} (95% CI: {auroc_qt_ci_lower:.3f} to {auroc_qt_ci_upper:.3f})\")\n",
    "print(f\"Pandey 2025 (CLOROTIC trial): AUROC = 0.70\")\n",
    "\n",
    "pandey_diff = auroc_quartile - 0.70\n",
    "print(f\"\u2192 Difference from Pandey: {pandey_diff:+.3f} ({100*pandey_diff/0.70:+.1f}%)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 5. EFFICIENCY BY RISK CATEGORY\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"5. DIURETIC EFFICIENCY BY RISK CATEGORY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'Risk Category':<15} {'N':<8} {'Median (IQR)':<25} {'Mean \u00b1 SD':<20}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    subset = df_24h[df_24h['risk_category'] == cat]['diuretic_efficiency_24h']\n",
    "    n = len(subset)\n",
    "    median = subset.median()\n",
    "    q1 = subset.quantile(0.25)\n",
    "    q3 = subset.quantile(0.75)\n",
    "    mean = subset.mean()\n",
    "    std = subset.std()\n",
    "    print(f\"{cat:<15} {n:<8} {median:.1f} ({q1:.1f}-{q3:.1f}){'':>8} {mean:.1f} \u00b1 {std:.1f}\")\n",
    "\n",
    "# Kruskal-Wallis test\n",
    "groups = [df_24h[df_24h['risk_category'] == cat]['diuretic_efficiency_24h'].values\n",
    "          for cat in ['Low', 'Moderate', 'High']]\n",
    "kw_stat, kw_p = kruskal(*groups)\n",
    "print(f\"\\nKruskal-Wallis H = {kw_stat:.1f}, p < 0.001\" if kw_p < 0.001 else f\"\\nKruskal-Wallis H = {kw_stat:.1f}, p = {kw_p:.3f}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# LITERATURE COMPARISON TABLE\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LITERATURE COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "Study                | Population       | N     | Spearman \u03c1 | Pearson r | AUROC (Q5) | AUROC (Q4)\n",
    "---------------------|------------------|-------|------------|-----------|------------|------------\n",
    "Segar 2024           | Trial derivation | 707   | \u2014          | \u2014         | 0.84       | \u2014\n",
    "Mauch 2025           | Floor patients   | 317   | \u2014          | -0.40     | \u2014          | \u2014\n",
    "Pandey 2025          | CLOROTIC trial   | 220   | \u2014          | \u2014         | \u2014          | 0.70\n",
    "---------------------|------------------|-------|------------|-----------|------------|------------\n",
    "THIS STUDY           | ICU patients     | {len(df_24h):,}   | {rho:.3f}      | {pearson_r:.3f}     | {auroc_quintile:.3f}      | {auroc_quartile:.3f}\n",
    "\n",
    "Key Findings:\n",
    "- Spearman \u03c1 = {rho:.3f} \u2014 strongest correlation among all validations\n",
    "- Pearson r = {pearson_r:.3f} \u2014 {abs(pct_diff):.0f}% {'stronger' if abs(pearson_r) > abs(mauch_r) else 'weaker'} than Mauch's r = -0.40\n",
    "- AUROC (quintile) = {auroc_quintile:.3f} \u2014 {'comparable to' if abs(auroc_quintile - 0.84) < 0.05 else 'lower than'} Segar's 0.84\n",
    "- AUROC (quartile) = {auroc_quartile:.3f} \u2014 {'exceeds' if auroc_quartile > 0.70 else 'comparable to'} Pandey's 0.70 by {pandey_diff:+.3f}\n",
    "\"\"\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# SUMMARY TABLE\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"=\"*70)\n",
    "print(\"SUMMARY: 24-HOUR DIURETIC EFFICIENCY DISCRIMINATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "Metric                              Value           95% CI                  Reference\n",
    "---------------------------------------------------------------------------------------------\n",
    "Spearman \u03c1 (primary)                {rho:.3f}          ({rho_ci_lower:.3f} to {rho_ci_upper:.3f})       \u2014\n",
    "Pearson r (Mauch comparison)        {pearson_r:.3f}          ({pearson_ci_lower:.3f} to {pearson_ci_upper:.3f})       Mauch: -0.40\n",
    "C-index                             {c_index:.3f}          ({c_index_ci_lower:.3f} to {c_index_ci_upper:.3f})       \u2014\n",
    "AUROC (lowest quintile)             {auroc_quintile:.3f}          ({auroc_q_ci_lower:.3f} to {auroc_q_ci_upper:.3f})       Segar: 0.84\n",
    "AUROC (lowest quartile)             {auroc_quartile:.3f}          ({auroc_qt_ci_lower:.3f} to {auroc_qt_ci_upper:.3f})       Pandey: 0.70\n",
    "\"\"\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# STORE RESULTS FOR USE IN SUBSEQUENT CELLS\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "results_24h = {\n",
    "    'n': len(df_24h),\n",
    "    'spearman_rho': rho,\n",
    "    'spearman_ci': (rho_ci_lower, rho_ci_upper),\n",
    "    'pearson_r': pearson_r,\n",
    "    'pearson_ci': (pearson_ci_lower, pearson_ci_upper),\n",
    "    'c_index': c_index,\n",
    "    'c_index_ci': (c_index_ci_lower, c_index_ci_upper),\n",
    "    'auroc_quintile': auroc_quintile,\n",
    "    'auroc_quintile_ci': (auroc_q_ci_lower, auroc_q_ci_upper),\n",
    "    'auroc_quartile': auroc_quartile,\n",
    "    'auroc_quartile_ci': (auroc_qt_ci_lower, auroc_qt_ci_upper),\n",
    "    'quintile_threshold': quintile_threshold,\n",
    "    'quartile_threshold': quartile_threshold,\n",
    "    'median_by_risk': {\n",
    "        'Low': df_24h[df_24h['risk_category']=='Low']['diuretic_efficiency_24h'].median(),\n",
    "        'Moderate': df_24h[df_24h['risk_category']=='Moderate']['diuretic_efficiency_24h'].median(),\n",
    "        'High': df_24h[df_24h['risk_category']=='High']['diuretic_efficiency_24h'].median()\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n\u2713 24h efficiency results stored in 'results_24h' dictionary\")\n",
    "print(\"\u2192 Next: Co-Primary Outcome 2 - 72h Diuretic Efficiency\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# SECTION 5: CO-PRIMARY OUTCOME 2 - 72-HOUR DIURETIC EFFICIENCY\n",
    "# Cell 10: Correlation, C-index Analysis\n",
    "#==========================================================================\n",
    "# PURPOSE: Evaluate BAN-ADHF score's ability to predict 72h diuretic efficiency\n",
    "# POPULATION: N=781 (ICU \u226572h with IV diuretic dose >0)\n",
    "# NOTE: This matches the ORIGINAL BAN-ADHF derivation endpoint (Segar 2024)\n",
    "# METRICS: Spearman correlation, Pearson (for comparison), C-index\n",
    "# OUTPUT: Secondary discrimination statistics with 95% CIs\n",
    "#==========================================================================\n",
    "\n",
    "from scipy.stats import spearmanr, pearsonr, kruskal\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lifelines.utils import concordance_index\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CO-PRIMARY OUTCOME 2: 72-HOUR DIURETIC EFFICIENCY\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nNOTE: 72-hour diuretic efficiency was the ORIGINAL endpoint used\")\n",
    "print(\"in the BAN-ADHF derivation study (Segar 2024).\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# ANALYSIS COHORT\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ANALYSIS COHORT\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "df_72h = df[(df['icu_stay_ge_72h'] == 1) &\n",
    "            (df['diuretic_efficiency_72h'].notna()) &\n",
    "            (df['diuretic_efficiency_72h'] > 0)].copy()\n",
    "\n",
    "print(f\"Population: ICU \u226572h with IV diuretic dose >0 in first 72 hours\")\n",
    "print(f\"N = {len(df_72h):,}\")\n",
    "print(f\"\\nDiuretic Efficiency Distribution:\")\n",
    "print(f\"  Mean \u00b1 SD:    {df_72h['diuretic_efficiency_72h'].mean():.1f} \u00b1 {df_72h['diuretic_efficiency_72h'].std():.1f} mL/mg\")\n",
    "print(f\"  Median (IQR): {df_72h['diuretic_efficiency_72h'].median():.1f} ({df_72h['diuretic_efficiency_72h'].quantile(0.25):.1f}-{df_72h['diuretic_efficiency_72h'].quantile(0.75):.1f}) mL/mg\")\n",
    "print(f\"  Range:        {df_72h['diuretic_efficiency_72h'].min():.1f} - {df_72h['diuretic_efficiency_72h'].max():.1f} mL/mg\")\n",
    "\n",
    "skewness = df_72h['diuretic_efficiency_72h'].skew()\n",
    "print(f\"  Skewness:     {skewness:.2f} ({'right-skewed' if skewness > 0.5 else 'approximately normal'})\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# BOOTSTRAP SETUP\n",
    "#------------------------------------------------------------------------------\n",
    "np.random.seed(42)\n",
    "n_bootstrap = 1000\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 1. SPEARMAN CORRELATION (PRIMARY)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"1. SPEARMAN CORRELATION (PRIMARY METRIC)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "rho_72, rho_72_p = spearmanr(df_72h['ban_adhf_total_score'],\n",
    "                              df_72h['diuretic_efficiency_72h'])\n",
    "\n",
    "# Bootstrap 95% CI\n",
    "rho_72_bootstrap = []\n",
    "for _ in range(n_bootstrap):\n",
    "    idx = np.random.choice(len(df_72h), size=len(df_72h), replace=True)\n",
    "    sample = df_72h.iloc[idx]\n",
    "    r, _ = spearmanr(sample['ban_adhf_total_score'], sample['diuretic_efficiency_72h'])\n",
    "    rho_72_bootstrap.append(r)\n",
    "\n",
    "rho_72_ci_lower = np.percentile(rho_72_bootstrap, 2.5)\n",
    "rho_72_ci_upper = np.percentile(rho_72_bootstrap, 97.5)\n",
    "\n",
    "print(f\"\\nSpearman \u03c1 = {rho_72:.3f} (95% CI: {rho_72_ci_lower:.3f} to {rho_72_ci_upper:.3f})\")\n",
    "print(f\"P-value: < 0.001\" if rho_72_p < 0.001 else f\"P-value: {rho_72_p:.4f}\")\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "if abs(rho_72) > 0.5:\n",
    "    print(f\"  Strong inverse correlation (|\u03c1| > 0.5)\")\n",
    "elif abs(rho_72) > 0.3:\n",
    "    print(f\"  Moderate inverse correlation (|\u03c1| 0.3-0.5)\")\n",
    "else:\n",
    "    print(f\"  Weak inverse correlation (|\u03c1| < 0.3)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 1b. PEARSON CORRELATION (FOR COMPARISON)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"1b. PEARSON CORRELATION\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "pearson_72, pearson_72_p = pearsonr(df_72h['ban_adhf_total_score'],\n",
    "                                     df_72h['diuretic_efficiency_72h'])\n",
    "\n",
    "# Bootstrap CI\n",
    "pearson_72_bootstrap = []\n",
    "for _ in range(n_bootstrap):\n",
    "    idx = np.random.choice(len(df_72h), size=len(df_72h), replace=True)\n",
    "    sample = df_72h.iloc[idx]\n",
    "    r, _ = pearsonr(sample['ban_adhf_total_score'], sample['diuretic_efficiency_72h'])\n",
    "    pearson_72_bootstrap.append(r)\n",
    "\n",
    "pearson_72_ci_lower = np.percentile(pearson_72_bootstrap, 2.5)\n",
    "pearson_72_ci_upper = np.percentile(pearson_72_bootstrap, 97.5)\n",
    "\n",
    "print(f\"\\nPearson r = {pearson_72:.3f} (95% CI: {pearson_72_ci_lower:.3f} to {pearson_72_ci_upper:.3f})\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 2. C-INDEX (HARRELL'S CONCORDANCE INDEX)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"2. C-INDEX (HARRELL'S CONCORDANCE INDEX)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "c_index_72 = concordance_index(\n",
    "    df_72h['diuretic_efficiency_72h'],\n",
    "    -df_72h['ban_adhf_total_score'],\n",
    "    np.ones(len(df_72h))\n",
    ")\n",
    "\n",
    "# Bootstrap 95% CI\n",
    "c_index_72_bootstrap = []\n",
    "for _ in range(n_bootstrap):\n",
    "    idx = np.random.choice(len(df_72h), size=len(df_72h), replace=True)\n",
    "    sample = df_72h.iloc[idx]\n",
    "    c = concordance_index(\n",
    "        sample['diuretic_efficiency_72h'],\n",
    "        -sample['ban_adhf_total_score'],\n",
    "        np.ones(len(sample))\n",
    "    )\n",
    "    c_index_72_bootstrap.append(c)\n",
    "\n",
    "c_index_72_ci_lower = np.percentile(c_index_72_bootstrap, 2.5)\n",
    "c_index_72_ci_upper = np.percentile(c_index_72_bootstrap, 97.5)\n",
    "\n",
    "print(f\"\\nC-index = {c_index_72:.3f} (95% CI: {c_index_72_ci_lower:.3f} to {c_index_72_ci_upper:.3f})\")\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "if c_index_72 >= 0.7:\n",
    "    print(f\"  Good discrimination (C-index \u2265 0.7)\")\n",
    "elif c_index_72 >= 0.6:\n",
    "    print(f\"  Moderate discrimination (C-index 0.6-0.7)\")\n",
    "else:\n",
    "    print(f\"  Poor discrimination (C-index < 0.6)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 3. AUROC FOR LOWEST QUINTILE (Bottom 20%)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"3. AUROC FOR LOWEST QUINTILE OF 72H EFFICIENCY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "quintile_72_threshold = df_72h['diuretic_efficiency_72h'].quantile(0.20)\n",
    "df_72h['lowest_quintile_72'] = (df_72h['diuretic_efficiency_72h'] <= quintile_72_threshold).astype(int)\n",
    "\n",
    "n_quintile_72 = df_72h['lowest_quintile_72'].sum()\n",
    "print(f\"Threshold: \u2264{quintile_72_threshold:.1f} mL/mg (20th percentile)\")\n",
    "print(f\"Patients in lowest quintile: {n_quintile_72} ({100*n_quintile_72/len(df_72h):.1f}%)\")\n",
    "\n",
    "auroc_quintile_72 = roc_auc_score(df_72h['lowest_quintile_72'], df_72h['ban_adhf_total_score'])\n",
    "\n",
    "# Bootstrap 95% CI\n",
    "auroc_q72_bootstrap = []\n",
    "for _ in range(n_bootstrap):\n",
    "    idx = np.random.choice(len(df_72h), size=len(df_72h), replace=True)\n",
    "    sample = df_72h.iloc[idx]\n",
    "    if sample['lowest_quintile_72'].sum() > 0 and sample['lowest_quintile_72'].sum() < len(sample):\n",
    "        auc = roc_auc_score(sample['lowest_quintile_72'], sample['ban_adhf_total_score'])\n",
    "        auroc_q72_bootstrap.append(auc)\n",
    "\n",
    "auroc_q72_ci_lower = np.percentile(auroc_q72_bootstrap, 2.5)\n",
    "auroc_q72_ci_upper = np.percentile(auroc_q72_bootstrap, 97.5)\n",
    "\n",
    "print(f\"\\nAUROC = {auroc_quintile_72:.3f} (95% CI: {auroc_q72_ci_lower:.3f} to {auroc_q72_ci_upper:.3f})\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 4. AUROC FOR LOWEST QUARTILE (Bottom 25%)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"4. AUROC FOR LOWEST QUARTILE OF 72H EFFICIENCY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "quartile_72_threshold = df_72h['diuretic_efficiency_72h'].quantile(0.25)\n",
    "df_72h['lowest_quartile_72'] = (df_72h['diuretic_efficiency_72h'] <= quartile_72_threshold).astype(int)\n",
    "\n",
    "n_quartile_72 = df_72h['lowest_quartile_72'].sum()\n",
    "print(f\"Threshold: \u2264{quartile_72_threshold:.1f} mL/mg (25th percentile)\")\n",
    "print(f\"Patients in lowest quartile: {n_quartile_72} ({100*n_quartile_72/len(df_72h):.1f}%)\")\n",
    "\n",
    "auroc_quartile_72 = roc_auc_score(df_72h['lowest_quartile_72'], df_72h['ban_adhf_total_score'])\n",
    "\n",
    "# Bootstrap 95% CI\n",
    "auroc_qt72_bootstrap = []\n",
    "for _ in range(n_bootstrap):\n",
    "    idx = np.random.choice(len(df_72h), size=len(df_72h), replace=True)\n",
    "    sample = df_72h.iloc[idx]\n",
    "    if sample['lowest_quartile_72'].sum() > 0 and sample['lowest_quartile_72'].sum() < len(sample):\n",
    "        auc = roc_auc_score(sample['lowest_quartile_72'], sample['ban_adhf_total_score'])\n",
    "        auroc_qt72_bootstrap.append(auc)\n",
    "\n",
    "auroc_qt72_ci_lower = np.percentile(auroc_qt72_bootstrap, 2.5)\n",
    "auroc_qt72_ci_upper = np.percentile(auroc_qt72_bootstrap, 97.5)\n",
    "\n",
    "print(f\"\\nAUROC = {auroc_quartile_72:.3f} (95% CI: {auroc_qt72_ci_lower:.3f} to {auroc_qt72_ci_upper:.3f})\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 5. EFFICIENCY BY RISK CATEGORY\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"5. 72H DIURETIC EFFICIENCY BY RISK CATEGORY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'Risk Category':<15} {'N':<8} {'Median (IQR)':<25} {'Mean \u00b1 SD':<20}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "median_72_by_risk = {}\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    subset = df_72h[df_72h['risk_category'] == cat]['diuretic_efficiency_72h']\n",
    "    n = len(subset)\n",
    "    median = subset.median()\n",
    "    q1 = subset.quantile(0.25)\n",
    "    q3 = subset.quantile(0.75)\n",
    "    mean = subset.mean()\n",
    "    std = subset.std()\n",
    "    median_72_by_risk[cat] = median\n",
    "    print(f\"{cat:<15} {n:<8} {median:.1f} ({q1:.1f}-{q3:.1f}){'':>8} {mean:.1f} \u00b1 {std:.1f}\")\n",
    "\n",
    "# Kruskal-Wallis test\n",
    "groups_72 = [df_72h[df_72h['risk_category'] == cat]['diuretic_efficiency_72h'].values\n",
    "             for cat in ['Low', 'Moderate', 'High']]\n",
    "kw_stat_72, kw_p_72 = kruskal(*groups_72)\n",
    "print(f\"\\nKruskal-Wallis H = {kw_stat_72:.1f}, p < 0.001\" if kw_p_72 < 0.001 else f\"\\nKruskal-Wallis H = {kw_stat_72:.1f}, p = {kw_p_72:.3f}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# COMPARISON: 24H vs 72H EFFICIENCY (Using stored results)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON: 24-HOUR vs 72-HOUR DIURETIC EFFICIENCY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check if results_24h exists, otherwise use placeholders\n",
    "if 'results_24h' in dir():\n",
    "    r24 = results_24h\n",
    "    print(f\"\"\"\n",
    "Metric                      24-Hour (N={r24['n']:,})       72-Hour (N={len(df_72h):,})\n",
    "--------------------------------------------------------------------------------\n",
    "Spearman \u03c1                  {r24['spearman_rho']:.3f}                  {rho_72:.3f}\n",
    "Pearson r                   {r24['pearson_r']:.3f}                  {pearson_72:.3f}\n",
    "C-index                     {r24['c_index']:.3f}                  {c_index_72:.3f}\n",
    "AUROC (quintile)            {r24['auroc_quintile']:.3f}                  {auroc_quintile_72:.3f}\n",
    "AUROC (quartile)            {r24['auroc_quartile']:.3f}                  {auroc_quartile_72:.3f}\n",
    "\n",
    "Efficiency by Risk:\n",
    "  Low risk median           {r24['median_by_risk']['Low']:.1f} mL/mg              {median_72_by_risk['Low']:.1f} mL/mg\n",
    "  Moderate median           {r24['median_by_risk']['Moderate']:.1f} mL/mg              {median_72_by_risk['Moderate']:.1f} mL/mg\n",
    "  High risk median          {r24['median_by_risk']['High']:.1f} mL/mg              {median_72_by_risk['High']:.1f} mL/mg\n",
    "\"\"\")\n",
    "else:\n",
    "    print(\"\\n\u26a0 results_24h not found - run Cell 9 storage snippet first\")\n",
    "    print(\"Showing 72h results only:\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# STORE 72H RESULTS\n",
    "#------------------------------------------------------------------------------\n",
    "results_72h = {\n",
    "    'n': len(df_72h),\n",
    "    'spearman_rho': rho_72,\n",
    "    'spearman_ci': (rho_72_ci_lower, rho_72_ci_upper),\n",
    "    'pearson_r': pearson_72,\n",
    "    'pearson_ci': (pearson_72_ci_lower, pearson_72_ci_upper),\n",
    "    'c_index': c_index_72,\n",
    "    'c_index_ci': (c_index_72_ci_lower, c_index_72_ci_upper),\n",
    "    'auroc_quintile': auroc_quintile_72,\n",
    "    'auroc_quintile_ci': (auroc_q72_ci_lower, auroc_q72_ci_upper),\n",
    "    'auroc_quartile': auroc_quartile_72,\n",
    "    'auroc_quartile_ci': (auroc_qt72_ci_lower, auroc_qt72_ci_upper),\n",
    "    'quintile_threshold': quintile_72_threshold,\n",
    "    'quartile_threshold': quartile_72_threshold,\n",
    "    'median_by_risk': median_72_by_risk\n",
    "}\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# SUMMARY TABLE\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"=\"*70)\n",
    "print(\"SUMMARY: 72-HOUR DIURETIC EFFICIENCY DISCRIMINATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "Metric                              Value           95% CI\n",
    "--------------------------------------------------------------------------------\n",
    "Spearman \u03c1                          {rho_72:.3f}          ({rho_72_ci_lower:.3f} to {rho_72_ci_upper:.3f})\n",
    "Pearson r                           {pearson_72:.3f}          ({pearson_72_ci_lower:.3f} to {pearson_72_ci_upper:.3f})\n",
    "C-index                             {c_index_72:.3f}          ({c_index_72_ci_lower:.3f} to {c_index_72_ci_upper:.3f})\n",
    "AUROC (lowest quintile)             {auroc_quintile_72:.3f}          ({auroc_q72_ci_lower:.3f} to {auroc_q72_ci_upper:.3f})\n",
    "AUROC (lowest quartile)             {auroc_quartile_72:.3f}          ({auroc_qt72_ci_lower:.3f} to {auroc_qt72_ci_upper:.3f})\n",
    "\"\"\")\n",
    "\n",
    "# Determine comparison\n",
    "if 'results_24h' in dir():\n",
    "    rho_diff = rho_72 - r24['spearman_rho']\n",
    "    comparison = 'comparable' if abs(rho_diff) < 0.03 else ('weaker' if rho_diff > 0 else 'stronger')\n",
    "    print(f\"Key Finding: 72-hour efficiency (original derivation endpoint) shows\")\n",
    "    print(f\"{comparison} discrimination compared to 24-hour efficiency (\u0394\u03c1 = {rho_diff:+.3f})\")\n",
    "\n",
    "print(\"\\n\u2713 72h efficiency results stored in 'results_72h' dictionary\")\n",
    "print(\"\\n\u2192 Next: Diuretic Resistance Analysis (Binary Outcome)\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# SECTION 6: DIURETIC RESISTANCE ANALYSIS\n",
    "# Cell 11: Binary Diuretic Resistance (Urine Output \u22643,000 mL)\n",
    "#==========================================================================\n",
    "# PURPOSE: Evaluate BAN-ADHF score's ability to predict binary DR\n",
    "# POPULATION: N=1,382 (ICU \u226524h)\n",
    "# DEFINITION: Urine output \u22643,000 mL in first 24 hours\n",
    "# METRICS: AUROC, sensitivity/specificity, DR rates by risk category\n",
    "# OUTPUT: Binary outcome discrimination statistics\n",
    "#==========================================================================\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DIURETIC RESISTANCE ANALYSIS (BINARY OUTCOME)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nDefinition: Urine output \u22643,000 mL in first 24 hours of ICU stay\")\n",
    "print(\"This is a SECONDARY outcome (BAN-ADHF was designed for efficiency,\")\n",
    "print(\"not binary resistance).\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# ANALYSIS COHORT\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ANALYSIS COHORT\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# ICU \u226524h cohort for DR analysis\n",
    "df_dr = df[df['icu_stay_ge_24h'] == 1].copy()\n",
    "\n",
    "print(f\"Population: ICU stay \u226524 hours\")\n",
    "print(f\"N = {len(df_dr):,}\")\n",
    "\n",
    "# Verify DR definition\n",
    "df_dr['diuretic_resistance'] = pd.to_numeric(df_dr['diuretic_resistance'], errors='coerce')\n",
    "n_dr = df_dr['diuretic_resistance'].sum()\n",
    "dr_prevalence = 100 * n_dr / len(df_dr)\n",
    "\n",
    "print(f\"\\nDiuretic Resistance:\")\n",
    "print(f\"  Resistant (\u22643L):     {int(n_dr):,} ({dr_prevalence:.1f}%)\")\n",
    "print(f\"  Not resistant (>3L): {len(df_dr) - int(n_dr):,} ({100-dr_prevalence:.1f}%)\")\n",
    "\n",
    "print(f\"\\nNote: DR prevalence ({dr_prevalence:.1f}%) is much higher than derivation\")\n",
    "print(f\"cohorts (~25%) due to ICU population severity.\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# BOOTSTRAP SETUP\n",
    "#------------------------------------------------------------------------------\n",
    "np.random.seed(42)\n",
    "n_bootstrap = 1000\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 1. AUROC FOR DIURETIC RESISTANCE\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"1. AUROC FOR DIURETIC RESISTANCE PREDICTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "auroc_dr = roc_auc_score(df_dr['diuretic_resistance'], df_dr['ban_adhf_total_score'])\n",
    "\n",
    "# Bootstrap 95% CI\n",
    "auroc_dr_bootstrap = []\n",
    "for _ in range(n_bootstrap):\n",
    "    idx = np.random.choice(len(df_dr), size=len(df_dr), replace=True)\n",
    "    sample = df_dr.iloc[idx]\n",
    "    if sample['diuretic_resistance'].sum() > 0 and sample['diuretic_resistance'].sum() < len(sample):\n",
    "        auc = roc_auc_score(sample['diuretic_resistance'], sample['ban_adhf_total_score'])\n",
    "        auroc_dr_bootstrap.append(auc)\n",
    "\n",
    "auroc_dr_ci_lower = np.percentile(auroc_dr_bootstrap, 2.5)\n",
    "auroc_dr_ci_upper = np.percentile(auroc_dr_bootstrap, 97.5)\n",
    "\n",
    "print(f\"\\nAUROC = {auroc_dr:.3f} (95% CI: {auroc_dr_ci_lower:.3f} to {auroc_dr_ci_upper:.3f})\")\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "if auroc_dr >= 0.7:\n",
    "    print(f\"  Good discrimination (AUROC \u2265 0.7)\")\n",
    "elif auroc_dr >= 0.6:\n",
    "    print(f\"  Moderate discrimination (AUROC 0.6-0.7)\")\n",
    "else:\n",
    "    print(f\"  Poor discrimination (AUROC < 0.6)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 2. OPTIMAL CUTOFF (YOUDEN'S INDEX)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"2. OPTIMAL CUTOFF FOR DIURETIC RESISTANCE (YOUDEN'S INDEX)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(df_dr['diuretic_resistance'],\n",
    "                                  df_dr['ban_adhf_total_score'])\n",
    "\n",
    "# Youden's J = Sensitivity + Specificity - 1\n",
    "youden_j = tpr - fpr\n",
    "optimal_idx = np.argmax(youden_j)\n",
    "optimal_cutoff = thresholds[optimal_idx]\n",
    "optimal_sensitivity = tpr[optimal_idx]\n",
    "optimal_specificity = 1 - fpr[optimal_idx]\n",
    "\n",
    "print(f\"\\nOptimal cutoff: \u2265{optimal_cutoff:.0f}\")\n",
    "print(f\"Sensitivity: {optimal_sensitivity:.3f} ({optimal_sensitivity*100:.1f}%)\")\n",
    "print(f\"Specificity: {optimal_specificity:.3f} ({optimal_specificity*100:.1f}%)\")\n",
    "print(f\"Youden's J: {youden_j[optimal_idx]:.3f}\")\n",
    "\n",
    "# Compare to our high-risk threshold (\u226513)\n",
    "idx_13 = np.argmin(np.abs(thresholds - 13))\n",
    "sens_13 = tpr[idx_13]\n",
    "spec_13 = 1 - fpr[idx_13]\n",
    "print(f\"\\nAt our high-risk threshold (\u226513):\")\n",
    "print(f\"  Sensitivity: {sens_13:.3f} ({sens_13*100:.1f}%)\")\n",
    "print(f\"  Specificity: {spec_13:.3f} ({spec_13*100:.1f}%)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 3. DIURETIC RESISTANCE BY RISK CATEGORY\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"3. DIURETIC RESISTANCE BY RISK CATEGORY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'Risk Category':<15} {'N':<8} {'DR n (%)':<20} {'No DR n (%)':<20}\")\n",
    "print(\"-\"*65)\n",
    "\n",
    "dr_by_risk = {}\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    subset = df_dr[df_dr['risk_category'] == cat]\n",
    "    n = len(subset)\n",
    "    n_dr_cat = int(subset['diuretic_resistance'].sum())\n",
    "    dr_rate = 100 * n_dr_cat / n if n > 0 else 0\n",
    "    dr_by_risk[cat] = {'n': n, 'n_dr': n_dr_cat, 'rate': dr_rate}\n",
    "    print(f\"{cat:<15} {n:<8} {n_dr_cat} ({dr_rate:.1f}%){'':>8} {n - n_dr_cat} ({100-dr_rate:.1f}%)\")\n",
    "\n",
    "# Chi-square test\n",
    "contingency = pd.crosstab(df_dr['risk_category'], df_dr['diuretic_resistance'])\n",
    "chi2, p_chi, dof, expected = chi2_contingency(contingency)\n",
    "print(f\"\\nChi-square = {chi2:.1f}, p < 0.001\" if p_chi < 0.001 else f\"\\nChi-square = {chi2:.1f}, p = {p_chi:.3f}\")\n",
    "\n",
    "# Risk ratios\n",
    "low_rate = dr_by_risk['Low']['rate']\n",
    "high_rate = dr_by_risk['High']['rate']\n",
    "if low_rate > 0:\n",
    "    rr_high_vs_low = high_rate / low_rate\n",
    "    print(f\"\\nRisk ratio (High vs Low): {rr_high_vs_low:.2f}\")\n",
    "    print(f\"  High-risk patients are {rr_high_vs_low:.1f}x more likely to have DR\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 4. SENSITIVITY ANALYSIS: DR THRESHOLD VARIATIONS\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"4. SENSITIVITY ANALYSIS: ALTERNATIVE DR DEFINITIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test different urine output thresholds\n",
    "print(\"\\nAUROC by different DR threshold definitions:\")\n",
    "print(f\"{'Threshold':<20} {'N with DR':<15} {'Prevalence':<15} {'AUROC':<15}\")\n",
    "print(\"-\"*65)\n",
    "\n",
    "for threshold in [2000, 2500, 3000, 3500, 4000]:\n",
    "    dr_alt = (df_dr['urine_output_24h_ml'] <= threshold).astype(int)\n",
    "    n_dr_alt = dr_alt.sum()\n",
    "    prev_alt = 100 * n_dr_alt / len(df_dr)\n",
    "    if n_dr_alt > 0 and n_dr_alt < len(df_dr):\n",
    "        auroc_alt = roc_auc_score(dr_alt, df_dr['ban_adhf_total_score'])\n",
    "        print(f\"\u2264{threshold} mL{'':<12} {n_dr_alt:<15} {prev_alt:.1f}%{'':>8} {auroc_alt:.3f}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 5. COMPARISON WITH EFFICIENCY METRICS\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"5. COMPARISON: BINARY DR vs CONTINUOUS EFFICIENCY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if 'results_24h' in dir():\n",
    "    print(f\"\"\"\n",
    "Outcome                         AUROC           Notes\n",
    "--------------------------------------------------------------------------------\n",
    "24h Efficiency (quintile)       {results_24h['auroc_quintile']:.3f}          Bottom 20% of efficiency\n",
    "24h Efficiency (quartile)       {results_24h['auroc_quartile']:.3f}          Bottom 25% of efficiency\n",
    "Binary DR (\u22643L)                 {auroc_dr:.3f}          Urine \u22643,000 mL\n",
    "\n",
    "Key Observation:\n",
    "Binary DR shows {'comparable' if abs(auroc_dr - results_24h['auroc_quintile']) < 0.05 else 'lower'}\n",
    "discrimination compared to efficiency quintile/quartile outcomes.\n",
    "This is expected as binary outcomes lose information compared to continuous.\n",
    "\"\"\")\n",
    "else:\n",
    "    print(f\"\\nBinary DR AUROC: {auroc_dr:.3f}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# STORE RESULTS\n",
    "#------------------------------------------------------------------------------\n",
    "results_dr = {\n",
    "    'n': len(df_dr),\n",
    "    'n_dr': int(n_dr),\n",
    "    'prevalence': dr_prevalence,\n",
    "    'auroc': auroc_dr,\n",
    "    'auroc_ci': (auroc_dr_ci_lower, auroc_dr_ci_upper),\n",
    "    'optimal_cutoff': optimal_cutoff,\n",
    "    'optimal_sensitivity': optimal_sensitivity,\n",
    "    'optimal_specificity': optimal_specificity,\n",
    "    'dr_by_risk': dr_by_risk\n",
    "}\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# SUMMARY\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY: DIURETIC RESISTANCE DISCRIMINATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "Population: ICU \u226524h (N = {len(df_dr):,})\n",
    "DR Definition: Urine output \u22643,000 mL in first 24 hours\n",
    "DR Prevalence: {dr_prevalence:.1f}% (higher than derivation cohorts due to ICU severity)\n",
    "\n",
    "Discrimination:\n",
    "  AUROC = {auroc_dr:.3f} (95% CI: {auroc_dr_ci_lower:.3f} to {auroc_dr_ci_upper:.3f})\n",
    "\n",
    "Optimal Cutoff (Youden):\n",
    "  Score \u2265{optimal_cutoff:.0f}\n",
    "  Sensitivity: {optimal_sensitivity*100:.1f}%\n",
    "  Specificity: {optimal_specificity*100:.1f}%\n",
    "\n",
    "DR Rates by Risk Category:\n",
    "  Low risk (\u22647):      {dr_by_risk['Low']['rate']:.1f}%\n",
    "  Moderate (8-12):    {dr_by_risk['Moderate']['rate']:.1f}%\n",
    "  High risk (\u226513):    {dr_by_risk['High']['rate']:.1f}%\n",
    "\n",
    "Risk Ratio (High vs Low): {rr_high_vs_low:.2f}x\n",
    "\"\"\")\n",
    "\n",
    "print(\"\u2713 DR results stored in 'results_dr' dictionary\")\n",
    "print(\"\\n\u2192 Next: Co-Primary Outcome 3 - In-Hospital Mortality (Exploratory)\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Make a SAFE AUROC summary for 24h efficiency (so it can't be overwritten)\n",
    "results_24h_auc = {\n",
    "    \"n\": int(len(df_24h)),\n",
    "    \"auroc_q20\": float(auroc_quintile),\n",
    "    \"auroc_q25\": float(auroc_quartile),\n",
    "    \"auroc_q20_ci\": (float(auroc_q_ci_lower), float(auroc_q_ci_upper)),\n",
    "    \"auroc_q25_ci\": (float(auroc_qt_ci_lower), float(auroc_qt_ci_upper)),\n",
    "}\n",
    "\n",
    "print(\"\u2713 results_24h_auc created\")\n",
    "print(results_24h_auc)\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# SECTION 7: CO-PRIMARY OUTCOME 3 - IN-HOSPITAL MORTALITY (EXPLORATORY)\n",
    "# Cell 12: Mortality Discrimination Analysis (CORRECTED)\n",
    "#==========================================================================\n",
    "# PURPOSE: Exploratory assessment of BAN-ADHF score association with in-hospital\n",
    "#          mortality (note: score developed for diuretic efficiency, not mortality)\n",
    "# POPULATION: N = 1,505 (Full cohort)\n",
    "# IMPORTANT: This mortality analysis is EXPLORATORY and represents an extension\n",
    "#            of the score to a different outcome domain.\n",
    "# METRICS:\n",
    "#   - Discrimination: AUROC with 95% CI by bootstrap resampling (1,000 iterations)\n",
    "#   - Secondary discrimination: AUPRC with 95% CI by bootstrap resampling\n",
    "#   - Exploratory cutoff: Youden's index and comparison to prespecified threshold (\u226513)\n",
    "#   - Risk stratification: Mortality rates by predefined risk category + chi-square test\n",
    "#   - Subgroups: AUROC (bootstrap CI) in cardiogenic shock vs no cardiogenic shock\n",
    "#   - Comparison table: uses results_24h_auc (Q20/Q25) + results_dr (binary DR) if present\n",
    "# OUTPUT: Exploratory mortality discrimination statistics\n",
    "#==========================================================================\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, average_precision_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CO-PRIMARY OUTCOME 3: IN-HOSPITAL MORTALITY (EXPLORATORY)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n\" + \"*\"*70)\n",
    "print(\"IMPORTANT: BAN-ADHF was designed for DIURETIC EFFICIENCY prediction,\")\n",
    "print(\"NOT mortality. This mortality analysis is EXPLORATORY and represents\")\n",
    "print(\"a novel extension of the score to a different outcome domain.\")\n",
    "print(\"*\"*70)\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# ANALYSIS COHORT\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ANALYSIS COHORT\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "df_mort = df.copy()\n",
    "\n",
    "n_total = len(df_mort)\n",
    "n_deaths = int(df_mort['hospital_expire_flag'].sum())\n",
    "mortality_rate = 100 * n_deaths / n_total\n",
    "\n",
    "print(\"Population: Full ICU ADHF cohort\")\n",
    "print(f\"N = {n_total:,}\")\n",
    "print(\"\\nIn-Hospital Mortality:\")\n",
    "print(f\"  Deaths:    {n_deaths} ({mortality_rate:.1f}%)\")\n",
    "print(f\"  Survivors: {n_total - n_deaths} ({100-mortality_rate:.1f}%)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# BOOTSTRAP SETUP\n",
    "#------------------------------------------------------------------------------\n",
    "np.random.seed(42)\n",
    "n_bootstrap = 1000\n",
    "\n",
    "def bootstrap_metric_ci(df_in, y_col, s_col, metric_fn, n_boot=1000):\n",
    "    \"\"\"\n",
    "    Bootstrap 95% CI for a metric that requires both classes present.\n",
    "    Returns: (point_estimate, ci_low, ci_high, n_valid_boot)\n",
    "    \"\"\"\n",
    "    y = df_in[y_col].values\n",
    "    s = df_in[s_col].values\n",
    "\n",
    "    point = metric_fn(y, s)\n",
    "\n",
    "    boot_vals = []\n",
    "    for _ in range(n_boot):\n",
    "        idx = np.random.choice(len(df_in), size=len(df_in), replace=True)\n",
    "        sample = df_in.iloc[idx]\n",
    "        if sample[y_col].nunique() < 2:\n",
    "            continue\n",
    "        boot_vals.append(metric_fn(sample[y_col].values, sample[s_col].values))\n",
    "\n",
    "    if len(boot_vals) < 50:\n",
    "        raise ValueError(\n",
    "            f\"Too few valid bootstrap resamples ({len(boot_vals)}/{n_boot}). \"\n",
    "            \"Event rate may be too low for stable bootstrap CI.\"\n",
    "        )\n",
    "\n",
    "    ci_low, ci_high = np.percentile(boot_vals, [2.5, 97.5])\n",
    "    return point, ci_low, ci_high, len(boot_vals)\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 1. DISCRIMINATION FOR MORTALITY: AUROC + AUPRC (EXPLORATORY)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"1. DISCRIMINATION FOR IN-HOSPITAL MORTALITY (EXPLORATORY)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# AUROC with bootstrap CI\n",
    "auroc_mort, auroc_mort_ci_lower, auroc_mort_ci_upper, n_valid_auc = bootstrap_metric_ci(\n",
    "    df_mort,\n",
    "    y_col='hospital_expire_flag',\n",
    "    s_col='ban_adhf_total_score',\n",
    "    metric_fn=roc_auc_score,\n",
    "    n_boot=n_bootstrap\n",
    ")\n",
    "\n",
    "print(f\"\\nAUROC = {auroc_mort:.3f} (95% CI: {auroc_mort_ci_lower:.3f} to {auroc_mort_ci_upper:.3f})\")\n",
    "print(f\"  Bootstrap resamples used: {n_valid_auc}/{n_bootstrap}\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "if auroc_mort >= 0.7:\n",
    "    print(\"  Moderate-good discrimination (AUROC \u2265 0.7)\")\n",
    "elif auroc_mort >= 0.6:\n",
    "    print(\"  Poor-moderate discrimination (AUROC 0.6-0.7)\")\n",
    "else:\n",
    "    print(\"  Poor discrimination (AUROC < 0.6)\")\n",
    "\n",
    "print(\"\\nContext: This is limited for a score\")\n",
    "print(\"not designed for mortality prediction.\")\n",
    "\n",
    "# AUPRC with bootstrap CI (helpful when outcome is imbalanced)\n",
    "auprc_mort, auprc_ci_lower, auprc_ci_upper, n_valid_pr = bootstrap_metric_ci(\n",
    "    df_mort,\n",
    "    y_col='hospital_expire_flag',\n",
    "    s_col='ban_adhf_total_score',\n",
    "    metric_fn=average_precision_score,\n",
    "    n_boot=n_bootstrap\n",
    ")\n",
    "\n",
    "print(f\"\\nAUPRC = {auprc_mort:.3f} (95% CI: {auprc_ci_lower:.3f} to {auprc_ci_upper:.3f})\")\n",
    "print(f\"  Bootstrap resamples used: {n_valid_pr}/{n_bootstrap}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 2. EXPLORATORY CUTOFF (YOUDEN'S INDEX) + COMPARISON TO PRE-SPECIFIED THRESHOLD\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"2. EXPLORATORY CUTOFF FOR MORTALITY (YOUDEN'S INDEX)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fpr_m, tpr_m, thresholds_m = roc_curve(\n",
    "    df_mort['hospital_expire_flag'],\n",
    "    df_mort['ban_adhf_total_score']\n",
    ")\n",
    "\n",
    "youden_j_m = tpr_m - fpr_m\n",
    "optimal_idx_m = int(np.argmax(youden_j_m))\n",
    "optimal_cutoff_m = thresholds_m[optimal_idx_m]\n",
    "optimal_sens_m = tpr_m[optimal_idx_m]\n",
    "optimal_spec_m = 1 - fpr_m[optimal_idx_m]\n",
    "\n",
    "print(\"\\nExploratory (Youden-based) cutoff:\")\n",
    "print(f\"  Cutoff: \u2265{optimal_cutoff_m:.0f}\")\n",
    "print(f\"  Sensitivity: {optimal_sens_m:.3f} ({optimal_sens_m*100:.1f}%)\")\n",
    "print(f\"  Specificity: {optimal_spec_m:.3f} ({optimal_spec_m*100:.1f}%)\")\n",
    "print(f\"  Youden's J: {youden_j_m[optimal_idx_m]:.3f}\")\n",
    "\n",
    "# Comparison to prespecified high-risk threshold (\u226513)\n",
    "idx_13_m = int(np.argmin(np.abs(thresholds_m - 13)))\n",
    "sens_13_m = tpr_m[idx_13_m]\n",
    "spec_13_m = 1 - fpr_m[idx_13_m]\n",
    "\n",
    "print(\"\\nComparison to prespecified high-risk threshold (\u226513):\")\n",
    "print(f\"  Sensitivity: {sens_13_m:.3f} ({sens_13_m*100:.1f}%)\")\n",
    "print(f\"  Specificity: {spec_13_m:.3f} ({spec_13_m*100:.1f}%)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 3. MORTALITY BY PREDEFINED RISK CATEGORY\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"3. MORTALITY BY RISK CATEGORY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'Risk Category':<15} {'N':<8} {'Deaths n (%)':<20} {'Survivors n (%)':<20}\")\n",
    "print(\"-\"*65)\n",
    "\n",
    "mort_by_risk = {}\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    subset = df_mort[df_mort['risk_category'] == cat]\n",
    "    n = len(subset)\n",
    "    n_deaths_cat = int(subset['hospital_expire_flag'].sum())\n",
    "    mort_rate = 100 * n_deaths_cat / n if n > 0 else 0.0\n",
    "    mort_by_risk[cat] = {'n': n, 'n_deaths': n_deaths_cat, 'rate': mort_rate}\n",
    "    print(f\"{cat:<15} {n:<8} {n_deaths_cat} ({mort_rate:.1f}%){'':>9} {n - n_deaths_cat} ({100-mort_rate:.1f}%)\")\n",
    "\n",
    "# Chi-square test\n",
    "contingency_m = pd.crosstab(df_mort['risk_category'], df_mort['hospital_expire_flag'])\n",
    "chi2_m, p_chi_m, dof_m, expected_m = chi2_contingency(contingency_m)\n",
    "print(\"\\n\" + (f\"Chi-square = {chi2_m:.1f}, p < 0.001\" if p_chi_m < 0.001 else f\"Chi-square = {chi2_m:.1f}, p = {p_chi_m:.3f}\"))\n",
    "\n",
    "# Risk ratio + absolute risk increase\n",
    "low_mort = mort_by_risk['Low']['rate']\n",
    "high_mort = mort_by_risk['High']['rate']\n",
    "\n",
    "rr_mort = np.nan\n",
    "if low_mort > 0:\n",
    "    rr_mort = high_mort / low_mort\n",
    "    print(f\"\\nRisk ratio (High vs Low): {rr_mort:.2f}\")\n",
    "    print(f\"  High-risk patients have {rr_mort:.1f}x higher mortality\")\n",
    "\n",
    "ari = high_mort - low_mort\n",
    "print(f\"Absolute risk increase: {ari:.1f} percentage points\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 4. CARDIOGENIC SHOCK SUBGROUP (PRE-SPECIFIED)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"4. MORTALITY DISCRIMINATION IN CARDIOGENIC SHOCK SUBGROUP\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_cs = df_mort[df_mort['cardiogenic_shock'] == 1].copy()\n",
    "df_no_cs = df_mort[df_mort['cardiogenic_shock'] == 0].copy()\n",
    "\n",
    "print(f\"\\nCardiogenic Shock (N = {len(df_cs):,}):\")\n",
    "print(f\"  Mortality rate: {100*df_cs['hospital_expire_flag'].mean():.1f}%\")\n",
    "\n",
    "if df_cs['hospital_expire_flag'].sum() > 10 and df_cs['hospital_expire_flag'].nunique() == 2:\n",
    "    auroc_cs, auroc_cs_ci_lower, auroc_cs_ci_upper, n_valid_cs = bootstrap_metric_ci(\n",
    "        df_cs,\n",
    "        y_col='hospital_expire_flag',\n",
    "        s_col='ban_adhf_total_score',\n",
    "        metric_fn=roc_auc_score,\n",
    "        n_boot=n_bootstrap\n",
    "    )\n",
    "    print(f\"  AUROC = {auroc_cs:.3f} (95% CI: {auroc_cs_ci_lower:.3f} to {auroc_cs_ci_upper:.3f})\")\n",
    "    print(f\"  Bootstrap resamples used: {n_valid_cs}/{n_bootstrap}\")\n",
    "else:\n",
    "    auroc_cs = None\n",
    "    auroc_cs_ci_lower, auroc_cs_ci_upper = (None, None)\n",
    "    print(\"  AUROC: Insufficient events for analysis\")\n",
    "\n",
    "print(f\"\\nNo Cardiogenic Shock (N = {len(df_no_cs):,}):\")\n",
    "print(f\"  Mortality rate: {100*df_no_cs['hospital_expire_flag'].mean():.1f}%\")\n",
    "\n",
    "if df_no_cs['hospital_expire_flag'].sum() > 10 and df_no_cs['hospital_expire_flag'].nunique() == 2:\n",
    "    auroc_no_cs, auroc_no_cs_ci_lower, auroc_no_cs_ci_upper, n_valid_no_cs = bootstrap_metric_ci(\n",
    "        df_no_cs,\n",
    "        y_col='hospital_expire_flag',\n",
    "        s_col='ban_adhf_total_score',\n",
    "        metric_fn=roc_auc_score,\n",
    "        n_boot=n_bootstrap\n",
    "    )\n",
    "    print(f\"  AUROC = {auroc_no_cs:.3f} (95% CI: {auroc_no_cs_ci_lower:.3f} to {auroc_no_cs_ci_upper:.3f})\")\n",
    "    print(f\"  Bootstrap resamples used: {n_valid_no_cs}/{n_bootstrap}\")\n",
    "else:\n",
    "    auroc_no_cs = None\n",
    "    auroc_no_cs_ci_lower, auroc_no_cs_ci_upper = (None, None)\n",
    "\n",
    "if auroc_cs is not None and auroc_no_cs is not None:\n",
    "    auroc_diff = auroc_cs - auroc_no_cs\n",
    "    print(f\"\\nDifference (CS - No CS): {auroc_diff:+.3f}\")\n",
    "    print(\"\u2192 BAN-ADHF shows better mortality discrimination in cardiogenic shock patients\" if auroc_diff > 0\n",
    "          else \"\u2192 BAN-ADHF shows worse mortality discrimination in cardiogenic shock patients\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 5. COMPARISON: MORTALITY vs DIURETIC EFFICIENCY OUTCOMES\n",
    "#    Uses results_24h_auc (Q20/Q25) and results_dr if they exist.\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"5. COMPARISON: MORTALITY vs DIURETIC EFFICIENCY OUTCOMES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "has_24h_auc = 'results_24h_auc' in globals() and isinstance(results_24h_auc, dict)\n",
    "has_dr = 'results_dr' in globals() and isinstance(results_dr, dict)\n",
    "\n",
    "if has_24h_auc and has_dr and ('auroc' in results_dr):\n",
    "    print(f\"\"\"\n",
    "Outcome                         AUROC           Population      Purpose\n",
    "--------------------------------------------------------------------------------\n",
    "24h Efficiency (Q20)            {results_24h_auc['auroc_q20']:.3f}          N={results_24h_auc['n']:,}        Score's intended use\n",
    "24h Efficiency (Q25)            {results_24h_auc['auroc_q25']:.3f}          N={results_24h_auc['n']:,}        Score's intended use\n",
    "Binary DR (\u22643L)                 {results_dr['auroc']:.3f}          N={results_dr['n']:,}        Secondary outcome\n",
    "In-hospital mortality           {auroc_mort:.3f}          N={n_total:,}        EXPLORATORY\n",
    "  - Cardiogenic shock           {auroc_cs:.3f}          N={len(df_cs):,}        Subgroup\n",
    "  - No cardiogenic shock        {auroc_no_cs:.3f}          N={len(df_no_cs):,}        Subgroup\n",
    "\"\"\")\n",
    "else:\n",
    "    print(\"Comparison table not shown because results_24h_auc and/or results_dr are missing.\")\n",
    "    if not has_24h_auc:\n",
    "        print(\"  - results_24h_auc not found. Run your Step A cell that creates results_24h_auc.\")\n",
    "    if not has_dr or ('auroc' not in results_dr):\n",
    "        print(\"  - results_dr not found or missing 'auroc'. Run the DR cell that creates results_dr['auroc'].\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# STORE RESULTS\n",
    "#------------------------------------------------------------------------------\n",
    "results_mortality = {\n",
    "    'n': n_total,\n",
    "    'n_deaths': n_deaths,\n",
    "    'mortality_rate': mortality_rate,\n",
    "    'auroc': auroc_mort,\n",
    "    'auroc_ci': (auroc_mort_ci_lower, auroc_mort_ci_upper),\n",
    "    'auprc': auprc_mort,\n",
    "    'auprc_ci': (auprc_ci_lower, auprc_ci_upper),\n",
    "    'youden_cutoff': float(optimal_cutoff_m),\n",
    "    'youden_sensitivity': float(optimal_sens_m),\n",
    "    'youden_specificity': float(optimal_spec_m),\n",
    "    'threshold_13_sensitivity': float(sens_13_m),\n",
    "    'threshold_13_specificity': float(spec_13_m),\n",
    "    'mort_by_risk': mort_by_risk,\n",
    "    'chi2': float(chi2_m),\n",
    "    'p_value': float(p_chi_m),\n",
    "    'risk_ratio_high_vs_low': float(rr_mort) if not np.isnan(rr_mort) else None,\n",
    "    'absolute_risk_increase_pp': float(ari),\n",
    "    'auroc_cs': auroc_cs,\n",
    "    'auroc_cs_ci': (auroc_cs_ci_lower, auroc_cs_ci_upper),\n",
    "    'auroc_no_cs': auroc_no_cs,\n",
    "    'auroc_no_cs_ci': (auroc_no_cs_ci_lower, auroc_no_cs_ci_upper)\n",
    "}\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# SUMMARY\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY: IN-HOSPITAL MORTALITY (EXPLORATORY)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "Population: Full cohort (N = {n_total:,})\n",
    "Mortality Rate: {mortality_rate:.1f}%\n",
    "\n",
    "IMPORTANT CONTEXT:\n",
    "BAN-ADHF was designed for diuretic efficiency, NOT mortality.\n",
    "These results represent a novel exploratory extension.\n",
    "\n",
    "Discrimination (Exploratory):\n",
    "  AUROC = {auroc_mort:.3f} (95% CI: {auroc_mort_ci_lower:.3f} to {auroc_mort_ci_upper:.3f})\n",
    "  AUPRC = {auprc_mort:.3f} (95% CI: {auprc_ci_lower:.3f} to {auprc_ci_upper:.3f})\n",
    "\n",
    "Mortality by Risk Category:\n",
    "  Low risk (\u22647):      {mort_by_risk['Low']['rate']:.1f}% (N={mort_by_risk['Low']['n']})\n",
    "  Moderate (8-12):    {mort_by_risk['Moderate']['rate']:.1f}% (N={mort_by_risk['Moderate']['n']})\n",
    "  High risk (\u226513):    {mort_by_risk['High']['rate']:.1f}% (N={mort_by_risk['High']['n']})\n",
    "\n",
    "Risk Ratio (High vs Low): {rr_mort:.2f}x\n",
    "Absolute Risk Increase: {ari:.1f} percentage points\n",
    "\n",
    "Subgroup Analysis:\n",
    "  Cardiogenic shock:     AUROC = {auroc_cs:.3f}\n",
    "  No cardiogenic shock:  AUROC = {auroc_no_cs:.3f}\n",
    "\"\"\")\n",
    "\n",
    "print(\"\u2713 Mortality results stored in 'results_mortality' dictionary\")\n",
    "print(\"\\n\u2192 Next: Subgroup Analyses\")\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# SECTION 6b: DISCRIMINATION COMPARISON FRAMEWORK\n",
    "# Cell 12b: Literature Comparison and Prevalence Effect Analysis (FIXED)\n",
    "#==========================================================================\n",
    "# PURPOSE: Synthesize discrimination results with literature comparisons\n",
    "# OUTPUT: Comparison tables and manuscript-ready interpretations\n",
    "#==========================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DISCRIMINATION COMPARISON FRAMEWORK\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nThis cell synthesizes results from Cells 9-12 with literature context.\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# SAFETY CHECKS\n",
    "#------------------------------------------------------------------------------\n",
    "missing = []\n",
    "if 'results_24h_auc' not in globals():\n",
    "    missing.append(\"results_24h_auc (Q20/Q25 AUROC summary)\")\n",
    "if 'results_dr' not in globals():\n",
    "    missing.append(\"results_dr (binary DR results)\")\n",
    "if 'results_mortality' not in globals():\n",
    "    missing.append(\"results_mortality (mortality results)\")\n",
    "\n",
    "# results_24h is used only for rho/r/c-index text. If it is missing or overwritten,\n",
    "# we still run the AUROC tables using results_24h_auc.\n",
    "has_results_24h_continuous = (\n",
    "    'results_24h' in globals() and isinstance(results_24h, dict)\n",
    "    and 'spearman_rho' in results_24h and 'pearson_r' in results_24h\n",
    "    and 'spearman_ci' in results_24h and 'pearson_ci' in results_24h\n",
    ")\n",
    "\n",
    "if missing:\n",
    "    raise ValueError(\"Missing required objects: \" + \", \".join(missing))\n",
    "\n",
    "# Convenience handles\n",
    "r_auc = results_24h_auc\n",
    "r_dr = results_dr\n",
    "r_m = results_mortality\n",
    "\n",
    "# Pull prevalence from results_dr (not hard-coded)\n",
    "dr_prev = float(r_dr.get('prevalence', np.nan))\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# TABLE X: DISCRIMINATION BY OUTCOME DEFINITION\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TABLE X: DISCRIMINATION BY OUTCOME DEFINITION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "Outcome                      Definition              Prevalence    AUROC (95% CI)                    Reference\n",
    "---------------------------------------------------------------------------------------------------------------\n",
    "Lowest efficiency quintile   Bottom 20%              20.0%         {r_auc['auroc_q20']:.3f} ({r_auc['auroc_q20_ci'][0]:.3f}\u2013{r_auc['auroc_q20_ci'][1]:.3f})        Segar: 0.84\n",
    "Lowest efficiency quartile   Bottom 25%              25.0%         {r_auc['auroc_q25']:.3f} ({r_auc['auroc_q25_ci'][0]:.3f}\u2013{r_auc['auroc_q25_ci'][1]:.3f})        Pandey: 0.70\n",
    "Binary DR                    Urine \u22643,000 mL         {dr_prev:.1f}%        {r_dr['auroc']:.3f} ({r_dr['auroc_ci'][0]:.3f}\u2013{r_dr['auroc_ci'][1]:.3f})        Mauch: 0.631\n",
    "In-hospital mortality        Death during admission  {r_m['mortality_rate']:.1f}%        {r_m['auroc']:.3f} ({r_m['auroc_ci'][0]:.3f}\u2013{r_m['auroc_ci'][1]:.3f})        Exploratory\n",
    "\"\"\")\n",
    "\n",
    "print(\"\"\"\n",
    "Key Observations:\n",
    "- Continuous efficiency definitions (Q20/Q25) show strong discrimination.\n",
    "- Binary DR is a coarser definition and loses information compared with continuous efficiency.\n",
    "- Mortality discrimination is limited, consistent with the score\u2019s original intent.\n",
    "\"\"\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# LITERATURE COMPARISON TABLE: DIURETIC EFFICIENCY\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LITERATURE COMPARISON: DIURETIC EFFICIENCY PREDICTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if has_results_24h_continuous:\n",
    "    print(f\"\"\"\n",
    "Study           Population       N       Correlation                AUROC (Quintile)   AUROC (Quartile)\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "Segar 2024      Trial derivation 707     \u2014                          0.84               \u2014\n",
    "Mauch 2025      Floor patients   317     r = \u22120.40                  \u2014                  \u2014\n",
    "Pandey 2025     CLOROTIC trial   220     \u2014                          \u2014                  0.70\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "This study      ICU patients     {r_auc['n']:,}   \u03c1 = {results_24h['spearman_rho']:.3f} (95% CI {results_24h['spearman_ci'][0]:.3f}\u2013{results_24h['spearman_ci'][1]:.3f})\n",
    "                                         r = {results_24h['pearson_r']:.3f} (95% CI {results_24h['pearson_ci'][0]:.3f}\u2013{results_24h['pearson_ci'][1]:.3f})     {r_auc['auroc_q20']:.3f}              {r_auc['auroc_q25']:.3f}\n",
    "\"\"\")\n",
    "else:\n",
    "    print(f\"\"\"\n",
    "Note: results_24h (continuous correlation summary) not available or has been overwritten.\n",
    "Showing AUROC comparisons only from results_24h_auc.\n",
    "\n",
    "This study (ICU patients, N={r_auc['n']:,}):\n",
    "  AUROC Q20: {r_auc['auroc_q20']:.3f}\n",
    "  AUROC Q25: {r_auc['auroc_q25']:.3f}\n",
    "\"\"\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# LITERATURE COMPARISON TABLE: BINARY DIURETIC RESISTANCE\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LITERATURE COMPARISON: BINARY DIURETIC RESISTANCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "Study           Population       DR Prevalence    Binary DR AUROC    Note\n",
    "---------------------------------------------------------------------------\n",
    "Mauch 2025      Floor patients   ~25%             0.631              Reference\n",
    "This study      ICU patients     {dr_prev:.1f}%            {r_dr['auroc']:.3f}              Higher prevalence and more severe case-mix\n",
    "---------------------------------------------------------------------------\n",
    "Difference (AUROC):                               {r_dr['auroc'] - 0.631:+.3f}\n",
    "\"\"\")\n",
    "\n",
    "print(\"\"\"\n",
    "Interpretation:\n",
    "Binary DR is a simplified threshold. In an ICU cohort where most patients meet the threshold,\n",
    "it becomes a less informative endpoint than continuous efficiency.\n",
    "\"\"\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# COMPLETE COMPARISON FRAMEWORK\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPLETE VALIDATION COMPARISON FRAMEWORK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Deltas for AUROC comparisons\n",
    "delta_quintile = ((r_auc['auroc_q20'] - 0.84) / 0.84) * 100\n",
    "delta_quartile = ((r_auc['auroc_q25'] - 0.70) / 0.70) * 100\n",
    "delta_dr = ((r_dr['auroc'] - 0.631) / 0.631) * 100\n",
    "\n",
    "if has_results_24h_continuous:\n",
    "    delta_pearson = ((abs(results_24h['pearson_r']) - 0.40) / 0.40) * 100\n",
    "    pearson_line = f\"{results_24h['pearson_r']:.3f}        Mauch: \u22120.40     {delta_pearson:+.1f}%       Comparable magnitude\"\n",
    "    spearman_line = f\"{results_24h['spearman_rho']:.3f}        \u2014                \u2014           Strong inverse association\"\n",
    "else:\n",
    "    pearson_line = \"NA           Mauch: \u22120.40     \u2014           Correlation summary not available in this session\"\n",
    "    spearman_line = \"NA           \u2014                \u2014           Correlation summary not available in this session\"\n",
    "\n",
    "print(f\"\"\"\n",
    "Metric                  This Study     Comparator       \u0394           Interpretation\n",
    "------------------------------------------------------------------------------------\n",
    "Spearman \u03c1              {spearman_line}\n",
    "Pearson r               {pearson_line}\n",
    "AUROC quintile (Q20)    {r_auc['auroc_q20']:.3f}        Segar: 0.84      {delta_quintile:+.1f}%       Comparable\n",
    "AUROC quartile (Q25)    {r_auc['auroc_q25']:.3f}        Pandey: 0.70     {delta_quartile:+.1f}%       Better\n",
    "Binary DR AUROC         {r_dr['auroc']:.3f}        Mauch: 0.631     {delta_dr:+.1f}%       Lower with binary threshold in ICU case-mix\n",
    "In-hospital mortality   {r_m['auroc']:.3f}        \u2014                \u2014           Exploratory (not designed)\n",
    "  - Cardiogenic shock   {r_m['auroc_cs']:.3f}        \u2014                \u2014           Improved discrimination\n",
    "  - No CS               {r_m['auroc_no_cs']:.3f}        \u2014                \u2014           Limited discrimination\n",
    "\"\"\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# KEY MANUSCRIPT SENTENCES (shorter, cleaner)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY MANUSCRIPT SENTENCES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if has_results_24h_continuous:\n",
    "    eff_sentence = (\n",
    "        f\"The BAN-ADHF score was inversely associated with 24-hour diuretic efficiency \"\n",
    "        f\"(Spearman \u03c1 = {results_24h['spearman_rho']:.3f}, 95% CI {results_24h['spearman_ci'][0]:.3f}\u2013{results_24h['spearman_ci'][1]:.3f}; p<0.001). \"\n",
    "        f\"For comparison with prior work, Pearson r was {results_24h['pearson_r']:.3f}.\"\n",
    "    )\n",
    "else:\n",
    "    eff_sentence = (\n",
    "        \"The BAN-ADHF score demonstrated strong discrimination for low 24-hour efficiency using percentile-based definitions.\"\n",
    "    )\n",
    "\n",
    "print(f\"\"\"\n",
    "RESULTS. Diuretic efficiency:\n",
    "{eff_sentence}\n",
    "Discrimination for low efficiency was strong (AUROC Q20 {r_auc['auroc_q20']:.3f}; AUROC Q25 {r_auc['auroc_q25']:.3f}).\n",
    "\n",
    "RESULTS. Binary diuretic resistance:\n",
    "Binary diuretic resistance (\u22643,000 mL) showed modest discrimination (AUROC {r_dr['auroc']:.3f}).\n",
    "This likely reflects information loss from dichotomizing a continuous phenomenon and the more severe ICU case-mix.\n",
    "\n",
    "RESULTS. Mortality (exploratory):\n",
    "In exploratory analysis, BAN-ADHF showed limited discrimination for in-hospital mortality (AUROC {r_m['auroc']:.3f}).\n",
    "Discrimination was higher in cardiogenic shock (AUROC {r_m['auroc_cs']:.3f}) than in non-shock patients (AUROC {r_m['auroc_no_cs']:.3f}).\n",
    "\"\"\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# STORE COMPARISON FRAMEWORK\n",
    "#------------------------------------------------------------------------------\n",
    "comparison_framework = {\n",
    "    'efficiency_auroc': {\n",
    "        'q20': {'value': r_auc['auroc_q20'], 'ci': r_auc['auroc_q20_ci'], 'reference': 0.84, 'delta_pct': delta_quintile},\n",
    "        'q25': {'value': r_auc['auroc_q25'], 'ci': r_auc['auroc_q25_ci'], 'reference': 0.70, 'delta_pct': delta_quartile},\n",
    "    },\n",
    "    'binary_dr': {\n",
    "        'auroc': {'value': r_dr['auroc'], 'ci': r_dr['auroc_ci'], 'reference': 0.631, 'delta_pct': delta_dr},\n",
    "        'prevalence_this': dr_prev\n",
    "    },\n",
    "    'mortality': {\n",
    "        'auroc_overall': {'value': r_m['auroc'], 'ci': r_m['auroc_ci']},\n",
    "        'auroc_cs': r_m['auroc_cs'],\n",
    "        'auroc_no_cs': r_m['auroc_no_cs']\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\u2713 Comparison framework stored in 'comparison_framework' dictionary\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n\u2192 Next: Cell 13 - Subgroup Analyses\")\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# SECTION 8: SUBGROUP ANALYSES\n",
    "# Cell 13: Pre-specified Subgroup Analyses\n",
    "#==========================================================================\n",
    "# PURPOSE: Evaluate BAN-ADHF performance across pre-specified subgroups\n",
    "# OUTCOME: 24-hour diuretic efficiency (score's intended purpose)\n",
    "# METRICS: Spearman correlation (with bootstrap CI), AUROC (Q20) per subgroup\n",
    "# OUTPUT: Tables, interaction p-values, forest plot data\n",
    "#==========================================================================\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SUBGROUP ANALYSES: 24-HOUR DIURETIC EFFICIENCY\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nPrimary outcome: 24-hour diuretic efficiency (BAN-ADHF's intended purpose)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# PREPARE ANALYSIS COHORT\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "df_sub = df[(df['icu_stay_ge_24h'] == 1) &\n",
    "            (df['diuretic_efficiency_24h'].notna()) &\n",
    "            (df['diuretic_efficiency_24h'] > 0)].copy()\n",
    "\n",
    "print(f\"\\nAnalysis cohort: N = {len(df_sub):,}\")\n",
    "\n",
    "# Define lowest quintile for AUROC (Q20)\n",
    "quintile_threshold = df_sub['diuretic_efficiency_24h'].quantile(0.20)\n",
    "df_sub['lowest_quintile'] = (df_sub['diuretic_efficiency_24h'] <= quintile_threshold).astype(int)\n",
    "\n",
    "print(f\"Lowest quintile threshold: \u2264{quintile_threshold:.1f} mL/mg\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# BOOTSTRAP SETUP\n",
    "#------------------------------------------------------------------------------\n",
    "np.random.seed(42)\n",
    "n_bootstrap = 1000\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# DEFINE SUBGROUPS\n",
    "# NOTE: KEEP YOUR OLD GENDER VAR THAT WORKED IN YOUR NOTEBOOK\n",
    "#------------------------------------------------------------------------------\n",
    "subgroups = {\n",
    "    'Age \u226565 years': {\n",
    "        'var': 'age_65_or_older',\n",
    "        'groups': {1: '\u226565 years', 0: '<65 years'}\n",
    "    },\n",
    "    'Sex': {\n",
    "        'var': 'gender',  # keep this exactly as your old notebook\n",
    "        'groups': {'M': 'Male', 'F': 'Female'}\n",
    "    },\n",
    "    'Diabetes': {\n",
    "        'var': 'hx_diabetes',\n",
    "        'groups': {1: 'Diabetes', 0: 'No diabetes'}\n",
    "    },\n",
    "    'Chronic kidney disease': {\n",
    "        'var': 'chronic_advanced_ckd',\n",
    "        'groups': {1: 'Advanced CKD', 0: 'No advanced CKD'}\n",
    "    },\n",
    "    'Atrial fibrillation': {\n",
    "        'var': 'hx_atrial_fibrillation',\n",
    "        'groups': {1: 'AFib', 0: 'No AFib'}\n",
    "    },\n",
    "    'Home diuretics': {\n",
    "        'var': 'on_home_diuretics',\n",
    "        'groups': {1: 'On home diuretics', 0: 'No home diuretics'}\n",
    "    },\n",
    "    'Cardiogenic shock': {\n",
    "        'var': 'cardiogenic_shock',\n",
    "        'groups': {1: 'Cardiogenic shock', 0: 'No cardiogenic shock'}\n",
    "    }\n",
    "}\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# HELPERS\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def bootstrap_spearman_ci(data: pd.DataFrame, n_boot: int = 1000):\n",
    "    \"\"\"Spearman rho + bootstrap CI\"\"\"\n",
    "    rho, p = spearmanr(data['ban_adhf_total_score'], data['diuretic_efficiency_24h'])\n",
    "\n",
    "    boot = []\n",
    "    for _ in range(n_boot):\n",
    "        idx = np.random.choice(len(data), size=len(data), replace=True)\n",
    "        sample = data.iloc[idx]\n",
    "        r, _ = spearmanr(sample['ban_adhf_total_score'], sample['diuretic_efficiency_24h'])\n",
    "        boot.append(r)\n",
    "\n",
    "    ci = (np.percentile(boot, 2.5), np.percentile(boot, 97.5))\n",
    "    return rho, ci, p\n",
    "\n",
    "\n",
    "def bootstrap_auroc_ci(data: pd.DataFrame, n_boot: int = 1000):\n",
    "    \"\"\"AUROC (Q20) + bootstrap CI\"\"\"\n",
    "    # guard for too-few events / no variation\n",
    "    events = int(data['lowest_quintile'].sum())\n",
    "    if events <= 5 or events >= len(data) - 5:\n",
    "        return None, (None, None)\n",
    "\n",
    "    auc = roc_auc_score(data['lowest_quintile'], data['ban_adhf_total_score'])\n",
    "\n",
    "    boot = []\n",
    "    for _ in range(n_boot):\n",
    "        idx = np.random.choice(len(data), size=len(data), replace=True)\n",
    "        sample = data.iloc[idx]\n",
    "        if sample['lowest_quintile'].sum() > 0 and sample['lowest_quintile'].sum() < len(sample):\n",
    "            boot.append(roc_auc_score(sample['lowest_quintile'], sample['ban_adhf_total_score']))\n",
    "\n",
    "    ci = (np.percentile(boot, 2.5), np.percentile(boot, 97.5))\n",
    "    return auc, ci\n",
    "\n",
    "\n",
    "def fisher_z_test(r1, n1, r2, n2):\n",
    "    \"\"\"Compare two correlations using Fisher z-transform (two-tailed)\"\"\"\n",
    "    # Fisher z\n",
    "    z1 = 0.5 * np.log((1 + r1) / (1 - r1))\n",
    "    z2 = 0.5 * np.log((1 + r2) / (1 - r2))\n",
    "    se = np.sqrt(1/(n1-3) + 1/(n2-3))\n",
    "    z_stat = (z1 - z2) / se\n",
    "\n",
    "    from scipy.stats import norm\n",
    "    p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
    "    return z_stat, p_value\n",
    "\n",
    "\n",
    "def calculate_subgroup_metrics(data: pd.DataFrame, n_boot: int = 1000):\n",
    "    rho, rho_ci, p = bootstrap_spearman_ci(data, n_boot=n_boot)\n",
    "    auc, auc_ci = bootstrap_auroc_ci(data, n_boot=n_boot)\n",
    "    return {\n",
    "        'n': len(data),\n",
    "        'n_events': int(data['lowest_quintile'].sum()),\n",
    "        'spearman_rho': float(rho),\n",
    "        'spearman_ci': (float(rho_ci[0]), float(rho_ci[1])),\n",
    "        'spearman_p': float(p),\n",
    "        'auroc': None if auc is None else float(auc),\n",
    "        'auroc_ci': (None, None) if auc is None else (float(auc_ci[0]), float(auc_ci[1]))\n",
    "    }\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# OVERALL (for forest plot row)\n",
    "#------------------------------------------------------------------------------\n",
    "overall_rho, overall_rho_ci, overall_p = bootstrap_spearman_ci(df_sub, n_boot=n_bootstrap)\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# ANALYZE EACH SUBGROUP\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUBGROUP RESULTS: SPEARMAN CORRELATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "subgroup_results = {}\n",
    "\n",
    "print(f\"\\n{'Subgroup':<30} {'N':<8} {'Spearman \u03c1':<12} {'95% CI':<22} {'p-value':<10}\")\n",
    "print(\"-\"*85)\n",
    "\n",
    "for subgroup_name, subgroup_info in subgroups.items():\n",
    "    var = subgroup_info['var']\n",
    "    groups = subgroup_info['groups']\n",
    "\n",
    "    subgroup_results[subgroup_name] = {}\n",
    "\n",
    "    for value, label in groups.items():\n",
    "        subset = df_sub[df_sub[var] == value]\n",
    "\n",
    "        if len(subset) >= 30:\n",
    "            metrics = calculate_subgroup_metrics(subset, n_boot=n_bootstrap)\n",
    "            subgroup_results[subgroup_name][label] = metrics\n",
    "\n",
    "            ci_str = f\"({metrics['spearman_ci'][0]:.3f}, {metrics['spearman_ci'][1]:.3f})\"\n",
    "            p_str = \"<0.001\" if metrics['spearman_p'] < 0.001 else f\"{metrics['spearman_p']:.3f}\"\n",
    "\n",
    "            print(f\"{label:<30} {metrics['n']:<8} {metrics['spearman_rho']:<12.3f} {ci_str:<22} {p_str:<10}\")\n",
    "        else:\n",
    "            print(f\"{label:<30} {len(subset):<8} {'Insufficient N':<12}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# INTERACTION TESTS\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERACTION TESTS: DIFFERENCE IN CORRELATIONS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nFisher's z-transformation to compare correlations between subgroups\")\n",
    "\n",
    "print(f\"\\n{'Comparison':<45} {'\u03c1\u2081':<8} {'\u03c1\u2082':<8} {'\u0394\u03c1':<10} {'p-interaction':<12}\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "interaction_results = {}\n",
    "\n",
    "for subgroup_name, subgroup_info in subgroups.items():\n",
    "    labels = list(subgroup_info['groups'].values())\n",
    "\n",
    "    if len(labels) == 2 and all(label in subgroup_results[subgroup_name] for label in labels):\n",
    "        r1 = subgroup_results[subgroup_name][labels[0]]['spearman_rho']\n",
    "        n1 = subgroup_results[subgroup_name][labels[0]]['n']\n",
    "        r2 = subgroup_results[subgroup_name][labels[1]]['spearman_rho']\n",
    "        n2 = subgroup_results[subgroup_name][labels[1]]['n']\n",
    "\n",
    "        z_stat, p_int = fisher_z_test(r1, n1, r2, n2)\n",
    "        delta_rho = r1 - r2\n",
    "\n",
    "        interaction_results[subgroup_name] = {\n",
    "            'rho_1': r1, 'rho_2': r2, 'delta': delta_rho,\n",
    "            'z_stat': z_stat, 'p_interaction': p_int\n",
    "        }\n",
    "\n",
    "        p_str = \"<0.001\" if p_int < 0.001 else f\"{p_int:.3f}\"\n",
    "        sig = \"*\" if p_int < 0.05 else \"\"\n",
    "        comparison = f\"{labels[0]} vs {labels[1]}\"\n",
    "        print(f\"{comparison:<45} {r1:<8.3f} {r2:<8.3f} {delta_rho:<+10.3f} {p_str:<12} {sig}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# AUROC BY SUBGROUP\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUBGROUP RESULTS: AUROC FOR LOWEST QUINTILE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'Subgroup':<30} {'N':<8} {'Events':<8} {'AUROC':<10} {'95% CI':<22}\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "for subgroup_name, groups_data in subgroup_results.items():\n",
    "    for label, metrics in groups_data.items():\n",
    "        if metrics['auroc'] is not None:\n",
    "            ci_str = f\"({metrics['auroc_ci'][0]:.3f}, {metrics['auroc_ci'][1]:.3f})\"\n",
    "            print(f\"{label:<30} {metrics['n']:<8} {metrics['n_events']:<8} {metrics['auroc']:<10.3f} {ci_str:<22}\")\n",
    "        else:\n",
    "            print(f\"{label:<30} {metrics['n']:<8} {metrics['n_events']:<8} {'N/A':<10} {'':<22}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# HF PHENOTYPE SUBGROUP (3 categories)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HF PHENOTYPE SUBGROUP ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "hf_results = {}\n",
    "df_hf = df_sub[df_sub['hf_phenotype'].notna()].copy()\n",
    "\n",
    "print(f\"\\nPatients with HF phenotype data: N = {len(df_hf):,}\")\n",
    "print(f\"\\n{'HF Phenotype':<20} {'N':<8} {'Spearman \u03c1':<12} {'95% CI':<22} {'AUROC':<10}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for phenotype in ['HFrEF', 'HFmrEF', 'HFpEF']:\n",
    "    subset = df_hf[df_hf['hf_phenotype'] == phenotype]\n",
    "\n",
    "    if len(subset) >= 30:\n",
    "        metrics = calculate_subgroup_metrics(subset, n_boot=n_bootstrap)\n",
    "        hf_results[phenotype] = metrics\n",
    "\n",
    "        ci_str = f\"({metrics['spearman_ci'][0]:.3f}, {metrics['spearman_ci'][1]:.3f})\"\n",
    "        auroc_str = f\"{metrics['auroc']:.3f}\" if metrics['auroc'] is not None else \"N/A\"\n",
    "        print(f\"{phenotype:<20} {metrics['n']:<8} {metrics['spearman_rho']:<12.3f} {ci_str:<22} {auroc_str:<10}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# FOREST PLOT DATA (FOR VISUALIZATION)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FOREST PLOT DATA (FOR VISUALIZATION)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "forest_data = []\n",
    "\n",
    "# Overall (computed directly so no dependency on results_24h dict shape)\n",
    "forest_data.append({\n",
    "    'subgroup': 'Overall',\n",
    "    'n': len(df_sub),\n",
    "    'rho': float(overall_rho),\n",
    "    'rho_ci_low': float(overall_rho_ci[0]),\n",
    "    'rho_ci_high': float(overall_rho_ci[1])\n",
    "})\n",
    "\n",
    "# Binary subgroups\n",
    "for subgroup_name, groups_data in subgroup_results.items():\n",
    "    for label, metrics in groups_data.items():\n",
    "        forest_data.append({\n",
    "            'subgroup': label,\n",
    "            'n': metrics['n'],\n",
    "            'rho': metrics['spearman_rho'],\n",
    "            'rho_ci_low': metrics['spearman_ci'][0],\n",
    "            'rho_ci_high': metrics['spearman_ci'][1]\n",
    "        })\n",
    "\n",
    "# HF phenotypes\n",
    "for phenotype, metrics in hf_results.items():\n",
    "    forest_data.append({\n",
    "        'subgroup': phenotype,\n",
    "        'n': metrics['n'],\n",
    "        'rho': metrics['spearman_rho'],\n",
    "        'rho_ci_low': metrics['spearman_ci'][0],\n",
    "        'rho_ci_high': metrics['spearman_ci'][1]\n",
    "    })\n",
    "\n",
    "forest_df = pd.DataFrame(forest_data)\n",
    "print(\"\\n\")\n",
    "print(forest_df.to_string(index=False))\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# KEY FINDINGS\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY SUBGROUP FINDINGS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "sig_interactions = {k: v for k, v in interaction_results.items() if v['p_interaction'] < 0.05}\n",
    "\n",
    "if sig_interactions:\n",
    "    print(\"\\nSignificant interactions (p < 0.05):\")\n",
    "    for name, data in sig_interactions.items():\n",
    "        p_str = \"<0.001\" if data['p_interaction'] < 0.001 else f\"{data['p_interaction']:.3f}\"\n",
    "        print(f\"  \u2022 {name}: \u0394\u03c1 = {data['delta']:+.3f}, p = {p_str}\")\n",
    "else:\n",
    "    print(\"\\nNo significant interactions detected (p < 0.05)\")\n",
    "    print(\"BAN-ADHF performance is consistent across subgroups\")\n",
    "\n",
    "# strongest/weakest by |rho|\n",
    "all_rhos = []\n",
    "for subgroup_name, groups_data in subgroup_results.items():\n",
    "    for label, metrics in groups_data.items():\n",
    "        all_rhos.append((label, metrics['spearman_rho'], metrics['n']))\n",
    "\n",
    "all_rhos.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "print(f\"\\nLargest |association|:  {all_rhos[0][0]} (\u03c1 = {all_rhos[0][1]:.3f}, N={all_rhos[0][2]})\")\n",
    "print(f\"Smallest |association|: {all_rhos[-1][0]} (\u03c1 = {all_rhos[-1][1]:.3f}, N={all_rhos[-1][2]})\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# STORE RESULTS\n",
    "#------------------------------------------------------------------------------\n",
    "results_subgroups = {\n",
    "    'subgroup_results': subgroup_results,\n",
    "    'interaction_results': interaction_results,\n",
    "    'hf_results': hf_results,\n",
    "    'forest_data': forest_df\n",
    "}\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# SUMMARY\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY: SUBGROUP ANALYSES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "Analysis: 24-hour diuretic efficiency (BAN-ADHF's intended purpose)\n",
    "Cohort: N = {len(df_sub):,}\n",
    "\n",
    "Key Findings:\n",
    "  \u2022 Overall Spearman \u03c1 = {overall_rho:.3f} (95% CI: {overall_rho_ci[0]:.3f} to {overall_rho_ci[1]:.3f})\n",
    "  \u2022 {len(sig_interactions)} significant interaction(s) detected\n",
    "\"\"\")\n",
    "\n",
    "print(\"\u2713 Subgroup results stored in 'results_subgroups' dictionary\")\n",
    "print(\"\\n\u2192 Next: Sensitivity Analyses\")\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#==========================================================================\n# SECTION 9: SENSITIVITY ANALYSES\n# Cell 14: Robustness Testing\n#==========================================================================\n# PURPOSE: Test robustness of primary findings under various conditions\n# NOTES:\n#   - Uses FIXED Q20 threshold from primary cohort for all analyses\n#   - Ensures consistency with eTable 3 (Subgroup Analysis)\n#   - Computes the primary reference metrics directly from df_base\n#==========================================================================\n\nfrom scipy.stats import spearmanr\nfrom sklearn.metrics import roc_auc_score\nimport numpy as np\nimport pandas as pd\n\nprint(\"=\"*70)\nprint(\"SENSITIVITY ANALYSES\")\nprint(\"=\"*70)\nprint(\"\\nTesting robustness of primary findings under various conditions\")\n\nnp.random.seed(42)\nn_bootstrap = 1000\n\n#------------------------------------------------------------------------------\n# BASE COHORT\n#------------------------------------------------------------------------------\ndf_base = df[(df['icu_stay_ge_24h'] == 1) &\n             (df['diuretic_efficiency_24h'].notna()) &\n             (df['diuretic_efficiency_24h'] > 0)].copy()\n\nprint(f\"\\nBase cohort (24h efficiency): N = {len(df_base):,}\")\n\n#------------------------------------------------------------------------------\n# FIXED THRESHOLDS FROM PRIMARY COHORT\n#------------------------------------------------------------------------------\nFIXED_Q20_THRESHOLD = df_base['diuretic_efficiency_24h'].quantile(0.20)\nFIXED_Q25_THRESHOLD = df_base['diuretic_efficiency_24h'].quantile(0.25)\n\nprint(f\"Q20 threshold: \u2264{FIXED_Q20_THRESHOLD:.1f} mL/mg\")\nprint(f\"Q25 threshold: \u2264{FIXED_Q25_THRESHOLD:.1f} mL/mg\")\n\n#------------------------------------------------------------------------------\n# BOOTSTRAP HELPERS\n#------------------------------------------------------------------------------\ndef bootstrap_spearman_ci(data, n_boot=1000):\n    rho, p = spearmanr(data['ban_adhf_total_score'], data['diuretic_efficiency_24h'])\n    boot = []\n    for _ in range(n_boot):\n        idx = np.random.choice(len(data), size=len(data), replace=True)\n        sample = data.iloc[idx]\n        r, _ = spearmanr(sample['ban_adhf_total_score'], sample['diuretic_efficiency_24h'])\n        boot.append(r)\n    ci = (np.percentile(boot, 2.5), np.percentile(boot, 97.5))\n    return float(rho), (float(ci[0]), float(ci[1])), float(p)\n\ndef bootstrap_auroc_ci(y, score, n_boot=1000):\n    y = pd.Series(y).reset_index(drop=True)\n    score = pd.Series(score).reset_index(drop=True)\n\n    if y.sum() == 0 or y.sum() == len(y):\n        return None, (None, None)\n\n    auc = roc_auc_score(y, score)\n    boot = []\n    for _ in range(n_boot):\n        idx = np.random.choice(len(y), size=len(y), replace=True)\n        yb = y.iloc[idx]\n        sb = score.iloc[idx]\n        if yb.sum() > 0 and yb.sum() < len(yb):\n            boot.append(roc_auc_score(yb, sb))\n\n    ci = (np.percentile(boot, 2.5), np.percentile(boot, 97.5))\n    return float(auc), (float(ci[0]), float(ci[1]))\n\ndef compute_primary_metrics(data, q20_thr, q25_thr):\n    rho, rho_ci, p = bootstrap_spearman_ci(data, n_boot=n_bootstrap)\n\n    # Q20 using fixed threshold\n    y20 = (data['diuretic_efficiency_24h'] <= q20_thr).astype(int)\n    auc20, auc20_ci = bootstrap_auroc_ci(y20, data['ban_adhf_total_score'], n_boot=n_bootstrap)\n\n    # Q25 using fixed threshold\n    y25 = (data['diuretic_efficiency_24h'] <= q25_thr).astype(int)\n    auc25, auc25_ci = bootstrap_auroc_ci(y25, data['ban_adhf_total_score'], n_boot=n_bootstrap)\n\n    return {\n        'n': int(len(data)),\n        'spearman_rho': rho,\n        'spearman_ci': rho_ci,\n        'spearman_p': p,\n        'q20_threshold': float(q20_thr),\n        'q25_threshold': float(q25_thr),\n        'auroc_q20': auc20,\n        'auroc_q20_ci': auc20_ci,\n        'auroc_q25': auc25,\n        'auroc_q25_ci': auc25_ci,\n        'n_q20': int(y20.sum()),\n        'n_q25': int(y25.sum()),\n    }\n\n#------------------------------------------------------------------------------\n# REFERENCE VALUES (Primary Analysis)\n#------------------------------------------------------------------------------\nprimary_24h = compute_primary_metrics(df_base, FIXED_Q20_THRESHOLD, FIXED_Q25_THRESHOLD)\n\nprint(\"\\n\" + \"-\"*70)\nprint(\"REFERENCE: PRIMARY ANALYSIS RESULTS\")\nprint(\"-\"*70)\n\nprint(f\"\"\"\nPrimary cohort (24h efficiency): N = {primary_24h['n']:,}\n  Spearman \u03c1:      {primary_24h['spearman_rho']:.3f} ({primary_24h['spearman_ci'][0]:.3f} to {primary_24h['spearman_ci'][1]:.3f})\n  AUROC (Q20):     {primary_24h['auroc_q20']:.3f} ({primary_24h['auroc_q20_ci'][0]:.3f} to {primary_24h['auroc_q20_ci'][1]:.3f})\n  AUROC (Q25):     {primary_24h['auroc_q25']:.3f} ({primary_24h['auroc_q25_ci'][0]:.3f} to {primary_24h['auroc_q25_ci'][1]:.3f})\n\"\"\")\n\n# Optional: keep your Step 12 dict aligned if it exists\ntry:\n    results_24h_auc = results_24h_auc  # noqa\n    results_24h_auc.update({\n        'n': primary_24h['n'],\n        'auroc_q20': primary_24h['auroc_q20'],\n        'auroc_q25': primary_24h['auroc_q25'],\n        'auroc_q20_ci': primary_24h['auroc_q20_ci'],\n        'auroc_q25_ci': primary_24h['auroc_q25_ci'],\n    })\nexcept NameError:\n    pass\n\n#------------------------------------------------------------------------------\n# SENSITIVITY RUN HELPER (uses fixed threshold)\n#------------------------------------------------------------------------------\ndef sensitivity_run(data, name, q20_thr):\n    out = {'name': name, 'n': int(len(data))}\n    if len(data) < 50:\n        out.update({'spearman': None, 'spearman_ci': (None, None), 'auroc': None, 'auroc_ci': (None, None),\n                    'n_events': None, 'note': 'Insufficient N'})\n        return out\n\n    rho, rho_ci, p = bootstrap_spearman_ci(data, n_boot=n_bootstrap)\n    out['spearman'] = rho\n    out['spearman_ci'] = rho_ci\n    out['spearman_p'] = p\n\n    # Use FIXED threshold from primary cohort\n    y = (data['diuretic_efficiency_24h'] <= q20_thr).astype(int)\n    out['threshold'] = float(q20_thr)\n    out['n_events'] = int(y.sum())\n\n    auc, auc_ci = bootstrap_auroc_ci(y, data['ban_adhf_total_score'], n_boot=n_bootstrap)\n    out['auroc'] = auc\n    out['auroc_ci'] = auc_ci\n    out['note'] = ''\n    return out\n\n#------------------------------------------------------------------------------\n# 1) EXCLUDE ADVANCED CKD\n#------------------------------------------------------------------------------\nprint(\"\\n\" + \"=\"*70)\nprint(\"1. EXCLUDE ADVANCED CKD (eGFR <30 mL/min/1.73m\u00b2)\")\nprint(\"=\"*70)\n\ndf_no_ckd = df_base[df_base['chronic_advanced_ckd'] == 0].copy()\nsa1 = sensitivity_run(df_no_ckd, \"Exclude advanced CKD\", FIXED_Q20_THRESHOLD)\n\nprint(f\"\\nExcluded: {len(df_base) - len(df_no_ckd)} patients with advanced CKD\")\nprint(f\"Remaining: N = {sa1['n']:,}\")\nprint(f\"Events (efficiency \u2264{FIXED_Q20_THRESHOLD:.1f} mL/mg): {sa1['n_events']}\")\nprint(f\"Spearman \u03c1 = {sa1['spearman']:.3f} ({sa1['spearman_ci'][0]:.3f} to {sa1['spearman_ci'][1]:.3f})\")\nprint(f\"AUROC (Q20) = {sa1['auroc']:.3f} ({sa1['auroc_ci'][0]:.3f} to {sa1['auroc_ci'][1]:.3f})\")\n\ndelta_rho_ckd = sa1['spearman'] - primary_24h['spearman_rho']\ndelta_auroc_ckd = sa1['auroc'] - primary_24h['auroc_q20']\nprint(f\"\\nChange from primary: \u0394\u03c1 = {delta_rho_ckd:+.3f}, \u0394AUROC = {delta_auroc_ckd:+.3f}\")\n\nprint(\"\"\"\nNOTE:\n  Creatinine is a BAN-ADHF component and also a determinant of diuretic response.\n  Excluding advanced CKD reduces score variability (range restriction), which can attenuate correlation.\n\"\"\")\n\n#------------------------------------------------------------------------------\n# 2) EXCLUDE EXTREME OUTLIERS\n#------------------------------------------------------------------------------\nprint(\"\\n\" + \"=\"*70)\nprint(\"2. EXCLUDE EXTREME EFFICIENCY OUTLIERS (>99th percentile)\")\nprint(\"=\"*70)\n\np99 = df_base['diuretic_efficiency_24h'].quantile(0.99)\ndf_no_outliers = df_base[df_base['diuretic_efficiency_24h'] <= p99].copy()\nsa2 = sensitivity_run(df_no_outliers, \"Exclude outliers >P99\", FIXED_Q20_THRESHOLD)\n\nprint(f\"\\n99th percentile threshold: {p99:.1f} mL/mg\")\nprint(f\"Excluded: {len(df_base) - len(df_no_outliers)} extreme outliers\")\nprint(f\"Remaining: N = {sa2['n']:,}\")\nprint(f\"Events (efficiency \u2264{FIXED_Q20_THRESHOLD:.1f} mL/mg): {sa2['n_events']}\")\nprint(f\"Spearman \u03c1 = {sa2['spearman']:.3f} ({sa2['spearman_ci'][0]:.3f} to {sa2['spearman_ci'][1]:.3f})\")\nprint(f\"AUROC (Q20) = {sa2['auroc']:.3f} ({sa2['auroc_ci'][0]:.3f} to {sa2['auroc_ci'][1]:.3f})\")\n\n#------------------------------------------------------------------------------\n# 3) EXCLUDE CARDIOGENIC SHOCK\n#------------------------------------------------------------------------------\nprint(\"\\n\" + \"=\"*70)\nprint(\"3. EXCLUDE CARDIOGENIC SHOCK PATIENTS\")\nprint(\"=\"*70)\n\ndf_no_cs = df_base[df_base['cardiogenic_shock'] == 0].copy()\nsa3 = sensitivity_run(df_no_cs, \"Exclude cardiogenic shock\", FIXED_Q20_THRESHOLD)\n\nprint(f\"\\nExcluded: {len(df_base) - len(df_no_cs)} patients with cardiogenic shock\")\nprint(f\"Remaining: N = {sa3['n']:,}\")\nprint(f\"Events (efficiency \u2264{FIXED_Q20_THRESHOLD:.1f} mL/mg): {sa3['n_events']}\")\nprint(f\"Spearman \u03c1 = {sa3['spearman']:.3f} ({sa3['spearman_ci'][0]:.3f} to {sa3['spearman_ci'][1]:.3f})\")\nprint(f\"AUROC (Q20) = {sa3['auroc']:.3f} ({sa3['auroc_ci'][0]:.3f} to {sa3['auroc_ci'][1]:.3f})\")\n\n#------------------------------------------------------------------------------\n# 4) RESTRICT TO COMPLETE LVEF DATA\n#------------------------------------------------------------------------------\nprint(\"\\n\" + \"=\"*70)\nprint(\"4. RESTRICT TO PATIENTS WITH LVEF DATA\")\nprint(\"=\"*70)\n\ndf_lvef = df_base[df_base['lvef'].notna()].copy()\nsa4 = sensitivity_run(df_lvef, \"Complete LVEF data\", FIXED_Q20_THRESHOLD)\n\nprint(f\"\\nExcluded: {len(df_base) - len(df_lvef)} patients without LVEF\")\nprint(f\"Remaining: N = {sa4['n']:,}\")\nprint(f\"Events (efficiency \u2264{FIXED_Q20_THRESHOLD:.1f} mL/mg): {sa4['n_events']}\")\nprint(f\"Spearman \u03c1 = {sa4['spearman']:.3f} ({sa4['spearman_ci'][0]:.3f} to {sa4['spearman_ci'][1]:.3f})\")\nprint(f\"AUROC (Q20) = {sa4['auroc']:.3f} ({sa4['auroc_ci'][0]:.3f} to {sa4['auroc_ci'][1]:.3f})\")\n\n#------------------------------------------------------------------------------\n# 5) ALTERNATIVE EFFICIENCY THRESHOLDS\n#------------------------------------------------------------------------------\nprint(\"\\n\" + \"=\"*70)\nprint(\"5. ALTERNATIVE EFFICIENCY THRESHOLDS FOR AUROC\")\nprint(\"=\"*70)\n\nprint(f\"\\n{'Percentile':<10} {'Definition':<18} {'Threshold':<14} {'Events':<8} {'AUROC':<10} {'95% CI':<18}\")\nprint(\"-\"*85)\n\nthreshold_results = []\nfor percentile, label in [\n    (0.10, \"Lowest 10%\"),\n    (0.15, \"Lowest 15%\"),\n    (0.20, \"Lowest 20% (Q20)\"),\n    (0.25, \"Lowest 25% (Q25)\"),\n    (0.30, \"Lowest 30%\"),\n    (0.33, \"Lowest 33%\")\n]:\n    thr = df_base['diuretic_efficiency_24h'].quantile(percentile)\n    y = (df_base['diuretic_efficiency_24h'] <= thr).astype(int)\n    events = int(y.sum())\n\n    auc, auc_ci = bootstrap_auroc_ci(y, df_base['ban_adhf_total_score'], n_boot=n_bootstrap)\n    threshold_results.append({\n        'percentile': percentile,\n        'label': label,\n        'threshold': float(thr),\n        'n_events': events,\n        'auroc': auc,\n        'auroc_ci': auc_ci\n    })\n\n    marker = \"  <- primary\" if percentile == 0.20 else \"\"\n    print(f\"{int(percentile*100):<10} {label:<18} {thr:<14.1f} {events:<8} {auc:<10.3f} ({auc_ci[0]:.3f}\u2013{auc_ci[1]:.3f}){marker}\")\n\naucs = [r['auroc'] for r in threshold_results if r['auroc'] is not None]\nauroc_threshold_range = max(aucs) - min(aucs)\nprint(f\"\\nAUROC range across thresholds: {min(aucs):.3f} to {max(aucs):.3f} (spread: {auroc_threshold_range:.3f})\")\n\n#------------------------------------------------------------------------------\n# 6) ALTERNATIVE DIURETIC RESISTANCE DEFINITIONS\n#------------------------------------------------------------------------------\nprint(\"\\n\" + \"=\"*70)\nprint(\"6. ALTERNATIVE DIURETIC RESISTANCE DEFINITIONS\")\nprint(\"=\"*70)\n\ndf_dr_base = df[df['icu_stay_ge_24h'] == 1].copy()\nprint(f\"\\nCohort: ICU \u226524h (N = {len(df_dr_base):,})\")\n\nprint(f\"\\n{'Definition':<20} {'Resistant':<10} {'Prev':<8} {'AUROC':<10} {'95% CI':<18}\")\nprint(\"-\"*75)\n\ndr_results = []\nfor thr_uop in [2000, 2500, 3000, 3500, 4000]:\n    y = (df_dr_base['urine_output_24h_ml'] <= thr_uop).astype(int)\n    resistant = int(y.sum())\n    prev = 100 * resistant / len(df_dr_base)\n\n    auc, auc_ci = bootstrap_auroc_ci(y, df_dr_base['ban_adhf_total_score'], n_boot=n_bootstrap)\n    dr_results.append({\n        'threshold_ml': thr_uop,\n        'n_resistant': resistant,\n        'prevalence_pct': float(prev),\n        'auroc': auc,\n        'auroc_ci': auc_ci\n    })\n\n    marker = \"  <- primary\" if thr_uop == 3000 else \"\"\n    print(f\"UOP \u2264{thr_uop:<12} {resistant:<10} {prev:<8.1f} {auc:<10.3f} ({auc_ci[0]:.3f}\u2013{auc_ci[1]:.3f}){marker}\")\n\ndr_aucs = [r['auroc'] for r in dr_results if r['auroc'] is not None]\ndr_auroc_range = max(dr_aucs) - min(dr_aucs)\nprint(f\"\\nBinary DR AUROC range across thresholds: {min(dr_aucs):.3f} to {max(dr_aucs):.3f} (spread: {dr_auroc_range:.3f})\")\n\n#------------------------------------------------------------------------------\n# SUMMARY TABLE\n#------------------------------------------------------------------------------\nprint(\"\\n\" + \"=\"*70)\nprint(\"SENSITIVITY ANALYSIS SUMMARY TABLE\")\nprint(\"=\"*70)\n\ndef fmt_ci(ci):\n    if ci[0] is None:\n        return \"NA\"\n    return f\"({ci[0]:.3f}\u2013{ci[1]:.3f})\"\n\nrows = [\n    (\"Primary analysis\", primary_24h['n'], primary_24h['spearman_rho'], primary_24h['spearman_ci'], primary_24h['auroc_q20'], primary_24h['auroc_q20_ci']),\n    (\"Exclude advanced CKD*\", sa1['n'], sa1['spearman'], sa1['spearman_ci'], sa1['auroc'], sa1['auroc_ci']),\n    (\"Exclude outliers (>P99)\", sa2['n'], sa2['spearman'], sa2['spearman_ci'], sa2['auroc'], sa2['auroc_ci']),\n    (\"Exclude cardiogenic shock\", sa3['n'], sa3['spearman'], sa3['spearman_ci'], sa3['auroc'], sa3['auroc_ci']),\n    (\"Complete LVEF data only\", sa4['n'], sa4['spearman'], sa4['spearman_ci'], sa4['auroc'], sa4['auroc_ci']),\n]\n\nprint(f\"\\n{'Analysis':<28} {'N':<8} {'Spearman \u03c1':<12} {'95% CI':<18} {'AUROC Q20':<10} {'95% CI':<18} {'\u0394\u03c1':<8} {'\u0394AUC':<8}\")\nprint(\"-\"*115)\n\nfor name, n, rho, rho_ci, auc, auc_ci in rows:\n    d_rho = rho - primary_24h['spearman_rho']\n    d_auc = auc - primary_24h['auroc_q20']\n    print(f\"{name:<28} {n:<8} {rho:<12.3f} {fmt_ci(rho_ci):<18} {auc:<10.3f} {fmt_ci(auc_ci):<18} {d_rho:<+8.3f} {d_auc:<+8.3f}\")\n\nprint(\"\"\"\n*CKD exclusion attenuation is expected due to range restriction, as creatinine \n is both a score component and independent predictor of diuretic efficiency.\n\"\"\")\n\n#------------------------------------------------------------------------------\n# ROBUSTNESS ASSESSMENT\n#------------------------------------------------------------------------------\nrobust_rhos = [sa2['spearman'], sa3['spearman'], sa4['spearman']]\nrobust_aucs = [sa2['auroc'], sa3['auroc'], sa4['auroc']]\n\nrho_spread = max(robust_rhos) - min(robust_rhos)\nauc_spread = max(robust_aucs) - min(robust_aucs)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ROBUSTNESS ASSESSMENT\")\nprint(\"=\"*70)\n\nprint(f\"\"\"\nExcluding outliers, excluding cardiogenic shock, and restricting to LVEF-complete:\n  Spearman \u03c1 spread: {rho_spread:.3f}\n  AUROC Q20 spread:  {auc_spread:.3f}\n\nThreshold stability:\n  Efficiency AUROC spread (10% to 33%): {auroc_threshold_range:.3f}\n  Binary DR AUROC spread (UOP 2000 to 4000): {dr_auroc_range:.3f}\n\"\"\")\n\n#------------------------------------------------------------------------------\n# STORE RESULTS\n#------------------------------------------------------------------------------\nresults_sensitivity = {\n    'fixed_q20_threshold': float(FIXED_Q20_THRESHOLD),\n    'fixed_q25_threshold': float(FIXED_Q25_THRESHOLD),\n    'primary_24h': primary_24h,\n    'exclude_ckd': sa1,\n    'exclude_outliers': sa2,\n    'exclude_cs': sa3,\n    'complete_lvef': sa4,\n    'efficiency_thresholds': threshold_results,\n    'dr_thresholds': dr_results,\n    'robustness_excluding_ckd': {\n        'rho_spread': float(rho_spread),\n        'auc_spread': float(auc_spread),\n        'note': \"Excludes CKD run because range restriction can attenuate correlation by design.\"\n    }\n}\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"\u2713 Sensitivity analysis results stored in 'results_sensitivity' dictionary\")\nprint(\"=\"*70)\nprint(\"\\n\u2192 Next: Secondary Outcomes (vasopressor, inotrope, MCS, ventilation, LOS)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# SECTION 10: SECONDARY OUTCOMES\n",
    "# Cell 15: ICU Interventions and Length of Stay\n",
    "#==========================================================================\n",
    "# PURPOSE: Evaluate BAN-ADHF association with exploratory secondary ICU outcomes\n",
    "# OUTCOMES:\n",
    "#   1. Vasopressor use\n",
    "#   2. Inotrope use\n",
    "#   3. Mechanical circulatory support (MCS)\n",
    "#   4. Invasive mechanical ventilation\n",
    "#   5. ICU length of stay\n",
    "#   6. Hospital length of stay\n",
    "# OUTPUT:\n",
    "#   - Binary outcomes: prevalence, AUROC (bootstrap 95% CI), risk-category rates, chi-square p\n",
    "#   - Continuous outcomes: Spearman rho (bootstrap 95% CI), Kruskal-Wallis across risk categories\n",
    "#==========================================================================\n",
    "\n",
    "from scipy.stats import spearmanr, chi2_contingency, kruskal\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SECONDARY OUTCOMES ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nExploratory outcomes: ICU resource utilization and severity markers.\")\n",
    "print(\"BAN-ADHF was not designed for these outcomes.\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# ANALYSIS COHORT (Full cohort)\n",
    "#------------------------------------------------------------------------------\n",
    "df_sec = df.copy()\n",
    "print(f\"\\nAnalysis cohort: N = {len(df_sec):,}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# BOOTSTRAP SETUP\n",
    "#------------------------------------------------------------------------------\n",
    "np.random.seed(42)\n",
    "n_bootstrap = 1000\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# UTILITIES\n",
    "#------------------------------------------------------------------------------\n",
    "def format_p(p_val):\n",
    "    if p_val is None or (isinstance(p_val, float) and np.isnan(p_val)):\n",
    "        return \"NA\"\n",
    "    if p_val < 0.001:\n",
    "        return \"<0.001\"\n",
    "    return f\"{p_val:.3f}\"\n",
    "\n",
    "def bootstrap_auroc_ci(y, score, n_boot=1000):\n",
    "    y = pd.Series(y).reset_index(drop=True)\n",
    "    score = pd.Series(score).reset_index(drop=True)\n",
    "\n",
    "    if y.sum() == 0 or y.sum() == len(y):\n",
    "        return None, (None, None)\n",
    "\n",
    "    auc = roc_auc_score(y, score)\n",
    "\n",
    "    boot = []\n",
    "    for _ in range(n_boot):\n",
    "        idx = np.random.choice(len(y), size=len(y), replace=True)\n",
    "        yb = y.iloc[idx]\n",
    "        sb = score.iloc[idx]\n",
    "        if yb.sum() > 0 and yb.sum() < len(yb):\n",
    "            boot.append(roc_auc_score(yb, sb))\n",
    "\n",
    "    ci = (np.percentile(boot, 2.5), np.percentile(boot, 97.5))\n",
    "    return float(auc), (float(ci[0]), float(ci[1]))\n",
    "\n",
    "def bootstrap_spearman_ci(x, y, n_boot=1000):\n",
    "    rho, p = spearmanr(x, y)\n",
    "    boot = []\n",
    "    x = pd.Series(x).reset_index(drop=True)\n",
    "    y = pd.Series(y).reset_index(drop=True)\n",
    "\n",
    "    for _ in range(n_boot):\n",
    "        idx = np.random.choice(len(x), size=len(x), replace=True)\n",
    "        r, _ = spearmanr(x.iloc[idx], y.iloc[idx])\n",
    "        boot.append(r)\n",
    "\n",
    "    ci = (np.percentile(boot, 2.5), np.percentile(boot, 97.5))\n",
    "    return float(rho), (float(ci[0]), float(ci[1])), float(p)\n",
    "\n",
    "def safe_chi_square(risk_series, outcome_series):\n",
    "    \"\"\"\n",
    "    Returns (chi2, p_value) or (None, None) if test cannot be computed.\n",
    "    Handles cases where a category has zero count or only one outcome level.\n",
    "    \"\"\"\n",
    "    tab = pd.crosstab(risk_series, outcome_series)\n",
    "\n",
    "    # Need at least 2 rows and 2 columns for chi-square\n",
    "    if tab.shape[0] < 2 or tab.shape[1] < 2:\n",
    "        return None, None\n",
    "\n",
    "    try:\n",
    "        chi2, p, dof, expected = chi2_contingency(tab)\n",
    "        return float(chi2), float(p)\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "def analyze_binary_outcome(data, outcome_var, outcome_label):\n",
    "    \"\"\"\n",
    "    Binary outcome analysis:\n",
    "      - filters to rows with risk_category and ban_adhf_total_score present\n",
    "      - coerces outcome to 0/1 numeric\n",
    "      - AUROC with bootstrap CI if feasible\n",
    "      - rates by risk category\n",
    "      - chi-square test if feasible\n",
    "    \"\"\"\n",
    "    d = data.copy()\n",
    "\n",
    "    needed_cols = ['ban_adhf_total_score', 'risk_category', outcome_var]\n",
    "    for c in needed_cols:\n",
    "        if c not in d.columns:\n",
    "            raise KeyError(f\"Missing required column: {c}\")\n",
    "\n",
    "    d = d[d['ban_adhf_total_score'].notna() & d['risk_category'].notna()].copy()\n",
    "\n",
    "    # Coerce outcome to numeric 0/1\n",
    "    d[outcome_var] = pd.to_numeric(d[outcome_var], errors='coerce')\n",
    "    d = d[d[outcome_var].notna()].copy()\n",
    "\n",
    "    # If values are not strictly 0/1 but close, force to 0/1\n",
    "    d[outcome_var] = (d[outcome_var] > 0).astype(int)\n",
    "\n",
    "    n_total = int(len(d))\n",
    "    n_events = int(d[outcome_var].sum())\n",
    "    prevalence = 100 * n_events / n_total if n_total > 0 else 0.0\n",
    "\n",
    "    res = {\n",
    "        'outcome': outcome_label,\n",
    "        'n': n_total,\n",
    "        'n_events': n_events,\n",
    "        'prevalence': float(prevalence),\n",
    "        'auroc': None,\n",
    "        'auroc_ci': (None, None),\n",
    "        'rates_by_risk': {},\n",
    "        'chi2': None,\n",
    "        'p_value': None,\n",
    "        'rr_high_vs_low': None\n",
    "    }\n",
    "\n",
    "    # Rates by risk category\n",
    "    for cat in ['Low', 'Moderate', 'High']:\n",
    "        sub = d[d['risk_category'] == cat]\n",
    "        n = int(len(sub))\n",
    "        n_pos = int(sub[outcome_var].sum()) if n > 0 else 0\n",
    "        rate = 100 * n_pos / n if n > 0 else np.nan\n",
    "        res['rates_by_risk'][cat] = {'n': n, 'n_events': n_pos, 'rate': float(rate) if not np.isnan(rate) else np.nan}\n",
    "\n",
    "    # AUROC if feasible\n",
    "    if n_total >= 50 and n_events > 10 and n_events < (n_total - 10):\n",
    "        auc, auc_ci = bootstrap_auroc_ci(d[outcome_var], d['ban_adhf_total_score'], n_boot=n_bootstrap)\n",
    "        res['auroc'] = auc\n",
    "        res['auroc_ci'] = auc_ci\n",
    "\n",
    "    # Chi-square if feasible\n",
    "    chi2, p = safe_chi_square(d['risk_category'], d[outcome_var])\n",
    "    res['chi2'] = chi2\n",
    "    res['p_value'] = p\n",
    "\n",
    "    # Risk ratio (High vs Low)\n",
    "    low_rate = res['rates_by_risk']['Low']['rate']\n",
    "    high_rate = res['rates_by_risk']['High']['rate']\n",
    "    if low_rate is not None and not np.isnan(low_rate) and low_rate > 0 and high_rate is not None and not np.isnan(high_rate):\n",
    "        res['rr_high_vs_low'] = float(high_rate / low_rate)\n",
    "\n",
    "    return res\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 1. VASOPRESSOR USE\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"1. VASOPRESSOR USE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "vaso_results = analyze_binary_outcome(df_sec, 'vasopressor_use', 'Vasopressor use')\n",
    "\n",
    "print(f\"\\nPrevalence: {vaso_results['n_events']}/{vaso_results['n']} ({vaso_results['prevalence']:.1f}%)\")\n",
    "if vaso_results['auroc'] is not None:\n",
    "    print(f\"AUROC: {vaso_results['auroc']:.3f} ({vaso_results['auroc_ci'][0]:.3f} to {vaso_results['auroc_ci'][1]:.3f})\")\n",
    "else:\n",
    "    print(\"AUROC: N/A (insufficient events or no variation)\")\n",
    "\n",
    "print(\"\\nRates by Risk Category:\")\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    r = vaso_results['rates_by_risk'][cat]\n",
    "    rate_str = \"NA\" if np.isnan(r['rate']) else f\"{r['rate']:.1f}%\"\n",
    "    print(f\"  {cat}: {r['n_events']}/{r['n']} ({rate_str})\")\n",
    "\n",
    "print(f\"\\nChi-square: {vaso_results['chi2']:.1f}\" if vaso_results['chi2'] is not None else \"\\nChi-square: NA\")\n",
    "print(f\"p = {format_p(vaso_results['p_value'])}\")\n",
    "if vaso_results['rr_high_vs_low'] is not None:\n",
    "    print(f\"Risk ratio (High vs Low): {vaso_results['rr_high_vs_low']:.2f}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 2. INOTROPE USE\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"2. INOTROPE USE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "ino_results = analyze_binary_outcome(df_sec, 'inotrope_use', 'Inotrope use')\n",
    "\n",
    "print(f\"\\nPrevalence: {ino_results['n_events']}/{ino_results['n']} ({ino_results['prevalence']:.1f}%)\")\n",
    "if ino_results['auroc'] is not None:\n",
    "    print(f\"AUROC: {ino_results['auroc']:.3f} ({ino_results['auroc_ci'][0]:.3f} to {ino_results['auroc_ci'][1]:.3f})\")\n",
    "else:\n",
    "    print(\"AUROC: N/A (insufficient events or no variation)\")\n",
    "\n",
    "print(\"\\nRates by Risk Category:\")\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    r = ino_results['rates_by_risk'][cat]\n",
    "    rate_str = \"NA\" if np.isnan(r['rate']) else f\"{r['rate']:.1f}%\"\n",
    "    print(f\"  {cat}: {r['n_events']}/{r['n']} ({rate_str})\")\n",
    "\n",
    "print(f\"\\nChi-square: {ino_results['chi2']:.1f}\" if ino_results['chi2'] is not None else \"\\nChi-square: NA\")\n",
    "print(f\"p = {format_p(ino_results['p_value'])}\")\n",
    "if ino_results['rr_high_vs_low'] is not None:\n",
    "    print(f\"Risk ratio (High vs Low): {ino_results['rr_high_vs_low']:.2f}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 3. MECHANICAL CIRCULATORY SUPPORT (MCS)\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"3. MECHANICAL CIRCULATORY SUPPORT (MCS)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "mcs_results = analyze_binary_outcome(df_sec, 'mcs_use', 'MCS use')\n",
    "\n",
    "print(f\"\\nPrevalence: {mcs_results['n_events']}/{mcs_results['n']} ({mcs_results['prevalence']:.1f}%)\")\n",
    "if mcs_results['auroc'] is not None:\n",
    "    print(f\"AUROC: {mcs_results['auroc']:.3f} ({mcs_results['auroc_ci'][0]:.3f} to {mcs_results['auroc_ci'][1]:.3f})\")\n",
    "else:\n",
    "    print(\"AUROC: N/A (insufficient events or no variation)\")\n",
    "\n",
    "print(\"\\nRates by Risk Category:\")\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    r = mcs_results['rates_by_risk'][cat]\n",
    "    rate_str = \"NA\" if np.isnan(r['rate']) else f\"{r['rate']:.1f}%\"\n",
    "    print(f\"  {cat}: {r['n_events']}/{r['n']} ({rate_str})\")\n",
    "\n",
    "print(f\"\\nChi-square: {mcs_results['chi2']:.1f}\" if mcs_results['chi2'] is not None else \"\\nChi-square: NA\")\n",
    "print(f\"p = {format_p(mcs_results['p_value'])}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 4. INVASIVE MECHANICAL VENTILATION\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"4. INVASIVE MECHANICAL VENTILATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "vent_results = analyze_binary_outcome(df_sec, 'invasive_vent', 'Invasive ventilation')\n",
    "\n",
    "print(f\"\\nPrevalence: {vent_results['n_events']}/{vent_results['n']} ({vent_results['prevalence']:.1f}%)\")\n",
    "if vent_results['auroc'] is not None:\n",
    "    print(f\"AUROC: {vent_results['auroc']:.3f} ({vent_results['auroc_ci'][0]:.3f} to {vent_results['auroc_ci'][1]:.3f})\")\n",
    "else:\n",
    "    print(\"AUROC: N/A (insufficient events or no variation)\")\n",
    "\n",
    "print(\"\\nRates by Risk Category:\")\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    r = vent_results['rates_by_risk'][cat]\n",
    "    rate_str = \"NA\" if np.isnan(r['rate']) else f\"{r['rate']:.1f}%\"\n",
    "    print(f\"  {cat}: {r['n_events']}/{r['n']} ({rate_str})\")\n",
    "\n",
    "print(f\"\\nChi-square: {vent_results['chi2']:.1f}\" if vent_results['chi2'] is not None else \"\\nChi-square: NA\")\n",
    "print(f\"p = {format_p(vent_results['p_value'])}\")\n",
    "if vent_results['rr_high_vs_low'] is not None:\n",
    "    print(f\"Risk ratio (High vs Low): {vent_results['rr_high_vs_low']:.2f}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 5. ICU LENGTH OF STAY\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"5. ICU LENGTH OF STAY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_los = df_sec[df_sec['icu_los_days'].notna() & df_sec['ban_adhf_total_score'].notna() & df_sec['risk_category'].notna()].copy()\n",
    "rho_icu, rho_icu_ci, p_icu = bootstrap_spearman_ci(df_los['ban_adhf_total_score'], df_los['icu_los_days'], n_boot=n_bootstrap)\n",
    "\n",
    "print(f\"\\nN = {len(df_los):,}\")\n",
    "print(f\"Spearman \u03c1 = {rho_icu:.3f} ({rho_icu_ci[0]:.3f} to {rho_icu_ci[1]:.3f})\")\n",
    "print(f\"p = {format_p(p_icu)}\")\n",
    "\n",
    "print(\"\\nICU LOS by Risk Category:\")\n",
    "print(f\"{'Category':<12} {'N':<8} {'Median (IQR)':<18} {'Mean \u00b1 SD':<14}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "icu_los_by_risk = {}\n",
    "groups_icu = []\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    s = df_los[df_los['risk_category'] == cat]['icu_los_days'].dropna()\n",
    "    n = int(len(s))\n",
    "    median = float(s.median()) if n > 0 else np.nan\n",
    "    q1 = float(s.quantile(0.25)) if n > 0 else np.nan\n",
    "    q3 = float(s.quantile(0.75)) if n > 0 else np.nan\n",
    "    mean = float(s.mean()) if n > 0 else np.nan\n",
    "    std = float(s.std()) if n > 1 else np.nan\n",
    "    icu_los_by_risk[cat] = {'n': n, 'median': median, 'iqr': (q1, q3), 'mean': mean, 'std': std}\n",
    "    groups_icu.append(s.values)\n",
    "\n",
    "    med_str = \"NA\" if np.isnan(median) else f\"{median:.1f} ({q1:.1f} to {q3:.1f})\"\n",
    "    mean_str = \"NA\" if np.isnan(mean) else f\"{mean:.1f} \u00b1 {std:.1f}\"\n",
    "    print(f\"{cat:<12} {n:<8} {med_str:<18} {mean_str:<14}\")\n",
    "\n",
    "# Kruskal-Wallis only if at least 2 groups have data\n",
    "nonempty = [g for g in groups_icu if len(g) > 0]\n",
    "if len(nonempty) >= 2:\n",
    "    kw_icu, p_kw_icu = kruskal(*nonempty)\n",
    "    print(f\"\\nKruskal-Wallis H = {kw_icu:.1f}, p = {format_p(p_kw_icu)}\")\n",
    "else:\n",
    "    kw_icu, p_kw_icu = None, None\n",
    "    print(\"\\nKruskal-Wallis: NA (insufficient group data)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# 6. HOSPITAL LENGTH OF STAY\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"6. HOSPITAL LENGTH OF STAY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_hlos = df_sec[df_sec['hospital_los_days'].notna() & df_sec['ban_adhf_total_score'].notna() & df_sec['risk_category'].notna()].copy()\n",
    "rho_hosp, rho_hosp_ci, p_hosp = bootstrap_spearman_ci(df_hlos['ban_adhf_total_score'], df_hlos['hospital_los_days'], n_boot=n_bootstrap)\n",
    "\n",
    "print(f\"\\nN = {len(df_hlos):,}\")\n",
    "print(f\"Spearman \u03c1 = {rho_hosp:.3f} ({rho_hosp_ci[0]:.3f} to {rho_hosp_ci[1]:.3f})\")\n",
    "print(f\"p = {format_p(p_hosp)}\")\n",
    "\n",
    "print(\"\\nHospital LOS by Risk Category:\")\n",
    "print(f\"{'Category':<12} {'N':<8} {'Median (IQR)':<18} {'Mean \u00b1 SD':<14}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "hosp_los_by_risk = {}\n",
    "groups_hosp = []\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    s = df_hlos[df_hlos['risk_category'] == cat]['hospital_los_days'].dropna()\n",
    "    n = int(len(s))\n",
    "    median = float(s.median()) if n > 0 else np.nan\n",
    "    q1 = float(s.quantile(0.25)) if n > 0 else np.nan\n",
    "    q3 = float(s.quantile(0.75)) if n > 0 else np.nan\n",
    "    mean = float(s.mean()) if n > 0 else np.nan\n",
    "    std = float(s.std()) if n > 1 else np.nan\n",
    "    hosp_los_by_risk[cat] = {'n': n, 'median': median, 'iqr': (q1, q3), 'mean': mean, 'std': std}\n",
    "    groups_hosp.append(s.values)\n",
    "\n",
    "    med_str = \"NA\" if np.isnan(median) else f\"{median:.1f} ({q1:.1f} to {q3:.1f})\"\n",
    "    mean_str = \"NA\" if np.isnan(mean) else f\"{mean:.1f} \u00b1 {std:.1f}\"\n",
    "    print(f\"{cat:<12} {n:<8} {med_str:<18} {mean_str:<14}\")\n",
    "\n",
    "nonempty = [g for g in groups_hosp if len(g) > 0]\n",
    "if len(nonempty) >= 2:\n",
    "    kw_hosp, p_kw_hosp = kruskal(*nonempty)\n",
    "    print(f\"\\nKruskal-Wallis H = {kw_hosp:.1f}, p = {format_p(p_kw_hosp)}\")\n",
    "else:\n",
    "    kw_hosp, p_kw_hosp = None, None\n",
    "    print(\"\\nKruskal-Wallis: NA (insufficient group data)\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# SUMMARY TABLE: SECONDARY OUTCOMES\n",
    "#------------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY TABLE: SECONDARY OUTCOMES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nBINARY OUTCOMES:\")\n",
    "print(f\"{'Outcome':<24} {'Prevalence':<12} {'AUROC (95% CI)':<22} {'p':<8}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "binary_outcomes = [\n",
    "    ('Vasopressor use', vaso_results),\n",
    "    ('Inotrope use', ino_results),\n",
    "    ('MCS use', mcs_results),\n",
    "    ('Invasive ventilation', vent_results)\n",
    "]\n",
    "\n",
    "for name, res in binary_outcomes:\n",
    "    prev_str = f\"{res['prevalence']:.1f}%\"\n",
    "    if res['auroc'] is not None:\n",
    "        auroc_str = f\"{res['auroc']:.3f} ({res['auroc_ci'][0]:.3f} to {res['auroc_ci'][1]:.3f})\"\n",
    "    else:\n",
    "        auroc_str = \"NA\"\n",
    "    p_str = format_p(res['p_value'])\n",
    "    print(f\"{name:<24} {prev_str:<12} {auroc_str:<22} {p_str:<8}\")\n",
    "\n",
    "print(\"\\nCONTINUOUS OUTCOMES:\")\n",
    "print(f\"{'Outcome':<24} {'N':<8} {'Spearman \u03c1 (95% CI)':<26} {'p':<8}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'ICU length of stay':<24} {len(df_los):<8} {rho_icu:.3f} ({rho_icu_ci[0]:.3f} to {rho_icu_ci[1]:.3f})   {format_p(p_icu):<8}\")\n",
    "print(f\"{'Hospital length of stay':<24} {len(df_hlos):<8} {rho_hosp:.3f} ({rho_hosp_ci[0]:.3f} to {rho_hosp_ci[1]:.3f})   {format_p(p_hosp):<8}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# STORE RESULTS\n",
    "#------------------------------------------------------------------------------\n",
    "results_secondary = {\n",
    "    'vasopressor': vaso_results,\n",
    "    'inotrope': ino_results,\n",
    "    'mcs': mcs_results,\n",
    "    'ventilation': vent_results,\n",
    "    'icu_los': {\n",
    "        'n': int(len(df_los)),\n",
    "        'spearman_rho': float(rho_icu),\n",
    "        'spearman_ci': tuple(rho_icu_ci),\n",
    "        'p_value': float(p_icu),\n",
    "        'kruskal_h': None if kw_icu is None else float(kw_icu),\n",
    "        'kruskal_p': None if p_kw_icu is None else float(p_kw_icu),\n",
    "        'by_risk': icu_los_by_risk\n",
    "    },\n",
    "    'hospital_los': {\n",
    "        'n': int(len(df_hlos)),\n",
    "        'spearman_rho': float(rho_hosp),\n",
    "        'spearman_ci': tuple(rho_hosp_ci),\n",
    "        'p_value': float(p_hosp),\n",
    "        'kruskal_h': None if kw_hosp is None else float(kw_hosp),\n",
    "        'kruskal_p': None if p_kw_hosp is None else float(p_kw_hosp),\n",
    "        'by_risk': hosp_los_by_risk\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\u2713 Secondary outcomes stored in 'results_secondary' dictionary\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n\u2192 Next: Tables and Figures\")\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# SECTION 12: MAIN MANUSCRIPT TABLES\n",
    "# Cell 16: Generate Tables 1, 2, and 3\n",
    "#==========================================================================\n",
    "\n",
    "from tableone import TableOne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from scipy.stats import kruskal, chi2_contingency\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MAIN MANUSCRIPT TABLES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Small helpers\n",
    "def safe_chi_square(df_in, group_col, outcome_col):\n",
    "    tab = pd.crosstab(df_in[group_col], df_in[outcome_col])\n",
    "    if tab.shape[0] < 2 or tab.shape[1] < 2:\n",
    "        return None\n",
    "    try:\n",
    "        chi2, p, dof, exp = chi2_contingency(tab)\n",
    "        return float(p)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def format_p(p):\n",
    "    if p is None or (isinstance(p, float) and np.isnan(p)):\n",
    "        return \"NA\"\n",
    "    if p < 0.001:\n",
    "        return \"<0.001\"\n",
    "    return f\"{p:.3f}\"\n",
    "\n",
    "#==========================================================================\n",
    "# TABLE 1: BASELINE CHARACTERISTICS BY BAN-ADHF RISK CATEGORY\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TABLE 1: Baseline Characteristics by BAN-ADHF Risk Category\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_table1 = df.copy()\n",
    "\n",
    "# Create male_sex variable\n",
    "if 'gender' in df_table1.columns:\n",
    "    if df_table1['gender'].dtype == 'object':\n",
    "        df_table1['male_sex'] = (df_table1['gender'].astype(str).str.upper().str.strip() == 'M').astype(int)\n",
    "    else:\n",
    "        df_table1['male_sex'] = pd.to_numeric(df_table1['gender'], errors='coerce')\n",
    "else:\n",
    "    # If gender not present, keep placeholder to avoid crash if someone left it in the column list\n",
    "    df_table1['male_sex'] = np.nan\n",
    "\n",
    "# Risk category as string\n",
    "df_table1['risk_category'] = df_table1['risk_category'].astype(str)\n",
    "\n",
    "# Convert binary variables to Yes/No for TableOne display\n",
    "binary_vars_to_fix = [\n",
    "    'male_sex', 'hx_atrial_fibrillation', 'hx_hypertension',\n",
    "    'prior_hf_hospitalization_12mo', 'hx_diabetes', 'hx_renal_disease',\n",
    "    'hx_myocardial_infarction', 'hx_stroke', 'hx_copd',\n",
    "    'cardiogenic_shock', 'invasive_vent'\n",
    "]\n",
    "\n",
    "for var in binary_vars_to_fix:\n",
    "    if var in df_table1.columns:\n",
    "        df_table1[var] = pd.to_numeric(df_table1[var], errors='coerce')\n",
    "        df_table1[var] = df_table1[var].map({1: 'Yes', 0: 'No'})\n",
    "\n",
    "# Define variables\n",
    "all_columns = [\n",
    "    'age', 'male_sex', 'ban_adhf_total_score',\n",
    "    'creatinine', 'bun', 'ntprobnp', 'dbp',\n",
    "    'total_furosemide_equivalent_mg',\n",
    "    'hx_atrial_fibrillation', 'hx_hypertension', 'prior_hf_hospitalization_12mo',\n",
    "    'lvef', 'hf_phenotype',\n",
    "    'hx_diabetes', 'hx_renal_disease', 'hx_myocardial_infarction',\n",
    "    'hx_stroke', 'hx_copd', 'cci_score',\n",
    "    'cardiogenic_shock', 'invasive_vent'\n",
    "]\n",
    "all_columns = [v for v in all_columns if v in df_table1.columns]\n",
    "\n",
    "categorical_vars = [\n",
    "    'male_sex', 'hx_atrial_fibrillation', 'hx_hypertension',\n",
    "    'prior_hf_hospitalization_12mo', 'hf_phenotype',\n",
    "    'hx_diabetes', 'hx_renal_disease', 'hx_myocardial_infarction',\n",
    "    'hx_stroke', 'hx_copd', 'cardiogenic_shock', 'invasive_vent'\n",
    "]\n",
    "categorical_vars = [v for v in categorical_vars if v in df_table1.columns]\n",
    "\n",
    "nonnormal_vars = ['ban_adhf_total_score', 'creatinine', 'bun', 'ntprobnp',\n",
    "                  'total_furosemide_equivalent_mg', 'cci_score']\n",
    "nonnormal_vars = [v for v in nonnormal_vars if v in df_table1.columns]\n",
    "\n",
    "labels = {\n",
    "    'age': 'Age, years',\n",
    "    'male_sex': 'Male sex',\n",
    "    'ban_adhf_total_score': 'BAN-ADHF score',\n",
    "    'creatinine': 'Creatinine, mg/dL',\n",
    "    'bun': 'BUN, mg/dL',\n",
    "    'ntprobnp': 'NT-proBNP, pg/mL',\n",
    "    'dbp': 'Diastolic BP, mmHg',\n",
    "    'total_furosemide_equivalent_mg': 'Home diuretic dose, mg/day +',\n",
    "    'hx_atrial_fibrillation': 'Atrial fibrillation',\n",
    "    'hx_hypertension': 'Hypertension',\n",
    "    'prior_hf_hospitalization_12mo': 'Prior HF hospitalization (12 mo)',\n",
    "    'lvef': 'LVEF, % ++',\n",
    "    'hf_phenotype': 'HF phenotype ++',\n",
    "    'hx_diabetes': 'Diabetes mellitus',\n",
    "    'hx_renal_disease': 'Chronic kidney disease',\n",
    "    'hx_myocardial_infarction': 'Prior myocardial infarction',\n",
    "    'hx_stroke': 'Prior stroke',\n",
    "    'hx_copd': 'COPD',\n",
    "    'cci_score': 'Charlson Comorbidity Index',\n",
    "    'cardiogenic_shock': 'Cardiogenic shock',\n",
    "    'invasive_vent': 'Invasive mechanical ventilation'\n",
    "}\n",
    "\n",
    "order = {\n",
    "    'risk_category': ['Low', 'Moderate', 'High'],\n",
    "    'male_sex': ['Yes', 'No'],\n",
    "    'hx_atrial_fibrillation': ['Yes', 'No'],\n",
    "    'hx_hypertension': ['Yes', 'No'],\n",
    "    'prior_hf_hospitalization_12mo': ['Yes', 'No'],\n",
    "    'hx_diabetes': ['Yes', 'No'],\n",
    "    'hx_renal_disease': ['Yes', 'No'],\n",
    "    'hx_myocardial_infarction': ['Yes', 'No'],\n",
    "    'hx_stroke': ['Yes', 'No'],\n",
    "    'hx_copd': ['Yes', 'No'],\n",
    "    'cardiogenic_shock': ['Yes', 'No'],\n",
    "    'invasive_vent': ['Yes', 'No']\n",
    "}\n",
    "\n",
    "limit = {k: 1 for k in order.keys() if k != 'risk_category'}\n",
    "\n",
    "table1 = TableOne(\n",
    "    df_table1,\n",
    "    columns=all_columns,\n",
    "    categorical=categorical_vars,\n",
    "    nonnormal=nonnormal_vars,\n",
    "    groupby='risk_category',\n",
    "    pval=True,\n",
    "    rename=labels,\n",
    "    missing=False,\n",
    "    overall=True,\n",
    "    order=order,\n",
    "    limit=limit,\n",
    "    decimals=1\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(table1.tabulate(tablefmt=\"simple\"))\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"+ Home diuretic dose as oral furosemide equivalents\")\n",
    "if 'lvef' in df_table1.columns:\n",
    "    print(\"++ LVEF available in\", int(df_table1['lvef'].notna().sum()), \"patients\")\n",
    "\n",
    "table1.to_csv('/content/Table1_baseline_by_risk.csv')\n",
    "table1.to_excel('/content/Table1_baseline_by_risk.xlsx')\n",
    "print(\"\\n\u2713 Table 1 saved\")\n",
    "\n",
    "# Verification gradients (uses original df, not the Yes/No transformed df_table1)\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"VERIFICATION: Comorbidity Gradients (should increase with higher risk)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "df_verify = df.copy()\n",
    "for col in ['hx_diabetes', 'hx_renal_disease', 'cardiogenic_shock', 'prior_hf_hospitalization_12mo']:\n",
    "    if col in df_verify.columns:\n",
    "        df_verify[col] = pd.to_numeric(df_verify[col], errors='coerce')\n",
    "\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    subset = df_verify[df_verify['risk_category'] == cat]\n",
    "    n = len(subset)\n",
    "    dm_pct = 100 * subset['hx_diabetes'].mean() if 'hx_diabetes' in subset.columns else np.nan\n",
    "    ckd_pct = 100 * subset['hx_renal_disease'].mean() if 'hx_renal_disease' in subset.columns else np.nan\n",
    "    cs_pct = 100 * subset['cardiogenic_shock'].mean() if 'cardiogenic_shock' in subset.columns else np.nan\n",
    "    hf_hosp = 100 * subset['prior_hf_hospitalization_12mo'].mean() if 'prior_hf_hospitalization_12mo' in subset.columns else np.nan\n",
    "    print(f\"  {cat}: DM={dm_pct:.1f}%, CKD={ckd_pct:.1f}%, CS={cs_pct:.1f}%, Prior HF hosp={hf_hosp:.1f}%\")\n",
    "\n",
    "#==========================================================================\n",
    "# CALCULATE EFFICIENCY BY RISK FOR TABLE 2\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Calculating efficiency distributions by risk category\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "df_24h = df[(df['icu_stay_ge_24h'] == 1) &\n",
    "            (df['diuretic_efficiency_24h'].notna()) &\n",
    "            (df['diuretic_efficiency_24h'] > 0)].copy()\n",
    "\n",
    "eff_24h_by_risk = {}\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    subset = df_24h[df_24h['risk_category'] == cat]['diuretic_efficiency_24h']\n",
    "    eff_24h_by_risk[cat] = {\n",
    "        'n': int(len(subset)),\n",
    "        'median': float(subset.median()),\n",
    "        'q1': float(subset.quantile(0.25)),\n",
    "        'q3': float(subset.quantile(0.75))\n",
    "    }\n",
    "    print(f\"  24h {cat}: N={eff_24h_by_risk[cat]['n']}, Median={eff_24h_by_risk[cat]['median']:.1f} [{eff_24h_by_risk[cat]['q1']:.1f} to {eff_24h_by_risk[cat]['q3']:.1f}]\")\n",
    "\n",
    "df_72h = df[(df['icu_stay_ge_72h'] == 1) &\n",
    "            (df['diuretic_efficiency_72h'].notna()) &\n",
    "            (df['diuretic_efficiency_72h'] > 0)].copy()\n",
    "\n",
    "eff_72h_by_risk = {}\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    subset = df_72h[df_72h['risk_category'] == cat]['diuretic_efficiency_72h']\n",
    "    eff_72h_by_risk[cat] = {\n",
    "        'n': int(len(subset)),\n",
    "        'median': float(subset.median()),\n",
    "        'q1': float(subset.quantile(0.25)),\n",
    "        'q3': float(subset.quantile(0.75))\n",
    "    }\n",
    "    print(f\"  72h {cat}: N={eff_72h_by_risk[cat]['n']}, Median={eff_72h_by_risk[cat]['median']:.1f} [{eff_72h_by_risk[cat]['q1']:.1f} to {eff_72h_by_risk[cat]['q3']:.1f}]\")\n",
    "\n",
    "# Kruskal-Wallis p across risk categories for efficiency rows\n",
    "groups_24h = [df_24h[df_24h['risk_category'] == cat]['diuretic_efficiency_24h'].values for cat in ['Low', 'Moderate', 'High']]\n",
    "groups_24h = [g for g in groups_24h if len(g) > 0]\n",
    "p_kw_24h = kruskal(*groups_24h).pvalue if len(groups_24h) >= 2 else None\n",
    "\n",
    "groups_72h = [df_72h[df_72h['risk_category'] == cat]['diuretic_efficiency_72h'].values for cat in ['Low', 'Moderate', 'High']]\n",
    "groups_72h = [g for g in groups_72h if len(g) > 0]\n",
    "p_kw_72h = kruskal(*groups_72h).pvalue if len(groups_72h) >= 2 else None\n",
    "\n",
    "#==========================================================================\n",
    "# TABLE 2: PRIMARY OUTCOMES AND DISCRIMINATION SUMMARY\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TABLE 2: Primary Outcomes and Discrimination Summary\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "table2_rows = []\n",
    "\n",
    "# 24-Hour Diuretic Efficiency\n",
    "table2_rows.append(['24-Hour Diuretic Efficiency', 'N', f\"{results_24h['n']:,}\", 'NA', 'NA'])\n",
    "table2_rows.append(['', 'Spearman rho', f\"{results_24h['spearman_rho']:.3f}\",\n",
    "                    f\"({results_24h['spearman_ci'][0]:.3f}, {results_24h['spearman_ci'][1]:.3f})\", \"<0.001\"])\n",
    "table2_rows.append(['', 'Pearson r', f\"{results_24h['pearson_r']:.3f}\",\n",
    "                    f\"({results_24h['pearson_ci'][0]:.3f}, {results_24h['pearson_ci'][1]:.3f})\", \"<0.001\"])\n",
    "table2_rows.append(['', 'C-index', f\"{results_24h['c_index']:.3f}\",\n",
    "                    f\"({results_24h['c_index_ci'][0]:.3f}, {results_24h['c_index_ci'][1]:.3f})\", \"NA\"])\n",
    "table2_rows.append(['', 'AUROC (Q20)', f\"{results_24h['auroc_quintile']:.3f}\",\n",
    "                    f\"({results_24h['auroc_quintile_ci'][0]:.3f}, {results_24h['auroc_quintile_ci'][1]:.3f})\", \"NA\"])\n",
    "table2_rows.append(['', 'AUROC (Q25)', f\"{results_24h['auroc_quartile']:.3f}\",\n",
    "                    f\"({results_24h['auroc_quartile_ci'][0]:.3f}, {results_24h['auroc_quartile_ci'][1]:.3f})\", \"NA\"])\n",
    "table2_rows.append(['', 'Efficiency by risk (median [Q1 to Q3])', '', '', f\"{format_p(p_kw_24h)} *\"])\n",
    "\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    e = eff_24h_by_risk[cat]\n",
    "    table2_rows.append(['', f'  {cat}, mL/mg', f\"{e['median']:.1f}\", f\"[{e['q1']:.1f} to {e['q3']:.1f}]\", ''])\n",
    "\n",
    "# 72-Hour Diuretic Efficiency\n",
    "table2_rows.append(['72-Hour Diuretic Efficiency', 'N', f\"{results_72h['n']:,}\", 'NA', 'NA'])\n",
    "table2_rows.append(['', 'Spearman rho', f\"{results_72h['spearman_rho']:.3f}\",\n",
    "                    f\"({results_72h['spearman_ci'][0]:.3f}, {results_72h['spearman_ci'][1]:.3f})\", \"<0.001\"])\n",
    "table2_rows.append(['', 'AUROC (Q20)', f\"{results_72h['auroc_quintile']:.3f}\",\n",
    "                    f\"({results_72h['auroc_quintile_ci'][0]:.3f}, {results_72h['auroc_quintile_ci'][1]:.3f})\", \"NA\"])\n",
    "table2_rows.append(['', 'Efficiency by risk (median [Q1 to Q3])', '', '', f\"{format_p(p_kw_72h)} *\"])\n",
    "\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    e = eff_72h_by_risk[cat]\n",
    "    table2_rows.append(['', f'  {cat}, mL/mg', f\"{e['median']:.1f}\", f\"[{e['q1']:.1f} to {e['q3']:.1f}]\", ''])\n",
    "\n",
    "# Diuretic Resistance\n",
    "table2_rows.append(['Diuretic Resistance +', 'N', f\"{results_dr['n']:,}\", 'NA', 'NA'])\n",
    "table2_rows.append(['', 'Prevalence', f\"{results_dr['prevalence']:.1f}%\", 'NA', 'NA'])\n",
    "table2_rows.append(['', 'AUROC', f\"{results_dr['auroc']:.3f}\",\n",
    "                    f\"({results_dr['auroc_ci'][0]:.3f}, {results_dr['auroc_ci'][1]:.3f})\", \"NA\"])\n",
    "\n",
    "p_dr_risk = None\n",
    "if 'dr_by_risk' in results_dr and 'risk_category' in df.columns and 'diuretic_resistance' in df.columns:\n",
    "    df_tmp = df[['risk_category', 'diuretic_resistance']].dropna().copy()\n",
    "    df_tmp['diuretic_resistance'] = pd.to_numeric(df_tmp['diuretic_resistance'], errors='coerce')\n",
    "    df_tmp = df_tmp[df_tmp['diuretic_resistance'].notna()]\n",
    "    df_tmp['diuretic_resistance'] = (df_tmp['diuretic_resistance'] > 0).astype(int)\n",
    "    p_dr_risk = safe_chi_square(df_tmp, 'risk_category', 'diuretic_resistance')\n",
    "\n",
    "table2_rows.append(['', 'DR rate by risk', '', '', f\"{format_p(p_dr_risk)} *\"])\n",
    "\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    rate = results_dr['dr_by_risk'][cat]['rate']\n",
    "    table2_rows.append(['', f'  {cat}', f\"{rate:.1f}%\", 'NA', ''])\n",
    "\n",
    "# Mortality\n",
    "table2_rows.append(['In-Hospital Mortality ++', 'N', f\"{results_mortality['n']:,}\", 'NA', 'NA'])\n",
    "table2_rows.append(['', 'Mortality rate', f\"{results_mortality['mortality_rate']:.1f}%\", 'NA', 'NA'])\n",
    "table2_rows.append(['', 'AUROC', f\"{results_mortality['auroc']:.3f}\",\n",
    "                    f\"({results_mortality['auroc_ci'][0]:.3f}, {results_mortality['auroc_ci'][1]:.3f})\", \"NA\"])\n",
    "table2_rows.append(['', 'AUROC (CS subgroup)', f\"{results_mortality['auroc_cs']:.3f}\", 'NA', 'NA'])\n",
    "\n",
    "p_mort_risk = None\n",
    "if 'mort_by_risk' in results_mortality and 'risk_category' in df.columns and 'in_hospital_mortality' in df.columns:\n",
    "    df_tmp = df[['risk_category', 'in_hospital_mortality']].dropna().copy()\n",
    "    df_tmp['in_hospital_mortality'] = pd.to_numeric(df_tmp['in_hospital_mortality'], errors='coerce')\n",
    "    df_tmp = df_tmp[df_tmp['in_hospital_mortality'].notna()]\n",
    "    df_tmp['in_hospital_mortality'] = (df_tmp['in_hospital_mortality'] > 0).astype(int)\n",
    "    p_mort_risk = safe_chi_square(df_tmp, 'risk_category', 'in_hospital_mortality')\n",
    "\n",
    "table2_rows.append(['', 'Mortality by risk', '', '', f\"{format_p(p_mort_risk)} *\"])\n",
    "\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    rate = results_mortality['mort_by_risk'][cat]['rate']\n",
    "    table2_rows.append(['', f'  {cat}', f\"{rate:.1f}%\", 'NA', ''])\n",
    "\n",
    "table2_df = pd.DataFrame(table2_rows, columns=['Outcome', 'Metric', 'Value', '95% CI', 'p-value'])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(table2_df.to_string(index=False))\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"* Kruskal-Wallis (efficiency) or Chi-square (binary) across risk categories\")\n",
    "print(\"+ Urine output <=3,000 mL in first 24 hours\")\n",
    "print(\"++ Exploratory outcome. BAN-ADHF designed for diuretic efficiency\")\n",
    "\n",
    "table2_df.to_csv('/content/Table2_outcomes_discrimination.csv', index=False)\n",
    "table2_df.to_excel('/content/Table2_outcomes_discrimination.xlsx', index=False)\n",
    "print(\"\\n\u2713 Table 2 saved\")\n",
    "\n",
    "#==========================================================================\n",
    "# TABLE 3: LITERATURE COMPARISON\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TABLE 3: Literature Comparison\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "delta_pearson = ((abs(results_24h['pearson_r']) - 0.40) / 0.40) * 100\n",
    "delta_q20 = ((results_24h['auroc_quintile'] - 0.84) / 0.84) * 100\n",
    "delta_q25 = ((results_24h['auroc_quartile'] - 0.70) / 0.70) * 100\n",
    "delta_dr = ((results_dr['auroc'] - 0.631) / 0.631) * 100\n",
    "\n",
    "table3_rows = [\n",
    "    ['Segar 2024', 'DOSE/ESCAPE', '707', 'NA', 'NA', '0.84', 'NA', 'NA', 'External validation'],\n",
    "    ['Pandey 2025', 'CLOROTIC', '220', 'NA', 'B=-0.18/pt +', 'NA', '0.70', 'NA', 'Trial validation'],\n",
    "    ['Mauch 2025', 'Floor patients', '317', 'NA', 'r=-0.40', 'NA', 'NA', '0.631', 'Real-world'],\n",
    "    ['This Study', 'ICU ADHF', f\"{results_24h['n']}\", f\"{results_24h['spearman_rho']:.3f}\",\n",
    "     f\"r={results_24h['pearson_r']:.3f}\", f\"{results_24h['auroc_quintile']:.3f}\",\n",
    "     f\"{results_24h['auroc_quartile']:.3f}\", f\"{results_dr['auroc']:.3f}\", 'ICU validation'],\n",
    "]\n",
    "\n",
    "table3_df = pd.DataFrame(\n",
    "    table3_rows,\n",
    "    columns=['Study', 'Population', 'N', 'Spearman rho', 'Association', 'AUROC Q20', 'AUROC Q25', 'Binary DR', 'Notes']\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(table3_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"COMPARISON VS REFERENCES\")\n",
    "print(\"-\"*70)\n",
    "print(f\"  Pearson r:  This study r={results_24h['pearson_r']:.3f} vs Mauch r=-0.40  -> {delta_pearson:+.1f}%\")\n",
    "print(f\"  AUROC Q20:  This study {results_24h['auroc_quintile']:.3f} vs Segar 0.84  -> {delta_q20:+.1f}%\")\n",
    "print(f\"  AUROC Q25:  This study {results_24h['auroc_quartile']:.3f} vs Pandey 0.70 -> {delta_q25:+.1f}%\")\n",
    "print(f\"  Binary DR:  This study {results_dr['auroc']:.3f} vs Mauch 0.631 -> {delta_dr:+.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"NOTES\")\n",
    "print(\"-\"*70)\n",
    "print(\"+ Pandey reports a beta coefficient (regression slope), not a correlation\")\n",
    "print(\"- Segar external validation: DOSE/ESCAPE, AUROC Q20=0.84\")\n",
    "print(\"- Mauch: r=-0.40 for 72h urine diuretic efficiency. Binary DR AUROC 0.631 for 24h urine output goal\")\n",
    "print(\"- This study Binary DR: UOP <=3000 mL, prevalence 76.3%\")\n",
    "print(\"- Mauch Binary DR prevalence is much lower, which can inflate AUROC relative to a high-prevalence ICU cohort\")\n",
    "\n",
    "table3_df.to_csv('/content/Table3_literature_comparison.csv', index=False)\n",
    "table3_df.to_excel('/content/Table3_literature_comparison.xlsx', index=False)\n",
    "print(\"\\n\u2713 Table 3 saved\")\n",
    "\n",
    "#==========================================================================\n",
    "# KEY FINDINGS SUMMARY FOR MANUSCRIPT\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY FINDINGS SUMMARY FOR MANUSCRIPT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "PRIMARY OUTCOME. 24h Diuretic Efficiency\n",
    "  Spearman rho = {results_24h['spearman_rho']:.3f} (95% CI: {results_24h['spearman_ci'][0]:.3f}, {results_24h['spearman_ci'][1]:.3f}), p<0.001\n",
    "  Pearson r    = {results_24h['pearson_r']:.3f} (95% CI: {results_24h['pearson_ci'][0]:.3f}, {results_24h['pearson_ci'][1]:.3f}), p<0.001\n",
    "  AUROC (Q20)  = {results_24h['auroc_quintile']:.3f} (95% CI: {results_24h['auroc_quintile_ci'][0]:.3f}, {results_24h['auroc_quintile_ci'][1]:.3f})\n",
    "\n",
    "RISK STRATIFICATION (examples)\n",
    "  Low:      Efficiency {eff_24h_by_risk['Low']['median']:.1f} mL/mg\n",
    "  Moderate: Efficiency {eff_24h_by_risk['Moderate']['median']:.1f} mL/mg\n",
    "  High:     Efficiency {eff_24h_by_risk['High']['median']:.1f} mL/mg\n",
    "\n",
    "CONCLUSION\n",
    "  BAN-ADHF validates in a critically ill ICU cohort with preserved continuous discrimination.\n",
    "  Binary discrimination is appropriately attenuated in a high-prevalence ICU setting.\n",
    "\"\"\")\n",
    "\n",
    "#==========================================================================\n",
    "# R DATA EXPORTS\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA EXPORTS FOR R\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Forest plot data\n",
    "# Fix: allow either results_subgroups['forest_data'] or results_subgroups itself containing the dataframe\n",
    "forest_df = None\n",
    "if isinstance(results_subgroups, dict):\n",
    "    forest_df = results_subgroups.get('forest_data', None)\n",
    "\n",
    "# If forest_df not present but you have a variable named forest_data in memory, use it\n",
    "if forest_df is None and 'forest_data' in globals():\n",
    "    forest_df = globals()['forest_data']\n",
    "\n",
    "if forest_df is None:\n",
    "    print(\"Forest plot export skipped. Could not find forest_data dataframe.\")\n",
    "else:\n",
    "    forest_df.to_csv('/content/data_for_R_forest_plot.csv', index=False)\n",
    "    print(\"\u2713 data_for_R_forest_plot.csv\")\n",
    "\n",
    "# Outcomes by risk\n",
    "outcomes_risk = []\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    outcomes_risk.append({\n",
    "        'risk_category': cat,\n",
    "        'eff_24h_median': eff_24h_by_risk[cat]['median'],\n",
    "        'eff_24h_q1': eff_24h_by_risk[cat]['q1'],\n",
    "        'eff_24h_q3': eff_24h_by_risk[cat]['q3'],\n",
    "        'eff_72h_median': eff_72h_by_risk[cat]['median'],\n",
    "        'eff_72h_q1': eff_72h_by_risk[cat]['q1'],\n",
    "        'eff_72h_q3': eff_72h_by_risk[cat]['q3'],\n",
    "        'dr_rate': results_dr['dr_by_risk'][cat]['rate'],\n",
    "        'mortality_rate': results_mortality['mort_by_risk'][cat]['rate']\n",
    "    })\n",
    "pd.DataFrame(outcomes_risk).to_csv('/content/data_for_R_outcomes_by_risk.csv', index=False)\n",
    "print(\"\u2713 data_for_R_outcomes_by_risk.csv\")\n",
    "\n",
    "# Raw efficiency data for box plots\n",
    "df_eff_r = df[['hadm_id', 'ban_adhf_total_score', 'risk_category',\n",
    "               'diuretic_efficiency_24h', 'diuretic_efficiency_72h']].copy()\n",
    "df_eff_r.to_csv('/content/data_for_R_efficiency_raw.csv', index=False)\n",
    "print(\"\u2713 data_for_R_efficiency_raw.csv\")\n",
    "\n",
    "# Literature comparison data for plotting\n",
    "lit_compare = pd.DataFrame({\n",
    "    'study': ['Segar 2024 (derivation)', 'Segar 2024 (validation)', 'Pandey 2025', 'Mauch 2025', 'This Study'],\n",
    "    'population': ['ROSE/CARRESS/ATHENA', 'DOSE/ESCAPE', 'CLOROTIC', 'Floor', 'ICU'],\n",
    "    'n': [794, 707, 220, 317, results_24h['n']],\n",
    "    'pearson_r': [np.nan, np.nan, -0.18, -0.40, results_24h['pearson_r']],\n",
    "    'auroc_q20': [0.87, 0.84, np.nan, np.nan, results_24h['auroc_quintile']],\n",
    "    'auroc_q25': [np.nan, np.nan, 0.70, np.nan, results_24h['auroc_quartile']],\n",
    "    'auroc_dr': [np.nan, np.nan, np.nan, 0.631, results_dr['auroc']]\n",
    "})\n",
    "lit_compare.to_csv('/content/data_for_R_literature_comparison.csv', index=False)\n",
    "print(\"\u2713 data_for_R_literature_comparison.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\u2713 ALL MAIN TABLES COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "Files generated:\n",
    "  - Table1_baseline_by_risk.csv/.xlsx\n",
    "  - Table2_outcomes_discrimination.csv/.xlsx\n",
    "  - Table3_literature_comparison.csv/.xlsx\n",
    "  - data_for_R_forest_plot.csv (if available)\n",
    "  - data_for_R_outcomes_by_risk.csv\n",
    "  - data_for_R_efficiency_raw.csv\n",
    "  - data_for_R_literature_comparison.csv\n",
    "\"\"\")\n",
    "print(\"\\n-> Next: Supplementary Tables (Cell 17)\")\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# SECTION 12: MAIN MANUSCRIPT TABLES\n",
    "# Cell 16: Generate Tables 1, 2, and 3 (CORRECTED C-INDEX)\n",
    "#==========================================================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tableone import TableOne\n",
    "\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MAIN MANUSCRIPT TABLES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Bootstrap setup (used for Table 2 primary metrics)\n",
    "# -------------------------------------------------------------------------\n",
    "np.random.seed(42)\n",
    "n_bootstrap = 1000\n",
    "\n",
    "def bootstrap_ci(values, alpha=0.05):\n",
    "    lo = np.percentile(values, 100 * (alpha/2))\n",
    "    hi = np.percentile(values, 100 * (1 - alpha/2))\n",
    "    return (lo, hi)\n",
    "\n",
    "def safe_roc_auc(y_true, y_score):\n",
    "    y_true = np.asarray(y_true)\n",
    "    if y_true.sum() == 0 or y_true.sum() == len(y_true):\n",
    "        return None\n",
    "    return roc_auc_score(y_true, y_score)\n",
    "\n",
    "def concordance_index_fallback(x, y):\n",
    "    \"\"\"\n",
    "    Harrell C-index for continuous outcome.\n",
    "    Higher BAN-ADHF score (x) should map to lower efficiency (y).\n",
    "    So compute c-index(efficiency, -score) = c-index(y, -x).\n",
    "\n",
    "    CORRECTED: Arguments now match Cell 9's approach.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from lifelines.utils import concordance_index\n",
    "        return float(concordance_index(y, -x))  # CORRECTED: was (x, -y)\n",
    "    except Exception:\n",
    "        x = np.asarray(x)\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        n = len(x)\n",
    "        concordant = 0\n",
    "        permissible = 0\n",
    "        ties = 0\n",
    "\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                if y[i] == y[j]:\n",
    "                    continue\n",
    "                permissible += 1\n",
    "                # Higher score should predict lower efficiency\n",
    "                # Concordant if: (y[i] > y[j] and x[i] < x[j]) or (y[i] < y[j] and x[i] > x[j])\n",
    "                dy = y[i] - y[j]\n",
    "                dx = x[i] - x[j]\n",
    "                if dx == 0:\n",
    "                    ties += 1\n",
    "                elif dy * dx < 0:  # CORRECTED: was dy * dx > 0\n",
    "                    concordant += 1\n",
    "\n",
    "        if permissible == 0:\n",
    "            return np.nan\n",
    "\n",
    "        return (concordant + 0.5 * ties) / permissible\n",
    "\n",
    "def compute_primary_eff_metrics(df_in, score_col, eff_col, q_list=(0.20, 0.25), n_boot=1000):\n",
    "    dfv = df_in[[score_col, eff_col]].dropna().copy()\n",
    "    dfv = dfv[dfv[eff_col] > 0].copy()\n",
    "    n = len(dfv)\n",
    "\n",
    "    x = dfv[score_col].astype(float).values\n",
    "    y = dfv[eff_col].astype(float).values\n",
    "\n",
    "    # Spearman + bootstrap CI\n",
    "    rho, p_rho = spearmanr(x, y)\n",
    "    rho_boot = []\n",
    "    for _ in range(n_boot):\n",
    "        idx = np.random.choice(n, size=n, replace=True)\n",
    "        r, _ = spearmanr(x[idx], y[idx])\n",
    "        rho_boot.append(r)\n",
    "    rho_ci = bootstrap_ci(rho_boot)\n",
    "\n",
    "    # Pearson + bootstrap CI\n",
    "    r_lin, p_lin = pearsonr(x, y)\n",
    "    r_boot = []\n",
    "    for _ in range(n_boot):\n",
    "        idx = np.random.choice(n, size=n, replace=True)\n",
    "        rr, _ = pearsonr(x[idx], y[idx])\n",
    "        r_boot.append(rr)\n",
    "    r_ci = bootstrap_ci(r_boot)\n",
    "\n",
    "    # C-index + bootstrap CI\n",
    "    c_index = concordance_index_fallback(x, y)\n",
    "    c_boot = []\n",
    "    for _ in range(n_boot):\n",
    "        idx = np.random.choice(n, size=n, replace=True)\n",
    "        c_boot.append(concordance_index_fallback(x[idx], y[idx]))\n",
    "    c_ci = bootstrap_ci(c_boot)\n",
    "\n",
    "    # AUROC(s) for low efficiency by quantile thresholds\n",
    "    aurocs = {}\n",
    "    for q in q_list:\n",
    "        thr = float(np.quantile(y, q))\n",
    "        low = (y <= thr).astype(int)\n",
    "        auc = safe_roc_auc(low, x)\n",
    "\n",
    "        auc_boot = []\n",
    "        if auc is not None:\n",
    "            for _ in range(n_boot):\n",
    "                idx = np.random.choice(n, size=n, replace=True)\n",
    "                low_b = low[idx]\n",
    "                x_b = x[idx]\n",
    "                auc_b = safe_roc_auc(low_b, x_b)\n",
    "                if auc_b is not None:\n",
    "                    auc_boot.append(auc_b)\n",
    "            auc_ci = bootstrap_ci(auc_boot) if len(auc_boot) > 0 else (np.nan, np.nan)\n",
    "        else:\n",
    "            auc_ci = (np.nan, np.nan)\n",
    "\n",
    "        aurocs[q] = {\n",
    "            \"threshold\": thr,\n",
    "            \"n_events\": int(low.sum()),\n",
    "            \"auroc\": float(auc) if auc is not None else np.nan,\n",
    "            \"auroc_ci\": (float(auc_ci[0]), float(auc_ci[1]))\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"n\": int(n),\n",
    "        \"spearman_rho\": float(rho),\n",
    "        \"spearman_p\": float(p_rho),\n",
    "        \"spearman_ci\": (float(rho_ci[0]), float(rho_ci[1])),\n",
    "        \"pearson_r\": float(r_lin),\n",
    "        \"pearson_p\": float(p_lin),\n",
    "        \"pearson_ci\": (float(r_ci[0]), float(r_ci[1])),\n",
    "        \"c_index\": float(c_index),\n",
    "        \"c_index_ci\": (float(c_ci[0]), float(c_ci[1])),\n",
    "        \"aurocs\": aurocs\n",
    "    }\n",
    "\n",
    "def format_ci_tuple(ci, decimals=3):\n",
    "    return f\"({ci[0]:.{decimals}f}, {ci[1]:.{decimals}f})\"\n",
    "\n",
    "\n",
    "#==========================================================================\n",
    "# TABLE 1: BASELINE CHARACTERISTICS BY BAN-ADHF RISK CATEGORY\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TABLE 1: Baseline Characteristics by BAN-ADHF Risk Category\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_table1 = df.copy()\n",
    "\n",
    "# Create male_sex variable robustly\n",
    "if 'gender' in df_table1.columns:\n",
    "    if df_table1['gender'].dtype == 'object':\n",
    "        g = df_table1['gender'].astype(str).str.strip().str.upper()\n",
    "        df_table1['male_sex'] = g.isin(['M', 'MALE', 'MAN']).astype(int)\n",
    "    else:\n",
    "        df_table1['male_sex'] = pd.to_numeric(df_table1['gender'], errors='coerce')\n",
    "else:\n",
    "    # If you ever run without gender, create missing column to avoid TableOne breaking\n",
    "    df_table1['male_sex'] = np.nan\n",
    "\n",
    "df_table1['risk_category'] = df_table1['risk_category'].astype(str)\n",
    "\n",
    "# Convert binary variables to Yes/No for TableOne\n",
    "binary_vars_to_fix = [\n",
    "    'male_sex', 'hx_atrial_fibrillation', 'hx_hypertension',\n",
    "    'prior_hf_hospitalization_12mo', 'hx_diabetes', 'hx_renal_disease',\n",
    "    'hx_myocardial_infarction', 'hx_stroke', 'hx_copd',\n",
    "    'cardiogenic_shock', 'invasive_vent'\n",
    "]\n",
    "\n",
    "for var in binary_vars_to_fix:\n",
    "    if var in df_table1.columns:\n",
    "        df_table1[var] = df_table1[var].map({1: 'Yes', 0: 'No', True: 'Yes', False: 'No'})\n",
    "\n",
    "all_columns = [\n",
    "    'age', 'male_sex', 'ban_adhf_total_score',\n",
    "    'creatinine', 'bun', 'ntprobnp', 'dbp',\n",
    "    'total_furosemide_equivalent_mg',\n",
    "    'hx_atrial_fibrillation', 'hx_hypertension', 'prior_hf_hospitalization_12mo',\n",
    "    'lvef', 'hf_phenotype',\n",
    "    'hx_diabetes', 'hx_renal_disease', 'hx_myocardial_infarction',\n",
    "    'hx_stroke', 'hx_copd', 'cci_score',\n",
    "    'cardiogenic_shock', 'invasive_vent'\n",
    "]\n",
    "all_columns = [v for v in all_columns if v in df_table1.columns]\n",
    "\n",
    "categorical_vars = [\n",
    "    'male_sex', 'hx_atrial_fibrillation', 'hx_hypertension',\n",
    "    'prior_hf_hospitalization_12mo', 'hf_phenotype',\n",
    "    'hx_diabetes', 'hx_renal_disease', 'hx_myocardial_infarction',\n",
    "    'hx_stroke', 'hx_copd', 'cardiogenic_shock', 'invasive_vent'\n",
    "]\n",
    "categorical_vars = [v for v in categorical_vars if v in df_table1.columns]\n",
    "\n",
    "nonnormal_vars = [\n",
    "    'ban_adhf_total_score', 'creatinine', 'bun', 'ntprobnp',\n",
    "    'total_furosemide_equivalent_mg', 'cci_score'\n",
    "]\n",
    "nonnormal_vars = [v for v in nonnormal_vars if v in df_table1.columns]\n",
    "\n",
    "labels = {\n",
    "    'age': 'Age, years',\n",
    "    'male_sex': 'Male sex',\n",
    "    'ban_adhf_total_score': 'BAN-ADHF score',\n",
    "    'creatinine': 'Creatinine, mg/dL',\n",
    "    'bun': 'BUN, mg/dL',\n",
    "    'ntprobnp': 'NT-proBNP, pg/mL',\n",
    "    'dbp': 'Diastolic BP, mmHg',\n",
    "    'total_furosemide_equivalent_mg': 'Home diuretic dose, mg/day +',\n",
    "    'hx_atrial_fibrillation': 'Atrial fibrillation',\n",
    "    'hx_hypertension': 'Hypertension',\n",
    "    'prior_hf_hospitalization_12mo': 'Prior HF hospitalization (12 mo)',\n",
    "    'lvef': 'LVEF, % ++',\n",
    "    'hf_phenotype': 'HF phenotype ++',\n",
    "    'hx_diabetes': 'Diabetes mellitus',\n",
    "    'hx_renal_disease': 'Chronic kidney disease',\n",
    "    'hx_myocardial_infarction': 'Prior myocardial infarction',\n",
    "    'hx_stroke': 'Prior stroke',\n",
    "    'hx_copd': 'COPD',\n",
    "    'cci_score': 'Charlson Comorbidity Index',\n",
    "    'cardiogenic_shock': 'Cardiogenic shock',\n",
    "    'invasive_vent': 'Invasive mechanical ventilation'\n",
    "}\n",
    "\n",
    "order = {\n",
    "    'risk_category': ['Low', 'Moderate', 'High'],\n",
    "    'male_sex': ['Yes', 'No'],\n",
    "    'hx_atrial_fibrillation': ['Yes', 'No'],\n",
    "    'hx_hypertension': ['Yes', 'No'],\n",
    "    'prior_hf_hospitalization_12mo': ['Yes', 'No'],\n",
    "    'hx_diabetes': ['Yes', 'No'],\n",
    "    'hx_renal_disease': ['Yes', 'No'],\n",
    "    'hx_myocardial_infarction': ['Yes', 'No'],\n",
    "    'hx_stroke': ['Yes', 'No'],\n",
    "    'hx_copd': ['Yes', 'No'],\n",
    "    'cardiogenic_shock': ['Yes', 'No'],\n",
    "    'invasive_vent': ['Yes', 'No']\n",
    "}\n",
    "\n",
    "limit = {k: 1 for k in [\n",
    "    'male_sex', 'hx_atrial_fibrillation', 'hx_hypertension',\n",
    "    'prior_hf_hospitalization_12mo', 'hx_diabetes', 'hx_renal_disease',\n",
    "    'hx_myocardial_infarction', 'hx_stroke', 'hx_copd',\n",
    "    'cardiogenic_shock', 'invasive_vent'\n",
    "] if k in df_table1.columns}\n",
    "\n",
    "table1 = TableOne(\n",
    "    df_table1,\n",
    "    columns=all_columns,\n",
    "    categorical=categorical_vars,\n",
    "    nonnormal=nonnormal_vars,\n",
    "    groupby='risk_category',\n",
    "    pval=True,\n",
    "    rename=labels,\n",
    "    missing=False,\n",
    "    overall=True,\n",
    "    order=order,\n",
    "    limit=limit,\n",
    "    decimals=1\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(table1.tabulate(tablefmt=\"simple\"))\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"+ Home diuretic dose as oral furosemide equivalents\")\n",
    "if 'lvef' in df_table1.columns:\n",
    "    print(\"++ LVEF available in\", int(df_table1['lvef'].notna().sum()), \"patients\")\n",
    "\n",
    "table1.to_csv('/content/Table1_baseline_by_risk.csv')\n",
    "table1.to_excel('/content/Table1_baseline_by_risk.xlsx')\n",
    "print(\"\\n\u2713 Table 1 saved\")\n",
    "\n",
    "# Verification gradients (works only if original columns are numeric 0/1 in df)\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"VERIFICATION: Comorbidity Gradients (should increase with higher risk)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "df_verify = df.copy()\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    subset = df_verify[df_verify['risk_category'] == cat]\n",
    "    n = len(subset)\n",
    "\n",
    "    def safe_mean(col):\n",
    "        if col not in subset.columns:\n",
    "            return np.nan\n",
    "        return pd.to_numeric(subset[col], errors='coerce').mean()\n",
    "\n",
    "    dm_pct = 100 * safe_mean('hx_diabetes')\n",
    "    ckd_pct = 100 * safe_mean('hx_renal_disease')\n",
    "    cs_pct = 100 * safe_mean('cardiogenic_shock')\n",
    "    hf_hosp = 100 * safe_mean('prior_hf_hospitalization_12mo')\n",
    "    print(f\"  {cat}: N={n}, DM={dm_pct:.1f}%, CKD={ckd_pct:.1f}%, CS={cs_pct:.1f}%, Prior HF hosp={hf_hosp:.1f}%\")\n",
    "\n",
    "#==========================================================================\n",
    "# CALCULATE EFFICIENCY BY RISK FOR TABLE 2\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Calculating efficiency distributions by risk category...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "df_24h = df[(df['icu_stay_ge_24h'] == 1) &\n",
    "            (df['diuretic_efficiency_24h'].notna()) &\n",
    "            (df['diuretic_efficiency_24h'] > 0)].copy()\n",
    "\n",
    "eff_24h_by_risk = {}\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    subset = df_24h[df_24h['risk_category'] == cat]['diuretic_efficiency_24h']\n",
    "    eff_24h_by_risk[cat] = {'n': len(subset), 'median': subset.median(),\n",
    "                           'q1': subset.quantile(0.25), 'q3': subset.quantile(0.75)}\n",
    "    print(f\"  24h {cat}: N={eff_24h_by_risk[cat]['n']}, Median={eff_24h_by_risk[cat]['median']:.1f} [{eff_24h_by_risk[cat]['q1']:.1f}-{eff_24h_by_risk[cat]['q3']:.1f}]\")\n",
    "\n",
    "df_72h = df[(df['icu_stay_ge_72h'] == 1) &\n",
    "            (df['diuretic_efficiency_72h'].notna()) &\n",
    "            (df['diuretic_efficiency_72h'] > 0)].copy()\n",
    "\n",
    "eff_72h_by_risk = {}\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    subset = df_72h[df_72h['risk_category'] == cat]['diuretic_efficiency_72h']\n",
    "    eff_72h_by_risk[cat] = {'n': len(subset), 'median': subset.median(),\n",
    "                           'q1': subset.quantile(0.25), 'q3': subset.quantile(0.75)}\n",
    "    print(f\"  72h {cat}: N={eff_72h_by_risk[cat]['n']}, Median={eff_72h_by_risk[cat]['median']:.1f} [{eff_72h_by_risk[cat]['q1']:.1f}-{eff_72h_by_risk[cat]['q3']:.1f}]\")\n",
    "\n",
    "\n",
    "#==========================================================================\n",
    "# TABLE 2: PRIMARY OUTCOMES AND DISCRIMINATION SUMMARY (CORRECTED)\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TABLE 2: Primary Outcomes and Discrimination Summary\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Compute primary discrimination fresh here.\n",
    "# This avoids KeyError from results_24h being overwritten elsewhere.\n",
    "results_24h_clean = compute_primary_eff_metrics(\n",
    "    df_24h,\n",
    "    score_col='ban_adhf_total_score',\n",
    "    eff_col='diuretic_efficiency_24h',\n",
    "    q_list=(0.20, 0.25),\n",
    "    n_boot=n_bootstrap\n",
    ")\n",
    "\n",
    "results_72h_clean = compute_primary_eff_metrics(\n",
    "    df_72h,\n",
    "    score_col='ban_adhf_total_score',\n",
    "    eff_col='diuretic_efficiency_72h',\n",
    "    q_list=(0.20,),\n",
    "    n_boot=n_bootstrap\n",
    ")\n",
    "\n",
    "# Pull AUROCs from the clean dict\n",
    "auroc24_q20 = results_24h_clean[\"aurocs\"][0.20][\"auroc\"]\n",
    "auroc24_q20_ci = results_24h_clean[\"aurocs\"][0.20][\"auroc_ci\"]\n",
    "auroc24_q25 = results_24h_clean[\"aurocs\"][0.25][\"auroc\"]\n",
    "auroc24_q25_ci = results_24h_clean[\"aurocs\"][0.25][\"auroc_ci\"]\n",
    "\n",
    "auroc72_q20 = results_72h_clean[\"aurocs\"][0.20][\"auroc\"]\n",
    "auroc72_q20_ci = results_72h_clean[\"aurocs\"][0.20][\"auroc_ci\"]\n",
    "\n",
    "table2_rows = []\n",
    "\n",
    "# 24-Hour Diuretic Efficiency\n",
    "table2_rows.append(['24-Hour Diuretic Efficiency', 'N', f\"{results_24h_clean['n']:,}\", 'NA', 'NA'])\n",
    "table2_rows.append(['', 'Spearman rho', f\"{results_24h_clean['spearman_rho']:.3f}\",\n",
    "                    format_ci_tuple(results_24h_clean['spearman_ci']), '<0.001'])\n",
    "table2_rows.append(['', 'Pearson r', f\"{results_24h_clean['pearson_r']:.3f}\",\n",
    "                    format_ci_tuple(results_24h_clean['pearson_ci']), '<0.001'])\n",
    "table2_rows.append(['', 'C-index', f\"{results_24h_clean['c_index']:.3f}\",\n",
    "                    format_ci_tuple(results_24h_clean['c_index_ci']), 'NA'])\n",
    "table2_rows.append(['', 'AUROC (Q20)', f\"{auroc24_q20:.3f}\",\n",
    "                    format_ci_tuple(auroc24_q20_ci), 'NA'])\n",
    "table2_rows.append(['', 'AUROC (Q25)', f\"{auroc24_q25:.3f}\",\n",
    "                    format_ci_tuple(auroc24_q25_ci), 'NA'])\n",
    "\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    e = eff_24h_by_risk[cat]\n",
    "    p_val = '<0.001 *' if cat == 'High' else ''\n",
    "    table2_rows.append(['', f'  {cat}, mL/mg', f\"{e['median']:.1f}\",\n",
    "                        f\"[{e['q1']:.1f}-{e['q3']:.1f}]\", p_val])\n",
    "\n",
    "# 72-Hour Diuretic Efficiency\n",
    "table2_rows.append(['72-Hour Diuretic Efficiency', 'N', f\"{results_72h_clean['n']:,}\", 'NA', 'NA'])\n",
    "table2_rows.append(['', 'Spearman rho', f\"{results_72h_clean['spearman_rho']:.3f}\",\n",
    "                    format_ci_tuple(results_72h_clean['spearman_ci']), '<0.001'])\n",
    "table2_rows.append(['', 'AUROC (Q20)', f\"{auroc72_q20:.3f}\",\n",
    "                    format_ci_tuple(auroc72_q20_ci), 'NA'])\n",
    "\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    e = eff_72h_by_risk[cat]\n",
    "    p_val = '<0.001 *' if cat == 'High' else ''\n",
    "    table2_rows.append(['', f'  {cat}, mL/mg', f\"{e['median']:.1f}\",\n",
    "                        f\"[{e['q1']:.1f}-{e['q3']:.1f}]\", p_val])\n",
    "\n",
    "# Diuretic Resistance (uses your existing results_dr dict, which has the right keys)\n",
    "table2_rows.append(['Diuretic Resistance +', 'N', f\"{results_dr['n']:,}\", 'NA', 'NA'])\n",
    "table2_rows.append(['', 'Prevalence', f\"{results_dr['prevalence']:.1f}%\", 'NA', 'NA'])\n",
    "table2_rows.append(['', 'AUROC', f\"{results_dr['auroc']:.3f}\",\n",
    "                    format_ci_tuple(results_dr['auroc_ci']), 'NA'])\n",
    "\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    rate = results_dr['dr_by_risk'][cat]['rate']\n",
    "    p_val = '<0.001 *' if cat == 'High' else ''\n",
    "    table2_rows.append(['', f'  {cat}', f\"{rate:.1f}%\", 'NA', p_val])\n",
    "\n",
    "# Mortality (uses your existing results_mortality dict, which has the right keys)\n",
    "table2_rows.append(['In-Hospital Mortality ++', 'N', f\"{results_mortality['n']:,}\", 'NA', 'NA'])\n",
    "table2_rows.append(['', 'Mortality rate', f\"{results_mortality['mortality_rate']:.1f}%\", 'NA', 'NA'])\n",
    "table2_rows.append(['', 'AUROC', f\"{results_mortality['auroc']:.3f}\",\n",
    "                    format_ci_tuple(results_mortality['auroc_ci']), 'NA'])\n",
    "table2_rows.append(['', 'AUROC (CS subgroup)', f\"{results_mortality['auroc_cs']:.3f}\",\n",
    "                    format_ci_tuple(results_mortality['auroc_cs_ci']), 'NA'])\n",
    "\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    rate = results_mortality['mort_by_risk'][cat]['rate']\n",
    "    p_val = '0.001 *' if cat == 'High' else ''\n",
    "    table2_rows.append(['', f'  {cat}', f\"{rate:.1f}%\", 'NA', p_val])\n",
    "\n",
    "table2_df = pd.DataFrame(table2_rows, columns=['Outcome', 'Metric', 'Value', '95% CI', 'p-value'])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(table2_df.to_string(index=False))\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"* Kruskal-Wallis or Chi-square test across risk categories\")\n",
    "print(\"+ Urine output <=3000 mL in first 24 hours\")\n",
    "print(\"++ Exploratory outcome. BAN-ADHF designed for diuretic efficiency\")\n",
    "\n",
    "table2_df.to_csv('/content/Table2_outcomes_discrimination.csv', index=False)\n",
    "table2_df.to_excel('/content/Table2_outcomes_discrimination.xlsx', index=False)\n",
    "print(\"\\n\u2713 Table 2 saved\")\n",
    "\n",
    "\n",
    "#==========================================================================\n",
    "# TABLE 3: LITERATURE COMPARISON (UPDATED TO USE results_24h_clean)\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TABLE 3: Literature Comparison\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Reference values used in your prior draft\n",
    "ref_r = 0.40\n",
    "ref_q20 = 0.84\n",
    "ref_q25 = 0.70\n",
    "ref_dr = 0.631\n",
    "\n",
    "delta_pearson = ((abs(results_24h_clean['pearson_r']) - ref_r) / ref_r) * 100\n",
    "delta_q20 = ((auroc24_q20 - ref_q20) / ref_q20) * 100\n",
    "delta_q25 = ((auroc24_q25 - ref_q25) / ref_q25) * 100\n",
    "delta_dr = ((results_dr['auroc'] - ref_dr) / ref_dr) * 100\n",
    "\n",
    "table3_rows = [\n",
    "    ['Segar 2024', 'DOSE/ESCAPE', '707', 'NA', 'NA', f\"{ref_q20:.2f}\", 'NA', 'NA', 'External validation'],\n",
    "    ['Pandey 2025', 'CLOROTIC', '220', 'NA', 'B=-0.18/pt +', 'NA', f\"{ref_q25:.2f}\", 'NA', 'Trial validation'],\n",
    "    ['Mauch 2025', 'Floor patients', '317', 'NA', 'r=-0.40', 'NA', 'NA', f\"{ref_dr:.3f}\", 'Real-world'],\n",
    "    ['This Study', 'ICU ADHF', f\"{results_24h_clean['n']:,}\",\n",
    "     f\"{results_24h_clean['spearman_rho']:.3f}\",\n",
    "     f\"r={results_24h_clean['pearson_r']:.3f}\",\n",
    "     f\"{auroc24_q20:.3f}\",\n",
    "     f\"{auroc24_q25:.3f}\",\n",
    "     f\"{results_dr['auroc']:.3f}\",\n",
    "     'ICU validation'],\n",
    "]\n",
    "\n",
    "table3_df = pd.DataFrame(\n",
    "    table3_rows,\n",
    "    columns=['Study', 'Population', 'N', 'Spearman rho', 'Association',\n",
    "             'AUROC Q20', 'AUROC Q25', 'Binary DR', 'Notes']\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(table3_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"COMPARISON VS REFERENCES:\")\n",
    "print(\"-\"*70)\n",
    "print(f\"  Pearson r:    This study r={results_24h_clean['pearson_r']:.3f} vs Mauch r=-0.40 -> {delta_pearson:+.1f}%\")\n",
    "print(f\"  AUROC Q20:    This study {auroc24_q20:.3f} vs Segar ext {ref_q20:.2f} -> {delta_q20:+.1f}%\")\n",
    "print(f\"  AUROC Q25:    This study {auroc24_q25:.3f} vs Pandey {ref_q25:.2f} -> {delta_q25:+.1f}%\")\n",
    "print(f\"  Binary DR:    This study {results_dr['auroc']:.3f} vs Mauch {ref_dr:.3f} -> {delta_dr:+.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"NOTES:\")\n",
    "print(\"-\"*70)\n",
    "print(\"+ Pandey: beta coefficient (regression slope), not correlation\")\n",
    "print(\"- This study Binary DR: UOP <=3000 mL, prevalence {:.1f}%\".format(results_dr['prevalence']))\n",
    "print(\"- Lower Binary DR AUROC can reflect higher prevalence and dichotomization\")\n",
    "\n",
    "table3_df.to_csv('/content/Table3_literature_comparison.csv', index=False)\n",
    "table3_df.to_excel('/content/Table3_literature_comparison.xlsx', index=False)\n",
    "print(\"\\n\u2713 Table 3 saved\")\n",
    "\n",
    "\n",
    "#==========================================================================\n",
    "# KEY FINDINGS SUMMARY FOR MANUSCRIPT (UPDATED)\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY FINDINGS SUMMARY FOR MANUSCRIPT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "PRIMARY OUTCOME - 24h Diuretic Efficiency:\n",
    "  Spearman rho = {results_24h_clean['spearman_rho']:.3f} (95% CI: {results_24h_clean['spearman_ci'][0]:.3f}, {results_24h_clean['spearman_ci'][1]:.3f}), p<0.001\n",
    "  Pearson r = {results_24h_clean['pearson_r']:.3f} (95% CI: {results_24h_clean['pearson_ci'][0]:.3f}, {results_24h_clean['pearson_ci'][1]:.3f}), p<0.001\n",
    "  AUROC (Q20) = {auroc24_q20:.3f} (95% CI: {auroc24_q20_ci[0]:.3f}, {auroc24_q20_ci[1]:.3f})\n",
    "\n",
    "COMPARISON TO LITERATURE:\n",
    "  Pearson r:     {results_24h_clean['pearson_r']:.3f} vs -0.40 (Mauch)\n",
    "  AUROC Q20:     {auroc24_q20:.3f} vs 0.84 (Segar validation)\n",
    "  AUROC Q25:     {auroc24_q25:.3f} vs 0.70 (Pandey)\n",
    "  Binary DR:     {results_dr['auroc']:.3f} vs 0.631 (Mauch)\n",
    "\n",
    "RISK STRATIFICATION (from existing results dicts):\n",
    "  Low:      Efficiency {eff_24h_by_risk['Low']['median']:.1f} mL/mg, DR {results_dr['dr_by_risk']['Low']['rate']:.1f}%, Mortality {results_mortality['mort_by_risk']['Low']['rate']:.1f}%\n",
    "  Moderate: Efficiency {eff_24h_by_risk['Moderate']['median']:.1f} mL/mg, DR {results_dr['dr_by_risk']['Moderate']['rate']:.1f}%, Mortality {results_mortality['mort_by_risk']['Moderate']['rate']:.1f}%\n",
    "  High:     Efficiency {eff_24h_by_risk['High']['median']:.1f} mL/mg, DR {results_dr['dr_by_risk']['High']['rate']:.1f}%, Mortality {results_mortality['mort_by_risk']['High']['rate']:.1f}%\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "#==========================================================================\n",
    "# R DATA EXPORTS (UPDATED TO NOT DEPEND ON overwritten results_24h)\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA EXPORTS FOR R\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Forest plot data (only export if present)\n",
    "if isinstance(results_subgroups, dict) and ('forest_data' in results_subgroups):\n",
    "    results_subgroups['forest_data'].to_csv('/content/data_for_R_forest_plot.csv', index=False)\n",
    "    print(\"\u2713 data_for_R_forest_plot.csv\")\n",
    "else:\n",
    "    print(\"Forest plot export skipped. results_subgroups['forest_data'] not found.\")\n",
    "\n",
    "# Outcomes by risk\n",
    "outcomes_risk = []\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    outcomes_risk.append({\n",
    "        'risk_category': cat,\n",
    "        'eff_24h_median': eff_24h_by_risk[cat]['median'],\n",
    "        'eff_24h_q1': eff_24h_by_risk[cat]['q1'],\n",
    "        'eff_24h_q3': eff_24h_by_risk[cat]['q3'],\n",
    "        'eff_72h_median': eff_72h_by_risk[cat]['median'],\n",
    "        'eff_72h_q1': eff_72h_by_risk[cat]['q1'],\n",
    "        'eff_72h_q3': eff_72h_by_risk[cat]['q3'],\n",
    "        'dr_rate': results_dr['dr_by_risk'][cat]['rate'],\n",
    "        'mortality_rate': results_mortality['mort_by_risk'][cat]['rate']\n",
    "    })\n",
    "\n",
    "pd.DataFrame(outcomes_risk).to_csv('/content/data_for_R_outcomes_by_risk.csv', index=False)\n",
    "print(\"\u2713 data_for_R_outcomes_by_risk.csv\")\n",
    "\n",
    "# Raw efficiency data for box plots\n",
    "df_eff_r = df[['hadm_id', 'ban_adhf_total_score', 'risk_category',\n",
    "               'diuretic_efficiency_24h', 'diuretic_efficiency_72h']].copy()\n",
    "df_eff_r.to_csv('/content/data_for_R_efficiency_raw.csv', index=False)\n",
    "print(\"\u2713 data_for_R_efficiency_raw.csv\")\n",
    "\n",
    "# Literature comparison data for plotting\n",
    "lit_compare = pd.DataFrame({\n",
    "    'study': ['Segar 2024 (validation)', 'Pandey 2025', 'Mauch 2025', 'This Study'],\n",
    "    'population': ['DOSE/ESCAPE', 'CLOROTIC', 'Floor', 'ICU'],\n",
    "    'n': [707, 220, 317, results_24h_clean['n']],\n",
    "    'pearson_r': [np.nan, -0.18, -0.40, results_24h_clean['pearson_r']],\n",
    "    'auroc_q20': [0.84, np.nan, np.nan, auroc24_q20],\n",
    "    'auroc_q25': [np.nan, 0.70, np.nan, auroc24_q25],\n",
    "    'auroc_dr': [np.nan, np.nan, 0.631, results_dr['auroc']]\n",
    "})\n",
    "lit_compare.to_csv('/content/data_for_R_literature_comparison.csv', index=False)\n",
    "print(\"\u2713 data_for_R_literature_comparison.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\u2713 ALL MAIN TABLES COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "Files generated:\n",
    "  - Table1_baseline_by_risk.csv/.xlsx\n",
    "  - Table2_outcomes_discrimination.csv/.xlsx\n",
    "  - Table3_literature_comparison.csv/.xlsx\n",
    "  - data_for_R_outcomes_by_risk.csv\n",
    "  - data_for_R_efficiency_raw.csv\n",
    "  - data_for_R_literature_comparison.csv\n",
    "\"\"\")\n",
    "print(\"\\n-> Next: Supplementary Tables (Cell 17)\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# SECTION 13: SUPPLEMENTARY TABLES\n",
    "# Cell 17: Generate Supplementary Tables (eTables 1-4)\n",
    "#==========================================================================\n",
    "\n",
    "from tableone import TableOne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SUPPLEMENTARY TABLES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Helper: find the correct primary 24h discrimination dict\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "def find_primary_24h_results():\n",
    "    \"\"\"\n",
    "    We want the dict that looks like:\n",
    "      keys include: n, spearman_rho, spearman_ci, pearson_r, pearson_ci,\n",
    "                    c_index, c_index_ci, auroc_quintile, auroc_quintile_ci, auroc_quartile, auroc_quartile_ci\n",
    "    Your current `results_24h` is a scenario dict (A/B/C) and doesn't have these.\n",
    "    This function searches globals for the right one without guessing names.\n",
    "    \"\"\"\n",
    "    required = {\"n\", \"spearman_rho\", \"spearman_ci\", \"auroc_quintile\", \"auroc_quintile_ci\"}\n",
    "    candidates = []\n",
    "\n",
    "    for name, obj in globals().items():\n",
    "        if isinstance(obj, dict) and required.issubset(set(obj.keys())):\n",
    "            candidates.append((name, obj))\n",
    "\n",
    "    if len(candidates) == 0:\n",
    "        # Give a helpful debug printout of dict-like objects that might be related\n",
    "        maybe = []\n",
    "        for name, obj in globals().items():\n",
    "            if isinstance(obj, dict) and (\"rho\" in str(obj.keys()).lower() or \"auroc\" in str(obj.keys()).lower() or \"c_index\" in str(obj.keys()).lower()):\n",
    "                maybe.append((name, list(obj.keys())[:25]))\n",
    "        raise KeyError(\n",
    "            \"Could not find the primary 24h discrimination results dict.\\n\"\n",
    "            \"Expected a dict with keys like: n, spearman_rho, spearman_ci, auroc_quintile, auroc_quintile_ci.\\n\"\n",
    "            f\"Possible related dicts found (name -> sample keys): {maybe}\"\n",
    "        )\n",
    "\n",
    "    if len(candidates) > 1:\n",
    "        # Prefer the one literally named results_24h_primary if present\n",
    "        for nm, ob in candidates:\n",
    "            if nm.lower() in [\"results_primary_24h\", \"results_24h_primary\", \"results_discrimination_24h\", \"results_24h_discrimination\"]:\n",
    "                return nm, ob\n",
    "        # Otherwise return the first one\n",
    "        return candidates[0]\n",
    "\n",
    "    return candidates[0]\n",
    "\n",
    "\n",
    "primary_24h_name, primary_24h = find_primary_24h_results()\n",
    "print(f\"\\nUsing primary 24h discrimination results from: {primary_24h_name}\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# eTable 1: BASELINE CHARACTERISTICS BY MORTALITY STATUS\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"eTable 1: Baseline Characteristics by Mortality Status\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_etable1 = df.copy()\n",
    "df_etable1['mortality_status'] = df_etable1['hospital_expire_flag'].map({0: 'Survivors', 1: 'Non-survivors'})\n",
    "\n",
    "if df_etable1['gender'].dtype == 'object':\n",
    "    df_etable1['male_sex'] = (df_etable1['gender'] == 'M').astype(int)\n",
    "else:\n",
    "    df_etable1['male_sex'] = df_etable1['gender']\n",
    "\n",
    "df_etable1['risk_category'] = df_etable1['risk_category'].astype(str)\n",
    "\n",
    "binary_vars_to_fix = [\n",
    "    'male_sex', 'hx_atrial_fibrillation', 'hx_hypertension',\n",
    "    'prior_hf_hospitalization_12mo', 'hx_diabetes', 'hx_renal_disease',\n",
    "    'hx_myocardial_infarction', 'hx_stroke', 'hx_copd',\n",
    "    'cardiogenic_shock', 'invasive_vent'\n",
    "]\n",
    "\n",
    "for var in binary_vars_to_fix:\n",
    "    if var in df_etable1.columns:\n",
    "        df_etable1[var] = df_etable1[var].map({1: 'Yes', 0: 'No', True: 'Yes', False: 'No'})\n",
    "\n",
    "all_columns = [\n",
    "    'age', 'male_sex', 'ban_adhf_total_score', 'risk_category',\n",
    "    'creatinine', 'bun', 'ntprobnp', 'dbp',\n",
    "    'total_furosemide_equivalent_mg',\n",
    "    'hx_atrial_fibrillation', 'hx_hypertension', 'prior_hf_hospitalization_12mo',\n",
    "    'lvef', 'hf_phenotype',\n",
    "    'hx_diabetes', 'hx_renal_disease', 'hx_myocardial_infarction',\n",
    "    'hx_stroke', 'hx_copd', 'cci_score',\n",
    "    'cardiogenic_shock', 'invasive_vent'\n",
    "]\n",
    "all_columns = [v for v in all_columns if v in df_etable1.columns]\n",
    "\n",
    "categorical_vars = [\n",
    "    'male_sex', 'risk_category', 'hx_atrial_fibrillation', 'hx_hypertension',\n",
    "    'prior_hf_hospitalization_12mo', 'hf_phenotype',\n",
    "    'hx_diabetes', 'hx_renal_disease', 'hx_myocardial_infarction',\n",
    "    'hx_stroke', 'hx_copd', 'cardiogenic_shock', 'invasive_vent'\n",
    "]\n",
    "categorical_vars = [v for v in categorical_vars if v in df_etable1.columns]\n",
    "\n",
    "nonnormal_vars = ['ban_adhf_total_score', 'creatinine', 'bun', 'ntprobnp',\n",
    "                  'total_furosemide_equivalent_mg', 'cci_score']\n",
    "nonnormal_vars = [v for v in nonnormal_vars if v in df_etable1.columns]\n",
    "\n",
    "labels = {\n",
    "    'age': 'Age, years',\n",
    "    'male_sex': 'Male sex',\n",
    "    'ban_adhf_total_score': 'BAN-ADHF score',\n",
    "    'risk_category': 'Risk category',\n",
    "    'creatinine': 'Creatinine, mg/dL',\n",
    "    'bun': 'BUN, mg/dL',\n",
    "    'ntprobnp': 'NT-proBNP, pg/mL',\n",
    "    'dbp': 'Diastolic BP, mmHg',\n",
    "    'total_furosemide_equivalent_mg': 'Home diuretic dose, mg/day',\n",
    "    'hx_atrial_fibrillation': 'Atrial fibrillation',\n",
    "    'hx_hypertension': 'Hypertension',\n",
    "    'prior_hf_hospitalization_12mo': 'Prior HF hospitalization (12 mo)',\n",
    "    'lvef': 'LVEF, %',\n",
    "    'hf_phenotype': 'HF phenotype',\n",
    "    'hx_diabetes': 'Diabetes mellitus',\n",
    "    'hx_renal_disease': 'Chronic kidney disease',\n",
    "    'hx_myocardial_infarction': 'Prior MI',\n",
    "    'hx_stroke': 'Prior stroke',\n",
    "    'hx_copd': 'COPD',\n",
    "    'cci_score': 'Charlson Comorbidity Index',\n",
    "    'cardiogenic_shock': 'Cardiogenic shock',\n",
    "    'invasive_vent': 'Invasive mechanical ventilation'\n",
    "}\n",
    "\n",
    "order = {\n",
    "    'mortality_status': ['Survivors', 'Non-survivors'],\n",
    "    'risk_category': ['Low', 'Moderate', 'High'],\n",
    "    'male_sex': ['Yes', 'No'],\n",
    "    'hx_atrial_fibrillation': ['Yes', 'No'],\n",
    "    'hx_hypertension': ['Yes', 'No'],\n",
    "    'prior_hf_hospitalization_12mo': ['Yes', 'No'],\n",
    "    'hx_diabetes': ['Yes', 'No'],\n",
    "    'hx_renal_disease': ['Yes', 'No'],\n",
    "    'hx_myocardial_infarction': ['Yes', 'No'],\n",
    "    'hx_stroke': ['Yes', 'No'],\n",
    "    'hx_copd': ['Yes', 'No'],\n",
    "    'cardiogenic_shock': ['Yes', 'No'],\n",
    "    'invasive_vent': ['Yes', 'No']\n",
    "}\n",
    "\n",
    "limit = {k: 1 for k in [\n",
    "    'male_sex', 'hx_atrial_fibrillation', 'hx_hypertension',\n",
    "    'prior_hf_hospitalization_12mo', 'hx_diabetes', 'hx_renal_disease',\n",
    "    'hx_myocardial_infarction', 'hx_stroke', 'hx_copd',\n",
    "    'cardiogenic_shock', 'invasive_vent'\n",
    "]}\n",
    "\n",
    "etable1 = TableOne(\n",
    "    df_etable1,\n",
    "    columns=all_columns,\n",
    "    categorical=categorical_vars,\n",
    "    nonnormal=nonnormal_vars,\n",
    "    groupby='mortality_status',\n",
    "    pval=True,\n",
    "    rename=labels,\n",
    "    missing=False,\n",
    "    overall=True,\n",
    "    order=order,\n",
    "    limit=limit,\n",
    "    decimals=1\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(etable1.tabulate(tablefmt=\"simple\"))\n",
    "\n",
    "etable1.to_csv('/content/eTable1_baseline_by_mortality.csv')\n",
    "etable1.to_excel('/content/eTable1_baseline_by_mortality.xlsx')\n",
    "print(\"\\n\u2713 eTable 1 saved\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# eTable 2: SENSITIVITY ANALYSES SUMMARY\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"eTable 2: Sensitivity Analyses Summary\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "etable2_rows = []\n",
    "\n",
    "# Primary analysis (now pulled from detected primary_24h dict)\n",
    "etable2_rows.append([\n",
    "    'Primary analysis',\n",
    "    primary_24h['n'],\n",
    "    f\"{primary_24h['spearman_rho']:.3f}\",\n",
    "    f\"({primary_24h['spearman_ci'][0]:.3f}, {primary_24h['spearman_ci'][1]:.3f})\",\n",
    "    f\"{primary_24h['auroc_quintile']:.3f}\",\n",
    "    f\"({primary_24h['auroc_quintile_ci'][0]:.3f}, {primary_24h['auroc_quintile_ci'][1]:.3f})\",\n",
    "    '(ref)',\n",
    "    '(ref)'\n",
    "])\n",
    "\n",
    "# Sensitivity analyses\n",
    "sa_list = [\n",
    "    ('Exclude advanced CKD +', results_sensitivity['exclude_ckd']),\n",
    "    ('Exclude outliers (>P99)', results_sensitivity['exclude_outliers']),\n",
    "    ('Exclude cardiogenic shock', results_sensitivity['exclude_cs']),\n",
    "    ('Complete LVEF data only', results_sensitivity['complete_lvef'])\n",
    "]\n",
    "\n",
    "for name, sa in sa_list:\n",
    "    delta_rho = sa['spearman'] - primary_24h['spearman_rho']\n",
    "    delta_auroc = sa['auroc'] - primary_24h['auroc_quintile']\n",
    "    etable2_rows.append([\n",
    "        name,\n",
    "        sa['n'],\n",
    "        f\"{sa['spearman']:.3f}\",\n",
    "        f\"({sa['spearman_ci'][0]:.3f}, {sa['spearman_ci'][1]:.3f})\",\n",
    "        f\"{sa['auroc']:.3f}\",\n",
    "        f\"({sa['auroc_ci'][0]:.3f}, {sa['auroc_ci'][1]:.3f})\",\n",
    "        f\"{delta_rho:+.3f}\",\n",
    "        f\"{delta_auroc:+.3f}\"\n",
    "    ])\n",
    "\n",
    "etable2_df = pd.DataFrame(\n",
    "    etable2_rows,\n",
    "    columns=['Analysis', 'N', 'Spearman rho', 'rho 95% CI',\n",
    "             'AUROC (Q20)', 'AUROC 95% CI', 'Delta_rho', 'Delta_AUROC']\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(etable2_df.to_string(index=False))\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"+ CKD exclusion attenuation is expected confounding (see Discussion)\")\n",
    "\n",
    "# Threshold sensitivity (efficiency)\n",
    "if 'threshold_results' in results_sensitivity:\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"Alternative Efficiency Thresholds:\")\n",
    "    print(\"-\"*70)\n",
    "    print(f\"{'Threshold':<20} {'N Events':<12} {'AUROC':<10} {'95% CI':<25}\")\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    for t in results_sensitivity['threshold_results']:\n",
    "        ci_str = f\"({t['auroc_ci'][0]:.3f}, {t['auroc_ci'][1]:.3f})\"\n",
    "        print(f\"{t['label']:<20} {t['n_events']:<12} {t['auroc']:.3f}      {ci_str}\")\n",
    "else:\n",
    "    print(\"\\nNote: results_sensitivity['threshold_results'] not found. Skipping threshold printout.\")\n",
    "\n",
    "# DR threshold sensitivity\n",
    "if 'dr_results' in results_sensitivity:\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"Alternative Diuretic Resistance Thresholds:\")\n",
    "    print(\"-\"*70)\n",
    "    print(f\"{'Threshold':<15} {'N Resistant':<15} {'Prevalence':<12} {'AUROC':<10} {'95% CI':<25}\")\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    for t in results_sensitivity['dr_results']:\n",
    "        marker = \" <- Primary\" if t['threshold'] == 3000 else \"\"\n",
    "        ci_str = f\"({t['auroc_ci'][0]:.3f}, {t['auroc_ci'][1]:.3f})\"\n",
    "        prev_str = f\"{t['prevalence']:.1f}%\"\n",
    "        print(f\"<={t['threshold']} mL      {t['n_dr']:<15} {prev_str:<12} {t['auroc']:.3f}      {ci_str}{marker}\")\n",
    "else:\n",
    "    print(\"\\nNote: results_sensitivity['dr_results'] not found. Skipping DR threshold printout.\")\n",
    "\n",
    "etable2_df.to_csv('/content/eTable2_sensitivity_analyses.csv', index=False)\n",
    "etable2_df.to_excel('/content/eTable2_sensitivity_analyses.xlsx', index=False)\n",
    "print(\"\\n\u2713 eTable 2 saved\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# eTable 3: SECONDARY OUTCOMES\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"eTable 3: Secondary Outcomes\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "etable3_rows = []\n",
    "\n",
    "binary_outcomes = [\n",
    "    ('Vasopressor use', results_secondary['vasopressor']),\n",
    "    ('Inotrope use', results_secondary['inotrope']),\n",
    "    ('MCS use', results_secondary['mcs']),\n",
    "    ('Invasive ventilation', results_secondary['ventilation'])\n",
    "]\n",
    "\n",
    "for name, res in binary_outcomes:\n",
    "    auroc_str = f\"{res['auroc']:.3f}\" if res.get('auroc', None) is not None else \"NA\"\n",
    "    auroc_ci = f\"({res['auroc_ci'][0]:.3f}, {res['auroc_ci'][1]:.3f})\" if res.get('auroc_ci', None) is not None else \"NA\"\n",
    "    p_str = \"<0.001\" if res['p_value'] < 0.001 else f\"{res['p_value']:.3f}\"\n",
    "\n",
    "    etable3_rows.append([\n",
    "        name,\n",
    "        res['n'],\n",
    "        f\"{res['prevalence']:.1f}%\",\n",
    "        auroc_str,\n",
    "        auroc_ci,\n",
    "        f\"{res['rates_by_risk']['Low']['rate']:.1f}%\",\n",
    "        f\"{res['rates_by_risk']['Moderate']['rate']:.1f}%\",\n",
    "        f\"{res['rates_by_risk']['High']['rate']:.1f}%\",\n",
    "        p_str\n",
    "    ])\n",
    "\n",
    "etable3_df = pd.DataFrame(\n",
    "    etable3_rows,\n",
    "    columns=['Outcome', 'N', 'Prevalence', 'AUROC', '95% CI',\n",
    "             'Low', 'Moderate', 'High', 'p-value']\n",
    ")\n",
    "\n",
    "print(\"\\n--- Binary Outcomes ---\")\n",
    "print(etable3_df.to_string(index=False))\n",
    "\n",
    "# Continuous outcomes (LOS)\n",
    "print(\"\\n--- Length of Stay ---\")\n",
    "print(f\"{'Outcome':<25} {'N':<8} {'Spearman rho':<15} {'95% CI':<25} {'p-value':<10}\")\n",
    "print(\"-\"*85)\n",
    "\n",
    "icu_los = results_secondary['icu_los']\n",
    "hosp_los = results_secondary['hospital_los']\n",
    "\n",
    "icu_ci = f\"({icu_los['spearman_ci'][0]:.3f}, {icu_los['spearman_ci'][1]:.3f})\"\n",
    "icu_p = \"<0.001\" if icu_los['p_value'] < 0.001 else f\"{icu_los['p_value']:.3f}\"\n",
    "print(f\"{'ICU LOS':<25} {icu_los['n']:<8} {icu_los['spearman_rho']:.3f}           {icu_ci:<25} {icu_p}\")\n",
    "\n",
    "hosp_ci = f\"({hosp_los['spearman_ci'][0]:.3f}, {hosp_los['spearman_ci'][1]:.3f})\"\n",
    "hosp_p = \"<0.001\" if hosp_los['p_value'] < 0.001 else f\"{hosp_los['p_value']:.3f}\"\n",
    "print(f\"{'Hospital LOS':<25} {hosp_los['n']:<8} {hosp_los['spearman_rho']:.3f}           {hosp_ci:<25} {hosp_p}\")\n",
    "\n",
    "# LOS by risk category\n",
    "print(\"\\n--- LOS by Risk Category ---\")\n",
    "print(f\"{'Outcome':<15} {'Category':<12} {'N':<8} {'Median [IQR]':<25}\")\n",
    "print(\"-\"*65)\n",
    "\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    icu_data = icu_los['by_risk'][cat]\n",
    "    iqr_str = f\"{icu_data['median']:.1f} [{icu_data['iqr'][0]:.1f}-{icu_data['iqr'][1]:.1f}]\"\n",
    "    print(f\"{'ICU LOS':<15} {cat:<12} {icu_data['n']:<8} {iqr_str}\")\n",
    "\n",
    "for cat in ['Low', 'Moderate', 'High']:\n",
    "    hosp_data = hosp_los['by_risk'][cat]\n",
    "    iqr_str = f\"{hosp_data['median']:.1f} [{hosp_data['iqr'][0]:.1f}-{hosp_data['iqr'][1]:.1f}]\"\n",
    "    print(f\"{'Hospital LOS':<15} {cat:<12} {hosp_data['n']:<8} {iqr_str}\")\n",
    "\n",
    "etable3_df.to_csv('/content/eTable3_secondary_outcomes.csv', index=False)\n",
    "etable3_df.to_excel('/content/eTable3_secondary_outcomes.xlsx', index=False)\n",
    "print(\"\\n\u2713 eTable 3 saved\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# eTable 4: HF PHENOTYPE SUBGROUP ANALYSIS\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"eTable 4: HF Phenotype Subgroup Analysis\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "etable4_rows = []\n",
    "\n",
    "for phenotype in ['HFrEF', 'HFmrEF', 'HFpEF']:\n",
    "    if phenotype in results_subgroups['hf_results']:\n",
    "        res = results_subgroups['hf_results'][phenotype]\n",
    "        rho_ci = f\"({res['spearman_ci'][0]:.3f}, {res['spearman_ci'][1]:.3f})\"\n",
    "        auroc_str = f\"{res['auroc']:.3f}\" if res.get('auroc', None) is not None else \"NA\"\n",
    "        auroc_ci = f\"({res['auroc_ci'][0]:.3f}, {res['auroc_ci'][1]:.3f})\" if res.get('auroc_ci', None) is not None else \"NA\"\n",
    "        etable4_rows.append([\n",
    "            phenotype,\n",
    "            res['n'],\n",
    "            f\"{res['spearman_rho']:.3f}\",\n",
    "            rho_ci,\n",
    "            auroc_str,\n",
    "            auroc_ci\n",
    "        ])\n",
    "\n",
    "etable4_df = pd.DataFrame(\n",
    "    etable4_rows,\n",
    "    columns=['HF Phenotype', 'N', 'Spearman rho', 'rho 95% CI',\n",
    "             'AUROC (Q20)', 'AUROC 95% CI']\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(etable4_df.to_string(index=False))\n",
    "\n",
    "# LVEF distribution\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"LVEF Distribution by Phenotype:\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "df_hf = df[df['hf_phenotype'].notna()].copy()\n",
    "for phenotype in ['HFrEF', 'HFmrEF', 'HFpEF']:\n",
    "    subset = df_hf[df_hf['hf_phenotype'] == phenotype]\n",
    "    n = len(subset)\n",
    "    lvef_mean = subset['lvef'].mean()\n",
    "    lvef_std = subset['lvef'].std()\n",
    "    pct = 100 * n / len(df_hf) if len(df_hf) > 0 else np.nan\n",
    "    print(f\"  {phenotype}: N={n} ({pct:.1f}%), LVEF = {lvef_mean:.1f} +/- {lvef_std:.1f}%\")\n",
    "\n",
    "etable4_df.to_csv('/content/eTable4_hf_phenotype.csv', index=False)\n",
    "etable4_df.to_excel('/content/eTable4_hf_phenotype.xlsx', index=False)\n",
    "print(\"\\n\u2713 eTable 4 saved\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# SUMMARY\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALL SUPPLEMENTARY TABLES COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "Files generated:\n",
    "  - eTable1_baseline_by_mortality.csv/.xlsx\n",
    "  - eTable2_sensitivity_analyses.csv/.xlsx\n",
    "  - eTable3_secondary_outcomes.csv/.xlsx\n",
    "  - eTable4_hf_phenotype.csv/.xlsx\n",
    "\"\"\")\n",
    "print(\"\\n-> Next: Main Figures (Cell 18)\")\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# SECTION 14: MAIN MANUSCRIPT FIGURES\n",
    "# Cell 18: Generate Main Figures (Python versions + R data exports)\n",
    "#==========================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ---------------------------\n",
    "# Helper: find primary 24h results dict (the one with n, rho, ci, etc.)\n",
    "# ---------------------------\n",
    "def find_primary_24h_results():\n",
    "    required = {\"n\", \"spearman_rho\", \"spearman_ci\", \"auroc_quintile\", \"auroc_quintile_ci\"}\n",
    "    candidates = []\n",
    "    for name, obj in globals().items():\n",
    "        if isinstance(obj, dict) and required.issubset(set(obj.keys())):\n",
    "            candidates.append((name, obj))\n",
    "\n",
    "    if not candidates:\n",
    "        maybe = []\n",
    "        for name, obj in globals().items():\n",
    "            if isinstance(obj, dict):\n",
    "                keys = list(obj.keys())\n",
    "                if any((\"rho\" in str(k).lower()) or (\"auroc\" in str(k).lower()) or (\"c_index\" in str(k).lower()) for k in keys):\n",
    "                    maybe.append((name, keys[:30]))\n",
    "        raise KeyError(\n",
    "            \"Could not find the primary 24h discrimination dict.\\n\"\n",
    "            \"Expected keys like: n, spearman_rho, spearman_ci, auroc_quintile, auroc_quintile_ci.\\n\"\n",
    "            f\"Possible related dicts: {maybe}\"\n",
    "        )\n",
    "\n",
    "    # Prefer specific names if present\n",
    "    preferred_names = {\"results_primary_24h\", \"results_24h_primary\", \"results_discrimination_24h\", \"results_24h_discrimination\"}\n",
    "    for nm, ob in candidates:\n",
    "        if nm.lower() in preferred_names:\n",
    "            return nm, ob\n",
    "\n",
    "    return candidates[0]\n",
    "\n",
    "\n",
    "primary_24h_name, primary_24h = find_primary_24h_results()\n",
    "print(f\"Using primary 24h discrimination results from: {primary_24h_name}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Matplotlib defaults\n",
    "# ---------------------------\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 500\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.linewidth'] = 1.0\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MAIN MANUSCRIPT FIGURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "#==========================================================================\n",
    "# FIGURE 1: STUDY FLOW DIAGRAM (Text-based for now)\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FIGURE 1: Study Flow Diagram\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "MIMIC-IV Database (2008-2019)\n",
    "         |\n",
    "         v\n",
    "ICU admissions with HF diagnosis (ICD-9/10)\n",
    "         |\n",
    "         v\n",
    "Applied inclusion criteria:\n",
    "  - Age >= 18 years\n",
    "  - Primary or secondary HF diagnosis\n",
    "  - IV diuretic administration in ICU\n",
    "  - ICU stay >= 24 hours\n",
    "         |\n",
    "         v\n",
    "Excluded:\n",
    "  - Missing BAN-ADHF score components\n",
    "  - ESRD/dialysis at admission\n",
    "  - Missing urine output data\n",
    "         |\n",
    "         v\n",
    "FINAL COHORT: N = 1,505\n",
    "         |\n",
    "    +---------+---------+\n",
    "    |         |         |\n",
    "    v         v         v\n",
    " Low Risk  Moderate  High Risk\n",
    " (<=7)     (8-12)    (>=13)\n",
    " N=446     N=480     N=579\n",
    " (29.6%)   (31.9%)   (38.5%)\n",
    "\n",
    "Note: Figure 1 will be created in PowerPoint/Illustrator for publication\n",
    "\"\"\")\n",
    "\n",
    "#==========================================================================\n",
    "# FIGURE 2: DIURETIC EFFICIENCY BY RISK CATEGORY\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FIGURE 2: Diuretic Efficiency by Risk Category\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "risk_order = ['Low', 'Moderate', 'High']\n",
    "\n",
    "# 24h data\n",
    "df_fig2_24h = df[\n",
    "    (df['icu_stay_ge_24h'] == 1) &\n",
    "    (df['diuretic_efficiency_24h'].notna()) &\n",
    "    (df['diuretic_efficiency_24h'] > 0)\n",
    "].copy()\n",
    "\n",
    "# 72h data\n",
    "df_fig2_72h = df[\n",
    "    (df['icu_stay_ge_72h'] == 1) &\n",
    "    (df['diuretic_efficiency_72h'].notna()) &\n",
    "    (df['diuretic_efficiency_72h'] > 0)\n",
    "].copy()\n",
    "\n",
    "# Create figure with two panels\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Panel A: 24-hour efficiency box plots\n",
    "ax1 = axes[0]\n",
    "box_data_24h = [df_fig2_24h[df_fig2_24h['risk_category'] == cat]['diuretic_efficiency_24h'].values\n",
    "                for cat in risk_order]\n",
    "\n",
    "bp1 = ax1.boxplot(\n",
    "    box_data_24h,\n",
    "    positions=[1, 2, 3],\n",
    "    widths=0.6,\n",
    "    patch_artist=True,\n",
    "    showfliers=False,\n",
    "    medianprops=dict(color='black', linewidth=2)\n",
    ")\n",
    "\n",
    "# Use default cycle colors for boxes, no hex palette\n",
    "for patch in bp1['boxes']:\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "# Add jittered points\n",
    "for i, cat in enumerate(risk_order, start=1):\n",
    "    y = df_fig2_24h[df_fig2_24h['risk_category'] == cat]['diuretic_efficiency_24h'].values\n",
    "    x = np.random.normal(i, 0.08, size=len(y))\n",
    "    ax1.scatter(x, y, alpha=0.25, s=10, zorder=1)\n",
    "\n",
    "# Add medians + sample sizes\n",
    "for i, cat in enumerate(risk_order, start=1):\n",
    "    med = df_fig2_24h[df_fig2_24h['risk_category'] == cat]['diuretic_efficiency_24h'].median()\n",
    "    n = len(df_fig2_24h[df_fig2_24h['risk_category'] == cat])\n",
    "    ax1.text(i, med + 5, f'{med:.1f}', ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "    ax1.text(i, -15, f'n={n}', ha='center', va='top', fontsize=9)\n",
    "\n",
    "ax1.set_xticks([1, 2, 3])\n",
    "ax1.set_xticklabels(['Low\\n(<=7)', 'Moderate\\n(8-12)', 'High\\n(>=13)'])\n",
    "ax1.set_ylabel('24-Hour Diuretic Efficiency (mL/mg)', fontsize=11)\n",
    "ax1.set_xlabel('BAN-ADHF Risk Category', fontsize=11)\n",
    "ax1.set_title('A. 24-Hour Diuretic Efficiency', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylim(-20, 250)\n",
    "ax1.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# P-value annotation (use text + line, no arrows)\n",
    "ax1.plot([1, 3], [230, 230], color='black', linewidth=1)\n",
    "ax1.text(2, 235, 'p < 0.001', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Panel B: 72-hour efficiency box plots\n",
    "ax2 = axes[1]\n",
    "box_data_72h = [df_fig2_72h[df_fig2_72h['risk_category'] == cat]['diuretic_efficiency_72h'].values\n",
    "                for cat in risk_order]\n",
    "\n",
    "bp2 = ax2.boxplot(\n",
    "    box_data_72h,\n",
    "    positions=[1, 2, 3],\n",
    "    widths=0.6,\n",
    "    patch_artist=True,\n",
    "    showfliers=False,\n",
    "    medianprops=dict(color='black', linewidth=2)\n",
    ")\n",
    "\n",
    "for patch in bp2['boxes']:\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "for i, cat in enumerate(risk_order, start=1):\n",
    "    y = df_fig2_72h[df_fig2_72h['risk_category'] == cat]['diuretic_efficiency_72h'].values\n",
    "    x = np.random.normal(i, 0.08, size=len(y))\n",
    "    ax2.scatter(x, y, alpha=0.25, s=10, zorder=1)\n",
    "\n",
    "for i, cat in enumerate(risk_order, start=1):\n",
    "    med = df_fig2_72h[df_fig2_72h['risk_category'] == cat]['diuretic_efficiency_72h'].median()\n",
    "    n = len(df_fig2_72h[df_fig2_72h['risk_category'] == cat])\n",
    "    ax2.text(i, med + 5, f'{med:.1f}', ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "    ax2.text(i, -15, f'n={n}', ha='center', va='top', fontsize=9)\n",
    "\n",
    "ax2.set_xticks([1, 2, 3])\n",
    "ax2.set_xticklabels(['Low\\n(<=7)', 'Moderate\\n(8-12)', 'High\\n(>=13)'])\n",
    "ax2.set_ylabel('72-Hour Diuretic Efficiency (mL/mg)', fontsize=11)\n",
    "ax2.set_xlabel('BAN-ADHF Risk Category', fontsize=11)\n",
    "ax2.set_title('B. 72-Hour Diuretic Efficiency', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylim(-20, 250)\n",
    "ax2.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "ax2.plot([1, 3], [230, 230], color='black', linewidth=1)\n",
    "ax2.text(2, 235, 'p < 0.001', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/Figure2_efficiency_by_risk.png', dpi=500, bbox_inches='tight',\n",
    "            facecolor='white', edgecolor='none')\n",
    "plt.savefig('/content/Figure2_efficiency_by_risk.tiff', dpi=500, bbox_inches='tight',\n",
    "            facecolor='white', edgecolor='none')\n",
    "plt.show()\n",
    "print(\"\\n\u2713 Figure 2 saved (PNG and TIFF)\")\n",
    "\n",
    "#==========================================================================\n",
    "# FIGURE 3: SUBGROUP FOREST PLOT\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FIGURE 3: Subgroup Forest Plot\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "forest_df = results_subgroups['forest_data'].copy()\n",
    "\n",
    "overall_row = pd.DataFrame({\n",
    "    'subgroup': ['Overall'],\n",
    "    'n': [primary_24h['n']],\n",
    "    'rho': [primary_24h['spearman_rho']],\n",
    "    'rho_ci_low': [primary_24h['spearman_ci'][0]],\n",
    "    'rho_ci_high': [primary_24h['spearman_ci'][1]]\n",
    "})\n",
    "\n",
    "forest_df = pd.concat([overall_row, forest_df], ignore_index=True)\n",
    "\n",
    "# Sort so Overall is at top, then keep existing order for the rest\n",
    "forest_df['__order'] = range(len(forest_df))\n",
    "forest_df.loc[forest_df['subgroup'] == 'Overall', '__order'] = -1\n",
    "forest_df = forest_df.sort_values('__order').drop(columns='__order').reset_index(drop=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "\n",
    "y = np.arange(len(forest_df))\n",
    "# Plot CIs + points\n",
    "for i in range(len(forest_df)):\n",
    "    row = forest_df.iloc[i]\n",
    "    is_overall = (row['subgroup'] == 'Overall')\n",
    "\n",
    "    ax.hlines(y[i], row['rho_ci_low'], row['rho_ci_high'], linewidth=2 if is_overall else 1.5, color='black')\n",
    "    ax.plot(row['rho'], y[i], marker='D' if is_overall else 'o',\n",
    "            markersize=10 if is_overall else 7, color='black')\n",
    "\n",
    "# Reference lines\n",
    "ax.axvline(x=primary_24h['spearman_rho'], color='gray', linestyle='--', alpha=0.5, zorder=0)\n",
    "ax.axvline(x=0, color='black', linestyle='-', alpha=0.3, zorder=0)\n",
    "\n",
    "ax.set_yticks(y)\n",
    "ax.set_yticklabels(forest_df['subgroup'].tolist())\n",
    "ax.invert_yaxis()\n",
    "\n",
    "ax.set_xlabel('Spearman correlation coefficient (rho)', fontsize=12)\n",
    "ax.set_title('Figure 3: Subgroup Analysis. BAN-ADHF score vs 24h diuretic efficiency',\n",
    "             fontsize=12, fontweight='bold')\n",
    "ax.set_xlim(-0.8, 0.1)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Right-side text (n and rho)\n",
    "ax_right = ax.twinx()\n",
    "ax_right.set_ylim(ax.get_ylim())\n",
    "ax_right.set_yticks(y)\n",
    "right_labels = [\n",
    "    f\"n={int(row['n']):,}  rho={row['rho']:.3f} ({row['rho_ci_low']:.3f}, {row['rho_ci_high']:.3f})\"\n",
    "    for _, row in forest_df.iterrows()\n",
    "]\n",
    "ax_right.set_yticklabels(right_labels, fontsize=9)\n",
    "ax_right.tick_params(axis='y', length=0)\n",
    "\n",
    "# Separator after Overall row (if present)\n",
    "if (forest_df['subgroup'] == 'Overall').any() and len(forest_df) > 1:\n",
    "    ax.axhline(y=0.5, color='gray', linestyle='-', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/Figure3_forest_plot.png', dpi=500, bbox_inches='tight',\n",
    "            facecolor='white', edgecolor='none')\n",
    "plt.savefig('/content/Figure3_forest_plot.tiff', dpi=500, bbox_inches='tight',\n",
    "            facecolor='white', edgecolor='none')\n",
    "plt.show()\n",
    "print(\"\\n\u2713 Figure 3 saved (PNG and TIFF)\")\n",
    "\n",
    "#==========================================================================\n",
    "# INTERACTION P-VALUES\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERACTION TEST RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'Subgroup':<30} {'rho_1':<10} {'rho_2':<10} {'Delta':<10} {'p_interaction':<15} {'Significant'}\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "interaction_data = []\n",
    "for subgroup, data in results_subgroups['interaction_results'].items():\n",
    "    p_int = data['p_interaction']\n",
    "    sig = \"Yes *\" if p_int < 0.05 else \"No\"\n",
    "    print(f\"{subgroup:<30} {data['rho_1']:.3f}     {data['rho_2']:.3f}     {data['delta']:.3f}     {p_int:.4f}          {sig}\")\n",
    "\n",
    "    interaction_data.append({\n",
    "        'subgroup': subgroup,\n",
    "        'rho_group1': data['rho_1'],\n",
    "        'rho_group2': data['rho_2'],\n",
    "        'delta_rho': data['delta'],\n",
    "        'z_stat': data['z_stat'],\n",
    "        'p_interaction': p_int,\n",
    "        'significant': p_int < 0.05\n",
    "    })\n",
    "\n",
    "print(\"\\n* Significant interaction (p < 0.05)\")\n",
    "\n",
    "#==========================================================================\n",
    "# R DATA EXPORTS\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"R DATA EXPORTS FOR PUBLICATION-QUALITY FIGURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fig2_data = df[['hadm_id', 'ban_adhf_total_score', 'risk_category',\n",
    "                'diuretic_efficiency_24h', 'diuretic_efficiency_72h',\n",
    "                'icu_stay_ge_24h', 'icu_stay_ge_72h']].copy()\n",
    "fig2_data.to_csv('/content/data_for_R_figure2_efficiency.csv', index=False)\n",
    "print(\"\u2713 data_for_R_figure2_efficiency.csv\")\n",
    "\n",
    "forest_df.to_csv('/content/data_for_R_figure3_forest.csv', index=False)\n",
    "print(\"\u2713 data_for_R_figure3_forest.csv\")\n",
    "\n",
    "fig2_summary = []\n",
    "for timepoint in ['24h', '72h']:\n",
    "    if timepoint == '24h':\n",
    "        df_temp = df[(df['icu_stay_ge_24h'] == 1) &\n",
    "                     (df['diuretic_efficiency_24h'].notna()) &\n",
    "                     (df['diuretic_efficiency_24h'] > 0)].copy()\n",
    "        eff_col = 'diuretic_efficiency_24h'\n",
    "    else:\n",
    "        df_temp = df[(df['icu_stay_ge_72h'] == 1) &\n",
    "                     (df['diuretic_efficiency_72h'].notna()) &\n",
    "                     (df['diuretic_efficiency_72h'] > 0)].copy()\n",
    "        eff_col = 'diuretic_efficiency_72h'\n",
    "\n",
    "    for cat in ['Low', 'Moderate', 'High']:\n",
    "        subset = df_temp[df_temp['risk_category'] == cat][eff_col]\n",
    "        fig2_summary.append({\n",
    "            'timepoint': timepoint,\n",
    "            'risk_category': cat,\n",
    "            'n': len(subset),\n",
    "            'median': subset.median(),\n",
    "            'q1': subset.quantile(0.25),\n",
    "            'q3': subset.quantile(0.75),\n",
    "            'mean': subset.mean(),\n",
    "            'sd': subset.std()\n",
    "        })\n",
    "\n",
    "pd.DataFrame(fig2_summary).to_csv('/content/data_for_R_figure2_summary.csv', index=False)\n",
    "print(\"\u2713 data_for_R_figure2_summary.csv\")\n",
    "\n",
    "pd.DataFrame(interaction_data).to_csv('/content/data_for_R_interactions.csv', index=False)\n",
    "print(\"\u2713 data_for_R_interactions.csv\")\n",
    "\n",
    "# Detailed subgroup data for extended forest plot\n",
    "subgroup_detail = []\n",
    "for subgroup_name, subgroup_data in results_subgroups['subgroup_results'].items():\n",
    "    for level, metrics in subgroup_data.items():\n",
    "        subgroup_detail.append({\n",
    "            'subgroup': subgroup_name,\n",
    "            'level': level,\n",
    "            'n': metrics['n'],\n",
    "            'spearman_rho': metrics['spearman_rho'],\n",
    "            'rho_ci_low': metrics['spearman_ci'][0],\n",
    "            'rho_ci_high': metrics['spearman_ci'][1],\n",
    "            'auroc': metrics['auroc'],\n",
    "            'auroc_ci_low': metrics['auroc_ci'][0],\n",
    "            'auroc_ci_high': metrics['auroc_ci'][1]\n",
    "        })\n",
    "\n",
    "pd.DataFrame(subgroup_detail).to_csv('/content/data_for_R_subgroups_detail.csv', index=False)\n",
    "print(\"\u2713 data_for_R_subgroups_detail.csv\")\n",
    "\n",
    "#==========================================================================\n",
    "# SUMMARY\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALL MAIN FIGURES COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "Figures generated:\n",
    "  - Figure2_efficiency_by_risk.png/.tiff (500 dpi)\n",
    "  - Figure3_forest_plot.png/.tiff (500 dpi)\n",
    "\n",
    "R data exports:\n",
    "  - data_for_R_figure2_efficiency.csv (raw data)\n",
    "  - data_for_R_figure2_summary.csv (summary statistics)\n",
    "  - data_for_R_figure3_forest.csv (forest plot data with overall)\n",
    "  - data_for_R_interactions.csv (interaction p-values)\n",
    "  - data_for_R_subgroups_detail.csv (detailed subgroup metrics)\n",
    "\n",
    "Note: Figure 1 (Study Flow) should be created in PowerPoint/Illustrator\n",
    "\n",
    "SIGNIFICANT INTERACTIONS (p < 0.05):\n",
    "\"\"\")\n",
    "\n",
    "for row in interaction_data:\n",
    "    if row['significant']:\n",
    "        print(f\"  - {row['subgroup']}: p = {row['p_interaction']:.4f}\")\n",
    "\n",
    "print(\"\\n-> Next: Supplementary Figures (Cell 19)\")\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# SECTION 15: SUPPLEMENTARY FIGURES\n",
    "# Cell 19: Generate Supplementary Figures (eFigures 1-3)\n",
    "#   - Updated to be consistent with your current results dicts\n",
    "#   - Keeps your risk colors (Low/Moderate/High)\n",
    "#   - Avoids seaborn dependency (not needed here)\n",
    "#   - Makes ROC sections robust to missing columns and NaNs\n",
    "#==========================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -----------------------------\n",
    "# Publication-quality defaults\n",
    "# -----------------------------\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 500\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.linewidth'] = 1.0\n",
    "\n",
    "# -----------------------------\n",
    "# Your fixed palette\n",
    "# -----------------------------\n",
    "RISK_COLORS = {'Low': '#2ecc71', 'Moderate': '#f39c12', 'High': '#e74c3c'}\n",
    "RISK_ORDER = ['Low', 'Moderate', 'High']\n",
    "\n",
    "# -----------------------------\n",
    "# Helper: safe ROC computation\n",
    "# -----------------------------\n",
    "def compute_roc(y_true, y_score):\n",
    "    \"\"\"\n",
    "    Returns (fpr, tpr, auc_value) or (None, None, None) if invalid\n",
    "    \"\"\"\n",
    "    y_true = pd.Series(y_true).astype(float)\n",
    "    y_score = pd.Series(y_score).astype(float)\n",
    "\n",
    "    valid = y_true.notna() & y_score.notna()\n",
    "    y_true = y_true[valid]\n",
    "    y_score = y_score[valid]\n",
    "\n",
    "    # Need both classes present\n",
    "    if y_true.nunique() < 2 or len(y_true) < 10:\n",
    "        return None, None, None\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    return fpr, tpr, auc(fpr, tpr)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SUPPLEMENTARY FIGURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "#==========================================================================\n",
    "# eFIGURE 1: ROC CURVES COMPARISON\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"eFigure 1: ROC Curves for Binary Outcomes\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "df_roc = df.copy()\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Panel A: Lowest Quintile (Q20) Efficiency (24h)\n",
    "#------------------------------------------------------------------------------\n",
    "ax1 = axes[0]\n",
    "\n",
    "df_24h_roc = df_roc[(df_roc['icu_stay_ge_24h'] == 1) &\n",
    "                    (df_roc['diuretic_efficiency_24h'].notna()) &\n",
    "                    (df_roc['diuretic_efficiency_24h'] > 0)].copy()\n",
    "\n",
    "q20_threshold = df_24h_roc['diuretic_efficiency_24h'].quantile(0.20)\n",
    "df_24h_roc['low_quintile'] = (df_24h_roc['diuretic_efficiency_24h'] <= q20_threshold).astype(int)\n",
    "\n",
    "# BAN-ADHF score ROC (note: higher score predicts lower efficiency, so this is correct direction)\n",
    "fpr_score, tpr_score, auc_score = compute_roc(df_24h_roc['low_quintile'], df_24h_roc['ban_adhf_total_score'])\n",
    "\n",
    "# Components ROCs (if present)\n",
    "component_defs = [\n",
    "    ('creatinine', 'Creatinine'),\n",
    "    ('bun', 'BUN'),\n",
    "    ('ntprobnp', 'NT-proBNP')\n",
    "]\n",
    "colors_comp = {'Creatinine': '#e74c3c', 'BUN': '#9b59b6', 'NT-proBNP': '#3498db'}\n",
    "\n",
    "if fpr_score is not None:\n",
    "    ax1.plot(fpr_score, tpr_score, color='black', linewidth=2.5,\n",
    "             label=f'BAN-ADHF Score (AUC={auc_score:.3f})')\n",
    "else:\n",
    "    ax1.text(0.5, 0.5, 'Insufficient data for ROC', ha='center', va='center', fontsize=11)\n",
    "\n",
    "ax1.plot([0, 1], [0, 1], 'k--', linewidth=1, alpha=0.5, label='Reference')\n",
    "\n",
    "for col, label in component_defs:\n",
    "    if col in df_24h_roc.columns:\n",
    "        fpr_c, tpr_c, auc_c = compute_roc(df_24h_roc['low_quintile'], df_24h_roc[col])\n",
    "        if fpr_c is not None:\n",
    "            ax1.plot(fpr_c, tpr_c, color=colors_comp.get(label, 'gray'),\n",
    "                     linewidth=1.5, linestyle='--', alpha=0.8,\n",
    "                     label=f'{label} (AUC={auc_c:.3f})')\n",
    "\n",
    "ax1.set_xlabel('1 - Specificity (False Positive Rate)', fontsize=11)\n",
    "ax1.set_ylabel('Sensitivity (True Positive Rate)', fontsize=11)\n",
    "ax1.set_title('A. Lowest Quintile Efficiency (Q20)', fontsize=12, fontweight='bold')\n",
    "ax1.legend(loc='lower right', fontsize=9)\n",
    "ax1.set_xlim([0, 1])\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.set_aspect('equal')\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Panel B: Diuretic Resistance\n",
    "#   Uses existing df['diuretic_resistance'] if present\n",
    "#   Otherwise reconstructs using UOP <= 3000 mL if a suitable UOP column exists\n",
    "#------------------------------------------------------------------------------\n",
    "ax2 = axes[1]\n",
    "\n",
    "df_dr_roc = df_roc[(df_roc['icu_stay_ge_24h'] == 1)].copy()\n",
    "\n",
    "if 'diuretic_resistance' in df_dr_roc.columns:\n",
    "    y_dr = df_dr_roc['diuretic_resistance']\n",
    "else:\n",
    "    # Try to reconstruct from common UOP column names\n",
    "    uop_candidates = ['urine_output_24h', 'uop_24h', 'uop_first_24h', 'urine_output_first_24h']\n",
    "    uop_col = next((c for c in uop_candidates if c in df_dr_roc.columns), None)\n",
    "    if uop_col is None:\n",
    "        y_dr = None\n",
    "    else:\n",
    "        y_dr = (df_dr_roc[uop_col] <= 3000).astype(int)\n",
    "\n",
    "if y_dr is None:\n",
    "    ax2.text(0.5, 0.5, 'No diuretic_resistance or UOP column found', ha='center', va='center', fontsize=11)\n",
    "    auc_dr = np.nan\n",
    "else:\n",
    "    fpr_dr, tpr_dr, auc_dr = compute_roc(y_dr, df_dr_roc['ban_adhf_total_score'])\n",
    "    if fpr_dr is not None:\n",
    "        ax2.plot(fpr_dr, tpr_dr, color='black', linewidth=2.5, label=f'BAN-ADHF Score (AUC={auc_dr:.3f})')\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'Insufficient data for ROC', ha='center', va='center', fontsize=11)\n",
    "\n",
    "ax2.plot([0, 1], [0, 1], 'k--', linewidth=1, alpha=0.5, label='Reference')\n",
    "ax2.set_xlabel('1 - Specificity (False Positive Rate)', fontsize=11)\n",
    "ax2.set_ylabel('Sensitivity (True Positive Rate)', fontsize=11)\n",
    "ax2.set_title('B. Diuretic Resistance (UOP <=3000 mL)', fontsize=12, fontweight='bold')\n",
    "ax2.legend(loc='lower right', fontsize=9)\n",
    "ax2.set_xlim([0, 1])\n",
    "ax2.set_ylim([0, 1])\n",
    "ax2.set_aspect('equal')\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "if y_dr is not None and pd.Series(y_dr).notna().any():\n",
    "    prevalence = pd.Series(y_dr).mean() * 100\n",
    "    ax2.text(0.95, 0.05, f'Prevalence: {prevalence:.1f}%', transform=ax2.transAxes,\n",
    "             ha='right', va='bottom', fontsize=10, style='italic')\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Panel C: In-Hospital Mortality\n",
    "#------------------------------------------------------------------------------\n",
    "ax3 = axes[2]\n",
    "\n",
    "df_mort_roc = df_roc[df_roc['hospital_expire_flag'].notna()].copy()\n",
    "fpr_mort, tpr_mort, auc_mort = compute_roc(df_mort_roc['hospital_expire_flag'], df_mort_roc['ban_adhf_total_score'])\n",
    "\n",
    "# CS subgroup\n",
    "if 'cardiogenic_shock' in df_mort_roc.columns:\n",
    "    df_cs = df_mort_roc[df_mort_roc['cardiogenic_shock'] == 1].copy()\n",
    "else:\n",
    "    df_cs = df_mort_roc.iloc[0:0].copy()\n",
    "\n",
    "fpr_cs, tpr_cs, auc_cs = (None, None, None)\n",
    "if len(df_cs) > 0:\n",
    "    fpr_cs, tpr_cs, auc_cs = compute_roc(df_cs['hospital_expire_flag'], df_cs['ban_adhf_total_score'])\n",
    "\n",
    "if fpr_mort is not None:\n",
    "    ax3.plot(fpr_mort, tpr_mort, color='black', linewidth=2.5, label=f'All patients (AUC={auc_mort:.3f})')\n",
    "else:\n",
    "    ax3.text(0.5, 0.55, 'Insufficient mortality data for ROC', ha='center', va='center', fontsize=11)\n",
    "\n",
    "if fpr_cs is not None:\n",
    "    ax3.plot(fpr_cs, tpr_cs, color=RISK_COLORS['High'], linewidth=2.0, label=f'CS subgroup (AUC={auc_cs:.3f})')\n",
    "\n",
    "ax3.plot([0, 1], [0, 1], 'k--', linewidth=1, alpha=0.5, label='Reference')\n",
    "\n",
    "ax3.set_xlabel('1 - Specificity (False Positive Rate)', fontsize=11)\n",
    "ax3.set_ylabel('Sensitivity (True Positive Rate)', fontsize=11)\n",
    "ax3.set_title('C. In-Hospital Mortality', fontsize=12, fontweight='bold')\n",
    "ax3.legend(loc='lower right', fontsize=9)\n",
    "ax3.set_xlim([0, 1])\n",
    "ax3.set_ylim([0, 1])\n",
    "ax3.set_aspect('equal')\n",
    "ax3.grid(alpha=0.3)\n",
    "\n",
    "mort_rate = df_mort_roc['hospital_expire_flag'].mean() * 100 if len(df_mort_roc) else np.nan\n",
    "if not np.isnan(mort_rate):\n",
    "    ax3.text(0.95, 0.05, f'Mortality: {mort_rate:.1f}%', transform=ax3.transAxes,\n",
    "             ha='right', va='bottom', fontsize=10, style='italic')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/eFigure1_ROC_curves.png', dpi=500, bbox_inches='tight',\n",
    "            facecolor='white', edgecolor='none')\n",
    "plt.savefig('/content/eFigure1_ROC_curves.tiff', dpi=500, bbox_inches='tight',\n",
    "            facecolor='white', edgecolor='none')\n",
    "plt.show()\n",
    "print(\"\\n\u2713 eFigure 1 saved (PNG and TIFF)\")\n",
    "\n",
    "#==========================================================================\n",
    "# eFIGURE 2: BAN-ADHF SCORE DISTRIBUTION\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"eFigure 2: BAN-ADHF Score Distribution\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Panel A: Score Distribution with Risk Categories\n",
    "#------------------------------------------------------------------------------\n",
    "ax1 = axes[0]\n",
    "\n",
    "for cat in RISK_ORDER:\n",
    "    subset = df[df['risk_category'] == cat]['ban_adhf_total_score'].dropna()\n",
    "    ax1.hist(subset, bins=range(0, 26), alpha=0.6, label=f'{cat} (n={len(subset)})',\n",
    "             color=RISK_COLORS[cat], edgecolor='white')\n",
    "\n",
    "# Thresholds (<=7, 8-12, >=13)\n",
    "ax1.axvline(x=7.5, color='black', linestyle='--', linewidth=2, label='Risk thresholds')\n",
    "ax1.axvline(x=12.5, color='black', linestyle='--', linewidth=2)\n",
    "\n",
    "ax1.set_xlabel('BAN-ADHF Score', fontsize=11)\n",
    "ax1.set_ylabel('Frequency', fontsize=11)\n",
    "ax1.set_title('A. Score Distribution by Risk Category', fontsize=12, fontweight='bold')\n",
    "ax1.legend(loc='upper right', fontsize=9)\n",
    "ax1.set_xlim([0, 25])\n",
    "\n",
    "median_score = df['ban_adhf_total_score'].median()\n",
    "iqr_low = df['ban_adhf_total_score'].quantile(0.25)\n",
    "iqr_high = df['ban_adhf_total_score'].quantile(0.75)\n",
    "ax1.text(0.02, 0.98, f'Median [IQR]: {median_score:.0f} [{iqr_low:.0f}-{iqr_high:.0f}]',\n",
    "         transform=ax1.transAxes, ha='left', va='top', fontsize=10,\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Panel B: Score Distribution by Mortality\n",
    "#------------------------------------------------------------------------------\n",
    "ax2 = axes[1]\n",
    "\n",
    "survivors = df[df['hospital_expire_flag'] == 0]['ban_adhf_total_score'].dropna()\n",
    "non_survivors = df[df['hospital_expire_flag'] == 1]['ban_adhf_total_score'].dropna()\n",
    "\n",
    "ax2.hist(survivors, bins=range(0, 26), alpha=0.6, label=f'Survivors (n={len(survivors)})',\n",
    "         color='#3498db', edgecolor='white', density=True)\n",
    "ax2.hist(non_survivors, bins=range(0, 26), alpha=0.6, label=f'Non-survivors (n={len(non_survivors)})',\n",
    "         color=RISK_COLORS['High'], edgecolor='white', density=True)\n",
    "\n",
    "ax2.axvline(x=survivors.median(), color='#3498db', linestyle='-', linewidth=2)\n",
    "ax2.axvline(x=non_survivors.median(), color=RISK_COLORS['High'], linestyle='-', linewidth=2)\n",
    "\n",
    "ax2.set_xlabel('BAN-ADHF Score', fontsize=11)\n",
    "ax2.set_ylabel('Density', fontsize=11)\n",
    "ax2.set_title('B. Score Distribution by Mortality Status', fontsize=12, fontweight='bold')\n",
    "ax2.legend(loc='upper right', fontsize=9)\n",
    "ax2.set_xlim([0, 25])\n",
    "\n",
    "ax2.text(0.02, 0.98,\n",
    "         f'Survivors median: {survivors.median():.0f}\\nNon-survivors median: {non_survivors.median():.0f}',\n",
    "         transform=ax2.transAxes, ha='left', va='top', fontsize=10,\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/eFigure2_score_distribution.png', dpi=500, bbox_inches='tight',\n",
    "            facecolor='white', edgecolor='none')\n",
    "plt.savefig('/content/eFigure2_score_distribution.tiff', dpi=500, bbox_inches='tight',\n",
    "            facecolor='white', edgecolor='none')\n",
    "plt.show()\n",
    "print(\"\\n\u2713 eFigure 2 saved (PNG and TIFF)\")\n",
    "\n",
    "#==========================================================================\n",
    "# eFIGURE 3: CORRELATION SCATTER PLOT\n",
    "#   Updated: pulls rho and r safely even if results_24h is scenario-keyed\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"eFigure 3: Correlation Scatter Plot\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "df_scatter = df[(df['icu_stay_ge_24h'] == 1) &\n",
    "                (df['diuretic_efficiency_24h'].notna()) &\n",
    "                (df['diuretic_efficiency_24h'] > 0)].copy()\n",
    "\n",
    "df_scatter['eff_capped'] = df_scatter['diuretic_efficiency_24h'].clip(upper=200)\n",
    "\n",
    "for cat in RISK_ORDER:\n",
    "    subset = df_scatter[df_scatter['risk_category'] == cat]\n",
    "    ax.scatter(subset['ban_adhf_total_score'], subset['eff_capped'],\n",
    "               alpha=0.4, s=20, color=RISK_COLORS[cat], label=cat)\n",
    "\n",
    "# Regression line\n",
    "z = np.polyfit(df_scatter['ban_adhf_total_score'], df_scatter['eff_capped'], 1)\n",
    "p = np.poly1d(z)\n",
    "x_line = np.linspace(0, 25, 100)\n",
    "ax.plot(x_line, p(x_line), color='black', linewidth=2, label='Linear fit')\n",
    "\n",
    "# Try to pull correlations from current-style dicts\n",
    "rho = None\n",
    "pearson_r = None\n",
    "if isinstance(results_24h, dict):\n",
    "    # If you have the \"final\" results dict elsewhere, use it.\n",
    "    # Otherwise, fall back to computing from df_scatter directly.\n",
    "    rho = None\n",
    "    pearson_r = None\n",
    "\n",
    "if rho is None:\n",
    "    # Spearman rho from data\n",
    "    rho = pd.Series(df_scatter['ban_adhf_total_score']).corr(pd.Series(df_scatter['diuretic_efficiency_24h']),\n",
    "                                                            method='spearman')\n",
    "if pearson_r is None:\n",
    "    pearson_r = pd.Series(df_scatter['ban_adhf_total_score']).corr(pd.Series(df_scatter['diuretic_efficiency_24h']),\n",
    "                                                                   method='pearson')\n",
    "\n",
    "ax.text(0.95, 0.95, f'Spearman rho = {rho:.3f}\\nPearson r = {pearson_r:.3f}\\np < 0.001',\n",
    "        transform=ax.transAxes, ha='right', va='top', fontsize=11,\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "\n",
    "ax.set_xlabel('BAN-ADHF Score', fontsize=12)\n",
    "ax.set_ylabel('24-Hour Diuretic Efficiency (mL/mg)', fontsize=12)\n",
    "ax.set_title('eFigure 3: BAN-ADHF Score vs Diuretic Efficiency', fontsize=12, fontweight='bold')\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "ax.set_xlim([0, 25])\n",
    "ax.set_ylim([0, 210])\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/eFigure3_scatter_correlation.png', dpi=500, bbox_inches='tight',\n",
    "            facecolor='white', edgecolor='none')\n",
    "plt.savefig('/content/eFigure3_scatter_correlation.tiff', dpi=500, bbox_inches='tight',\n",
    "            facecolor='white', edgecolor='none')\n",
    "plt.show()\n",
    "print(\"\\n\u2713 eFigure 3 saved (PNG and TIFF)\")\n",
    "\n",
    "#==========================================================================\n",
    "# R DATA EXPORTS FOR SUPPLEMENTARY FIGURES\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"R DATA EXPORTS FOR SUPPLEMENTARY FIGURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ROC data for eFigure 1 (primary curve only, plus threshold for reproducibility)\n",
    "roc_data = pd.DataFrame({\n",
    "    'fpr_q20': pd.Series(fpr_score) if fpr_score is not None else pd.Series(dtype=float),\n",
    "    'tpr_q20': pd.Series(tpr_score) if tpr_score is not None else pd.Series(dtype=float),\n",
    "})\n",
    "roc_data.to_csv('/content/data_for_R_roc_q20.csv', index=False)\n",
    "print(\"\u2713 data_for_R_roc_q20.csv\")\n",
    "\n",
    "# Score distribution data\n",
    "score_dist = df[['ban_adhf_total_score', 'risk_category', 'hospital_expire_flag']].copy()\n",
    "score_dist.to_csv('/content/data_for_R_score_distribution.csv', index=False)\n",
    "print(\"\u2713 data_for_R_score_distribution.csv\")\n",
    "\n",
    "# Scatter plot data\n",
    "scatter_data = df_scatter[['ban_adhf_total_score', 'diuretic_efficiency_24h', 'risk_category']].copy()\n",
    "scatter_data.to_csv('/content/data_for_R_scatter.csv', index=False)\n",
    "print(\"\u2713 data_for_R_scatter.csv\")\n",
    "\n",
    "#==========================================================================\n",
    "# SUMMARY\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALL SUPPLEMENTARY FIGURES COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\"\"\n",
    "Figures generated:\n",
    "  - eFigure1_ROC_curves.png/.tiff (500 dpi)\n",
    "  - eFigure2_score_distribution.png/.tiff (500 dpi)\n",
    "  - eFigure3_scatter_correlation.png/.tiff (500 dpi)\n",
    "\n",
    "R data exports:\n",
    "  - data_for_R_roc_q20.csv\n",
    "  - data_for_R_score_distribution.csv\n",
    "  - data_for_R_scatter.csv\n",
    "\n",
    "Summary of AUROCs:\n",
    "  - Lowest quintile (Q20): {auc_score:.3f}\n",
    "  - Diuretic resistance: {auc_dr:.3f}\n",
    "  - Mortality (all): {auc_mort:.3f}\n",
    "  - Mortality (CS subgroup): {auc_cs:.3f}\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n-> Next: Abstract and Results Text (Cell 20)\")\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# SECTION 16: MANUSCRIPT TEXT GENERATION\n",
    "# Cell 20: Generate Abstract and Results Section Text (ROBUST + CONSISTENT)\n",
    "#\n",
    "# Fixes in this version:\n",
    "#  - Handles gender coded as 'M'/'F', 1/0, True/False, or already \"male_sex\"\n",
    "#  - Avoids KeyError if any results dict keys are missing\n",
    "#  - Uses your computed medians/IQRs by risk from eff_24h_by_risk\n",
    "#  - Removes the \u201cstrongest Spearman in any study\u201d claim (hard to defend without full review)\n",
    "#  - Keeps your AUROC Q20 CI consistent with your printed Table 2\n",
    "#==========================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MANUSCRIPT TEXT GENERATION (ROBUST)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# -----------------------------\n",
    "# Helper functions\n",
    "# -----------------------------\n",
    "def safe_get(d, key, default=np.nan):\n",
    "    return d.get(key, default) if isinstance(d, dict) else default\n",
    "\n",
    "def safe_ci(d, key, default=(np.nan, np.nan)):\n",
    "    ci = safe_get(d, key, default)\n",
    "    if ci is None or (isinstance(ci, float) and np.isnan(ci)):\n",
    "        return default\n",
    "    if isinstance(ci, (list, tuple)) and len(ci) == 2:\n",
    "        return (ci[0], ci[1])\n",
    "    return default\n",
    "\n",
    "def fmt_pct(x, decimals=1):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return \"NA\"\n",
    "    return f\"{x*100:.{decimals}f}%\"\n",
    "\n",
    "def fmt_mean_sd(series, decimals=1):\n",
    "    s = pd.Series(series).dropna()\n",
    "    if len(s) == 0:\n",
    "        return \"NA\"\n",
    "    return f\"{s.mean():.{decimals}f} +/- {s.std():.{decimals}f}\"\n",
    "\n",
    "def infer_male_pct(df):\n",
    "    \"\"\"\n",
    "    Returns (male_pct_float, male_label_str) where male_pct_float is 0-1 or np.nan\n",
    "    \"\"\"\n",
    "    # Prefer explicit male_sex if present\n",
    "    if 'male_sex' in df.columns:\n",
    "        s = pd.Series(df['male_sex'])\n",
    "        # map common encodings\n",
    "        if s.dtype == 'object':\n",
    "            s2 = s.map({'Yes': 1, 'No': 0, 'M': 1, 'F': 0, 'Male': 1, 'Female': 0, True: 1, False: 0})\n",
    "        else:\n",
    "            s2 = s.astype(float)\n",
    "        s2 = s2.dropna()\n",
    "        if len(s2) == 0:\n",
    "            return (np.nan, \"NA\")\n",
    "        return (float(s2.mean()), fmt_pct(float(s2.mean())))\n",
    "    # Fall back to gender if present\n",
    "    if 'gender' in df.columns:\n",
    "        g = pd.Series(df['gender'])\n",
    "        if g.dtype == 'object':\n",
    "            male = g.astype(str).str.upper().eq('M')\n",
    "            male_pct = male.mean() if len(male) else np.nan\n",
    "            return (float(male_pct), fmt_pct(float(male_pct)))\n",
    "        # If numeric/bool: assume 1=male, 0=female (common)\n",
    "        g2 = pd.to_numeric(g, errors='coerce').dropna()\n",
    "        if len(g2) == 0:\n",
    "            return (np.nan, \"NA\")\n",
    "        male_pct = float((g2 == 1).mean())\n",
    "        return (male_pct, fmt_pct(male_pct))\n",
    "    return (np.nan, \"NA\")\n",
    "\n",
    "def risk_counts(df):\n",
    "    out = {}\n",
    "    n_total = len(df)\n",
    "    for cat in ['Low', 'Moderate', 'High']:\n",
    "        n = int((df['risk_category'] == cat).sum()) if 'risk_category' in df.columns else 0\n",
    "        out[cat] = {'n': n, 'pct': (n / n_total) if n_total > 0 else np.nan}\n",
    "    return out\n",
    "\n",
    "def fmt_ci(ci, decimals=3, sep=\" to \"):\n",
    "    lo, hi = ci\n",
    "    if lo is None or hi is None or (isinstance(lo, float) and np.isnan(lo)) or (isinstance(hi, float) and np.isnan(hi)):\n",
    "        return \"NA\"\n",
    "    return f\"{lo:.{decimals}f}{sep}{hi:.{decimals}f}\"\n",
    "\n",
    "# -----------------------------\n",
    "# Pull core stats safely\n",
    "# -----------------------------\n",
    "n_total = len(df)\n",
    "age_mean_sd = fmt_mean_sd(df['age']) if 'age' in df.columns else \"NA\"\n",
    "male_pct_float, male_pct_str = infer_male_pct(df)\n",
    "\n",
    "ban_median = df['ban_adhf_total_score'].median() if 'ban_adhf_total_score' in df.columns else np.nan\n",
    "ban_q1 = df['ban_adhf_total_score'].quantile(0.25) if 'ban_adhf_total_score' in df.columns else np.nan\n",
    "ban_q3 = df['ban_adhf_total_score'].quantile(0.75) if 'ban_adhf_total_score' in df.columns else np.nan\n",
    "\n",
    "risk = risk_counts(df)\n",
    "\n",
    "# Results dict keys\n",
    "n_24 = int(safe_get(results_24h, 'n', np.nan)) if safe_get(results_24h, 'n', None) is not None else np.nan\n",
    "rho_24 = safe_get(results_24h, 'spearman_rho', np.nan)\n",
    "rho_24_ci = safe_ci(results_24h, 'spearman_ci')\n",
    "pearson_24 = safe_get(results_24h, 'pearson_r', np.nan)\n",
    "pearson_24_ci = safe_ci(results_24h, 'pearson_ci')\n",
    "auroc_q20 = safe_get(results_24h, 'auroc_quintile', np.nan)\n",
    "auroc_q20_ci = safe_ci(results_24h, 'auroc_quintile_ci')\n",
    "auroc_q25 = safe_get(results_24h, 'auroc_quartile', np.nan)\n",
    "auroc_q25_ci = safe_ci(results_24h, 'auroc_quartile_ci')\n",
    "c_index = safe_get(results_24h, 'c_index', np.nan)\n",
    "c_index_ci = safe_ci(results_24h, 'c_index_ci')\n",
    "\n",
    "# 72h\n",
    "n_72 = int(safe_get(results_72h, 'n', np.nan)) if safe_get(results_72h, 'n', None) is not None else np.nan\n",
    "rho_72 = safe_get(results_72h, 'spearman_rho', np.nan)\n",
    "rho_72_ci = safe_ci(results_72h, 'spearman_ci')\n",
    "auroc72_q20 = safe_get(results_72h, 'auroc_quintile', np.nan)\n",
    "auroc72_q20_ci = safe_ci(results_72h, 'auroc_quintile_ci')\n",
    "\n",
    "# DR + mortality\n",
    "dr_prev = safe_get(results_dr, 'prevalence', np.nan)\n",
    "dr_auroc = safe_get(results_dr, 'auroc', np.nan)\n",
    "dr_auroc_ci = safe_ci(results_dr, 'auroc_ci')\n",
    "\n",
    "mort_rate = safe_get(results_mortality, 'mortality_rate', np.nan)\n",
    "mort_n = safe_get(results_mortality, 'n', np.nan)\n",
    "mort_deaths = safe_get(results_mortality, 'n_deaths', np.nan)\n",
    "mort_auroc = safe_get(results_mortality, 'auroc', np.nan)\n",
    "mort_auroc_ci = safe_ci(results_mortality, 'auroc_ci')\n",
    "mort_auroc_cs = safe_get(results_mortality, 'auroc_cs', np.nan)\n",
    "\n",
    "# Fold difference (guard against divide by zero)\n",
    "low_med = eff_24h_by_risk['Low']['median'] if 'Low' in eff_24h_by_risk else np.nan\n",
    "high_med = eff_24h_by_risk['High']['median'] if 'High' in eff_24h_by_risk else np.nan\n",
    "fold_diff = (low_med / high_med) if (pd.notna(low_med) and pd.notna(high_med) and high_med != 0) else np.nan\n",
    "pct_reduction = ((low_med - high_med) / low_med * 100) if (pd.notna(low_med) and pd.notna(high_med) and low_med != 0) else np.nan\n",
    "\n",
    "# Some cohort severity fields (only if columns exist)\n",
    "cs_pct = df['cardiogenic_shock'].mean() if 'cardiogenic_shock' in df.columns else np.nan\n",
    "vent_pct = df['invasive_vent'].mean() if 'invasive_vent' in df.columns else np.nan\n",
    "ckd_pct = df['hx_renal_disease'].mean() if 'hx_renal_disease' in df.columns else np.nan\n",
    "nt_median = df['ntprobnp'].median() if 'ntprobnp' in df.columns else np.nan\n",
    "nt_q1 = df['ntprobnp'].quantile(0.25) if 'ntprobnp' in df.columns else np.nan\n",
    "nt_q3 = df['ntprobnp'].quantile(0.75) if 'ntprobnp' in df.columns else np.nan\n",
    "\n",
    "# Subgroup interactions (use what you computed, but don\u2019t hardcode values)\n",
    "interaction_results = safe_get(results_subgroups, 'interaction_results', {}) or {}\n",
    "\n",
    "# HF phenotypes\n",
    "hf_results = safe_get(results_subgroups, 'hf_results', {}) or {}\n",
    "\n",
    "#==========================================================================\n",
    "# ABSTRACT\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ABSTRACT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "abstract = f\"\"\"\n",
    "BACKGROUND: The BAN-ADHF score was developed to predict diuretic efficiency in acute decompensated heart failure (ADHF). Its performance in critically ill intensive care unit (ICU) populations is less well characterized.\n",
    "\n",
    "OBJECTIVES: To externally validate the BAN-ADHF score for predicting diuretic efficiency in ICU patients with ADHF.\n",
    "\n",
    "METHODS: Retrospective cohort study using the MIMIC-IV database (2008-2019). We included adult ICU patients with ADHF receiving intravenous diuretics and an ICU stay of at least 24 hours. The primary outcome was 24-hour diuretic efficiency (mL urine output per mg intravenous furosemide equivalent). Discrimination was assessed using Spearman correlation, Pearson correlation, concordance index (C-index), and area under the receiver operating characteristic curve (AUROC) for the lowest efficiency quintile. Patients were stratified into low (<=7), moderate (8-12), and high (>=13) risk categories.\n",
    "\n",
    "RESULTS: Among {n_24:,} patients with 24-hour efficiency data (age {age_mean_sd} years, {male_pct_str} male), the BAN-ADHF score demonstrated an inverse association with diuretic efficiency (Spearman rho = {rho_24:.3f}, 95% CI {rho_24_ci[0]:.3f} to {rho_24_ci[1]:.3f}; Pearson r = {pearson_24:.3f}, 95% CI {pearson_24_ci[0]:.3f} to {pearson_24_ci[1]:.3f}). AUROC for identifying the lowest efficiency quintile was {auroc_q20:.3f} (95% CI {auroc_q20_ci[0]:.3f}-{auroc_q20_ci[1]:.3f}). Median 24-hour diuretic efficiency decreased across risk categories: low {eff_24h_by_risk['Low']['median']:.1f} mL/mg [IQR {eff_24h_by_risk['Low']['q1']:.1f}-{eff_24h_by_risk['Low']['q3']:.1f}], moderate {eff_24h_by_risk['Moderate']['median']:.1f} mL/mg [{eff_24h_by_risk['Moderate']['q1']:.1f}-{eff_24h_by_risk['Moderate']['q3']:.1f}], and high {eff_24h_by_risk['High']['median']:.1f} mL/mg [{eff_24h_by_risk['High']['q1']:.1f}-{eff_24h_by_risk['High']['q3']:.1f}] (p < 0.001). Results were similar across pre-specified sensitivity analyses and subgroups.\n",
    "\n",
    "CONCLUSIONS: The BAN-ADHF score demonstrates preserved discrimination for diuretic efficiency in critically ill ICU patients, supporting its use for risk stratification in this high-acuity population.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(abstract)\n",
    "\n",
    "#==========================================================================\n",
    "# RESULTS SECTION\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTS SECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Build interaction summary lines dynamically (only significant ones)\n",
    "sig_interactions = []\n",
    "for name, d in interaction_results.items():\n",
    "    p_int = safe_get(d, 'p_interaction', np.nan)\n",
    "    if pd.notna(p_int) and p_int < 0.05:\n",
    "        sig_interactions.append((name, d))\n",
    "\n",
    "interaction_block = \"\"\n",
    "if len(sig_interactions) > 0:\n",
    "    interaction_lines = []\n",
    "    for name, d in sig_interactions:\n",
    "        p_int = safe_get(d, 'p_interaction', np.nan)\n",
    "        rho1 = safe_get(d, 'rho_1', np.nan)\n",
    "        rho2 = safe_get(d, 'rho_2', np.nan)\n",
    "        interaction_lines.append(\n",
    "            f\"{name}: p-interaction = {p_int:.3f}; rho = {rho1:.3f} vs {rho2:.3f}\"\n",
    "        )\n",
    "    interaction_block = \"Significant effect modification was observed for: \" + \"; \".join(interaction_lines) + \".\"\n",
    "else:\n",
    "    interaction_block = \"No statistically significant effect modification was observed across pre-specified subgroups.\"\n",
    "\n",
    "# HF phenotype block (only if present)\n",
    "hf_block = \"\"\n",
    "if isinstance(hf_results, dict) and len(hf_results) > 0:\n",
    "    parts = []\n",
    "    for pheno in ['HFrEF', 'HFmrEF', 'HFpEF']:\n",
    "        if pheno in hf_results:\n",
    "            r = hf_results[pheno]\n",
    "            parts.append(\n",
    "                f\"{pheno} (rho = {safe_get(r, 'spearman_rho', np.nan):.3f}, AUROC = {safe_get(r, 'auroc', np.nan):.3f})\"\n",
    "            )\n",
    "    if len(parts) > 0:\n",
    "        hf_block = \"Score performance was preserved across heart failure phenotypes (eTable 4): \" + \", \".join(parts) + \".\"\n",
    "\n",
    "results_text = f\"\"\"\n",
    "RESULTS\n",
    "\n",
    "Study Population\n",
    "\n",
    "From the MIMIC-IV database, we identified {n_total:,} patients meeting inclusion criteria (Figure 1). The cohort had an age of {age_mean_sd} years, with {male_pct_str} male. The median BAN-ADHF score was {ban_median:.0f} (IQR {ban_q1:.0f}-{ban_q3:.0f}). Patients were distributed across risk categories as follows: low risk (score <=7) {risk['Low']['n']:,} ({risk['Low']['pct']*100:.1f}%), moderate risk (8-12) {risk['Moderate']['n']:,} ({risk['Moderate']['pct']*100:.1f}%), and high risk (>=13) {risk['High']['n']:,} ({risk['High']['pct']*100:.1f}%) (Table 1).\n",
    "\n",
    "In this ICU cohort, {fmt_pct(cs_pct)} presented with cardiogenic shock and {fmt_pct(vent_pct)} required invasive mechanical ventilation. The prevalence of chronic kidney disease was {fmt_pct(ckd_pct)}. Median NT-proBNP was {nt_median:,.0f} pg/mL (IQR {nt_q1:,.0f}-{nt_q3:,.0f}), when available.\n",
    "\n",
    "Primary Outcome: 24-Hour Diuretic Efficiency\n",
    "\n",
    "Among {n_24:,} patients with valid 24-hour diuretic efficiency data, the BAN-ADHF score demonstrated an inverse association with diuretic efficiency (Spearman rho = {rho_24:.3f}, 95% CI {fmt_ci(rho_24_ci, decimals=3)}, p < 0.001; Pearson r = {pearson_24:.3f}, 95% CI {fmt_ci(pearson_24_ci, decimals=3)}, p < 0.001) (Figure 2, eFigure 3). The C-index was {c_index:.3f} (95% CI {c_index_ci[0]:.3f}-{c_index_ci[1]:.3f}).\n",
    "\n",
    "For binary discrimination, the AUROC for identifying patients in the lowest efficiency quintile was {auroc_q20:.3f} (95% CI {auroc_q20_ci[0]:.3f}-{auroc_q20_ci[1]:.3f}), and for the lowest quartile was {auroc_q25:.3f} (95% CI {auroc_q25_ci[0]:.3f}-{auroc_q25_ci[1]:.3f}) (Table 2).\n",
    "\n",
    "Risk Stratification\n",
    "\n",
    "Median 24-hour diuretic efficiency demonstrated a clear gradient across risk categories (Table 2, Figure 2A). Patients in the low-risk category achieved a median efficiency of {eff_24h_by_risk['Low']['median']:.1f} mL/mg (IQR {eff_24h_by_risk['Low']['q1']:.1f}-{eff_24h_by_risk['Low']['q3']:.1f}), compared with {eff_24h_by_risk['Moderate']['median']:.1f} mL/mg (IQR {eff_24h_by_risk['Moderate']['q1']:.1f}-{eff_24h_by_risk['Moderate']['q3']:.1f}) for moderate risk and {eff_24h_by_risk['High']['median']:.1f} mL/mg (IQR {eff_24h_by_risk['High']['q1']:.1f}-{eff_24h_by_risk['High']['q3']:.1f}) for high risk (p < 0.001). This corresponds to a {fold_diff:.1f}-fold difference in median efficiency from low to high risk, or a {pct_reduction:.0f}% reduction relative to low risk.\n",
    "\n",
    "Secondary Outcomes\n",
    "\n",
    "72-Hour Diuretic Efficiency: Among {n_72:,} patients with an ICU stay of at least 72 hours, the inverse association remained (Spearman rho = {rho_72:.3f}, 95% CI {fmt_ci(rho_72_ci, decimals=3)}, p < 0.001), with AUROC for the lowest efficiency quintile of {auroc72_q20:.3f} (95% CI {auroc72_q20_ci[0]:.3f}-{auroc72_q20_ci[1]:.3f}).\n",
    "\n",
    "Diuretic Resistance: Diuretic resistance (24-hour urine output <=3000 mL) occurred in {dr_prev:.1f}% of patients. The BAN-ADHF score demonstrated modest discrimination (AUROC {dr_auroc:.3f}, 95% CI {dr_auroc_ci[0]:.3f}-{dr_auroc_ci[1]:.3f}).\n",
    "\n",
    "In-Hospital Mortality: Overall mortality was {mort_rate:.1f}% ({mort_deaths} of {mort_n:,}). The BAN-ADHF score showed modest discrimination for mortality (AUROC {mort_auroc:.3f}, 95% CI {mort_auroc_ci[0]:.3f}-{mort_auroc_ci[1]:.3f}), with higher AUROC in the cardiogenic shock subgroup (AUROC {mort_auroc_cs:.3f}). Mortality increased across risk categories (Table 2).\n",
    "\n",
    "Subgroup Analyses\n",
    "\n",
    "The inverse association between BAN-ADHF score and 24-hour diuretic efficiency was consistent across pre-specified subgroups (Figure 3). {interaction_block}\n",
    "\n",
    "Sensitivity Analyses\n",
    "\n",
    "Results were robust across sensitivity analyses (eTable 2). Exclusion of outliers (>99th percentile efficiency), exclusion of cardiogenic shock, and restriction to patients with complete left ventricular ejection fraction data yielded similar estimates. Exclusion of patients with advanced chronic kidney disease attenuated the association, which is expected given that creatinine is a score component and is independently associated with diuretic response.\n",
    "\n",
    "HF Phenotype Analysis\n",
    "\n",
    "{hf_block}\n",
    "\n",
    "Comparison with Literature\n",
    "\n",
    "Our findings align with prior validation studies (Table 3). In this ICU cohort, binary discrimination for diuretic resistance and mortality was modest, which is consistent with outcome prevalence and the information loss introduced by dichotomization.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(results_text)\n",
    "\n",
    "#==========================================================================\n",
    "# KEY STATISTICS SUMMARY\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY STATISTICS FOR QUICK REFERENCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "COHORT:\n",
    "  N total: {n_total:,}\n",
    "  N 24h analysis: {n_24:,}\n",
    "  N 72h analysis: {n_72:,}\n",
    "  Age: {age_mean_sd} years\n",
    "  Male: {male_pct_str}\n",
    "\n",
    "SCORE DISTRIBUTION:\n",
    "  Median [IQR]: {ban_median:.0f} [{ban_q1:.0f}-{ban_q3:.0f}]\n",
    "  Low risk (<=7): {risk['Low']['n']:,} ({risk['Low']['pct']*100:.1f}%)\n",
    "  Moderate (8-12): {risk['Moderate']['n']:,} ({risk['Moderate']['pct']*100:.1f}%)\n",
    "  High risk (>=13): {risk['High']['n']:,} ({risk['High']['pct']*100:.1f}%)\n",
    "\n",
    "PRIMARY OUTCOME (24h Efficiency):\n",
    "  Spearman rho: {rho_24:.3f} (95% CI {rho_24_ci[0]:.3f}, {rho_24_ci[1]:.3f})\n",
    "  Pearson r: {pearson_24:.3f} (95% CI {pearson_24_ci[0]:.3f}, {pearson_24_ci[1]:.3f})\n",
    "  C-index: {c_index:.3f} (95% CI {c_index_ci[0]:.3f}, {c_index_ci[1]:.3f})\n",
    "  AUROC Q20: {auroc_q20:.3f} (95% CI {auroc_q20_ci[0]:.3f}, {auroc_q20_ci[1]:.3f})\n",
    "  AUROC Q25: {auroc_q25:.3f} (95% CI {auroc_q25_ci[0]:.3f}, {auroc_q25_ci[1]:.3f})\n",
    "\n",
    "EFFICIENCY BY RISK (24h):\n",
    "  Low: {eff_24h_by_risk['Low']['median']:.1f} mL/mg [{eff_24h_by_risk['Low']['q1']:.1f}-{eff_24h_by_risk['Low']['q3']:.1f}]\n",
    "  Moderate: {eff_24h_by_risk['Moderate']['median']:.1f} mL/mg [{eff_24h_by_risk['Moderate']['q1']:.1f}-{eff_24h_by_risk['Moderate']['q3']:.1f}]\n",
    "  High: {eff_24h_by_risk['High']['median']:.1f} mL/mg [{eff_24h_by_risk['High']['q1']:.1f}-{eff_24h_by_risk['High']['q3']:.1f}]\n",
    "  Fold difference (Low vs High): {fold_diff:.1f}-fold\n",
    "\n",
    "SECONDARY OUTCOMES:\n",
    "  72h rho: {rho_72:.3f} (95% CI {rho_72_ci[0]:.3f}, {rho_72_ci[1]:.3f})\n",
    "  DR prevalence: {dr_prev:.1f}%, AUROC {dr_auroc:.3f}\n",
    "  Mortality: {mort_rate:.1f}%, AUROC {mort_auroc:.3f}\n",
    "\"\"\")\n",
    "\n",
    "#==========================================================================\n",
    "# SAVE TEXT FILES\n",
    "#==========================================================================\n",
    "\n",
    "with open('/content/manuscript_abstract.txt', 'w') as f:\n",
    "    f.write(abstract + \"\\n\")\n",
    "\n",
    "with open('/content/manuscript_results.txt', 'w') as f:\n",
    "    f.write(results_text + \"\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MANUSCRIPT TEXT COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "Files generated:\n",
    "  - manuscript_abstract.txt\n",
    "  - manuscript_results.txt\n",
    "\n",
    "Notes:\n",
    "  - Gender percent is computed robustly (male_sex if available, otherwise gender).\n",
    "  - Claims that require comprehensive literature review were removed to keep the text defensible.\n",
    "\"\"\")\n",
    "print(\"\\n-> Next: Package all outputs (Cell 21)\")\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# SECTION 17: PACKAGE ALL OUTPUTS\n",
    "# Cell 21: Organize files, create checklists, README, and ZIP (ROBUST)\n",
    "#\n",
    "# Fixes in this version:\n",
    "#  - Robust file copy: tries multiple possible filenames (handles your Figure/R export name drift)\n",
    "#  - No KeyError in README: uses safe getters for dicts + safe CI formatting\n",
    "#  - Risk table in README uses eff_24h_by_risk if present, otherwise computes on the fly\n",
    "#  - Fold difference guards against divide-by-zero\n",
    "#  - \"Comparison with Literature\" deltas won't crash if values missing. Also avoids hardcoded % deltas\n",
    "#  - Uses a stable Analysis Date (yyyy-mm-dd)\n",
    "#==========================================================================\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PACKAGING ALL OUTPUTS (ROBUST)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "#==========================================================================\n",
    "# HELPERS\n",
    "#==========================================================================\n",
    "\n",
    "def safe_get(d, key, default=np.nan):\n",
    "    return d.get(key, default) if isinstance(d, dict) else default\n",
    "\n",
    "def safe_ci(d, key, default=(np.nan, np.nan)):\n",
    "    ci = safe_get(d, key, default)\n",
    "    if ci is None:\n",
    "        return default\n",
    "    if isinstance(ci, (list, tuple)) and len(ci) == 2:\n",
    "        return (ci[0], ci[1])\n",
    "    return default\n",
    "\n",
    "def fmt_num(x, nd=3):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return \"NA\"\n",
    "    return f\"{x:.{nd}f}\"\n",
    "\n",
    "def fmt_ci(ci, nd=3):\n",
    "    lo, hi = ci\n",
    "    if lo is None or hi is None:\n",
    "        return \"NA\"\n",
    "    if (isinstance(lo, float) and np.isnan(lo)) or (isinstance(hi, float) and np.isnan(hi)):\n",
    "        return \"NA\"\n",
    "    return f\"({lo:.{nd}f}, {hi:.{nd}f})\"\n",
    "\n",
    "def try_copy(possible_names, dest_dir, label_prefix=\"\"):\n",
    "    \"\"\"\n",
    "    possible_names: list of filenames (without /content/)\n",
    "    Copies the first existing one found.\n",
    "    Returns (copied_bool, chosen_filename_or_None)\n",
    "    \"\"\"\n",
    "    for name in possible_names:\n",
    "        src = f\"/content/{name}\"\n",
    "        if os.path.exists(src):\n",
    "            shutil.copy(src, os.path.join(dest_dir, name))\n",
    "            if label_prefix:\n",
    "                print(f\"  \u2713 {label_prefix}/{name}\")\n",
    "            else:\n",
    "                print(f\"  \u2713 {name}\")\n",
    "            return True, name\n",
    "    # nothing found\n",
    "    missing_display = possible_names[0] if possible_names else \"UNKNOWN\"\n",
    "    print(f\"  \u26a0 Missing: {missing_display}\")\n",
    "    return False, None\n",
    "\n",
    "def ensure_dir(path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "#==========================================================================\n",
    "# CREATE FOLDER STRUCTURE\n",
    "#==========================================================================\n",
    "\n",
    "base_dir = '/content/BAN_ADHF_Validation'\n",
    "\n",
    "# Remove existing folder if present\n",
    "if os.path.exists(base_dir):\n",
    "    shutil.rmtree(base_dir)\n",
    "\n",
    "folders = [\n",
    "    f'{base_dir}/Tables/Main',\n",
    "    f'{base_dir}/Tables/Supplementary',\n",
    "    f'{base_dir}/Figures/Main',\n",
    "    f'{base_dir}/Figures/Supplementary',\n",
    "    f'{base_dir}/Figures/R_Data',\n",
    "    f'{base_dir}/Manuscript',\n",
    "    f'{base_dir}/Checklists',\n",
    "    f'{base_dir}/Data'\n",
    "]\n",
    "\n",
    "for folder in folders:\n",
    "    ensure_dir(folder)\n",
    "\n",
    "print(\"\u2713 Folder structure created\")\n",
    "\n",
    "#==========================================================================\n",
    "# COPY FILES TO APPROPRIATE FOLDERS\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Copying files to organized folders...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# --- Main Tables (stable names)\n",
    "main_tables = [\n",
    "    'Table1_baseline_by_risk.csv',\n",
    "    'Table1_baseline_by_risk.xlsx',\n",
    "    'Table2_outcomes_discrimination.csv',\n",
    "    'Table2_outcomes_discrimination.xlsx',\n",
    "    'Table3_literature_comparison.csv',\n",
    "    'Table3_literature_comparison.xlsx'\n",
    "]\n",
    "for f in main_tables:\n",
    "    try_copy([f], f'{base_dir}/Tables/Main', label_prefix=\"Tables/Main\")\n",
    "\n",
    "# --- Supplementary Tables\n",
    "supp_tables = [\n",
    "    'eTable1_baseline_by_mortality.csv',\n",
    "    'eTable1_baseline_by_mortality.xlsx',\n",
    "    'eTable2_sensitivity_analyses.csv',\n",
    "    'eTable2_sensitivity_analyses.xlsx',\n",
    "    'eTable3_secondary_outcomes.csv',\n",
    "    'eTable3_secondary_outcomes.xlsx',\n",
    "    'eTable4_hf_phenotype.csv',\n",
    "    'eTable4_hf_phenotype.xlsx'\n",
    "]\n",
    "for f in supp_tables:\n",
    "    try_copy([f], f'{base_dir}/Tables/Supplementary', label_prefix=\"Tables/Supplementary\")\n",
    "\n",
    "# --- Main Figures (handle .tif vs .tiff drift)\n",
    "main_figures_map = [\n",
    "    (['Figure2_efficiency_by_risk.png'], 'Figures/Main'),\n",
    "    (['Figure2_efficiency_by_risk.tiff', 'Figure2_efficiency_by_risk.tif'], 'Figures/Main'),\n",
    "    (['Figure3_forest_plot.png'], 'Figures/Main'),\n",
    "    (['Figure3_forest_plot.tiff', 'Figure3_forest_plot.tif'], 'Figures/Main'),\n",
    "]\n",
    "for names, subdir in main_figures_map:\n",
    "    try_copy(names, f'{base_dir}/{subdir}', label_prefix=subdir)\n",
    "\n",
    "# --- Supplementary Figures\n",
    "supp_figures_map = [\n",
    "    (['eFigure1_ROC_curves.png'], 'Figures/Supplementary'),\n",
    "    (['eFigure1_ROC_curves.tiff', 'eFigure1_ROC_curves.tif'], 'Figures/Supplementary'),\n",
    "    (['eFigure2_score_distribution.png'], 'Figures/Supplementary'),\n",
    "    (['eFigure2_score_distribution.tiff', 'eFigure2_score_distribution.tif'], 'Figures/Supplementary'),\n",
    "    (['eFigure3_scatter_correlation.png'], 'Figures/Supplementary'),\n",
    "    (['eFigure3_scatter_correlation.tiff', 'eFigure3_scatter_correlation.tif'], 'Figures/Supplementary'),\n",
    "]\n",
    "for names, subdir in supp_figures_map:\n",
    "    try_copy(names, f'{base_dir}/{subdir}', label_prefix=subdir)\n",
    "\n",
    "# --- R Data files (your earlier section exported these names, but older notebooks sometimes used others)\n",
    "r_data_candidates = {\n",
    "    # current names from your Section 14/15\n",
    "    'data_for_R_figure2_efficiency.csv': ['data_for_R_figure2_efficiency.csv'],\n",
    "    'data_for_R_figure2_summary.csv': ['data_for_R_figure2_summary.csv'],\n",
    "    'data_for_R_figure3_forest.csv': ['data_for_R_figure3_forest.csv'],\n",
    "    'data_for_R_interactions.csv': ['data_for_R_interactions.csv'],\n",
    "    'data_for_R_subgroups_detail.csv': ['data_for_R_subgroups_detail.csv'],\n",
    "    'data_for_R_literature_comparison.csv': ['data_for_R_literature_comparison.csv'],\n",
    "    'data_for_R_roc_q20.csv': ['data_for_R_roc_q20.csv'],\n",
    "    'data_for_R_score_distribution.csv': ['data_for_R_score_distribution.csv'],\n",
    "    'data_for_R_scatter.csv': ['data_for_R_scatter.csv'],\n",
    "\n",
    "    # legacy / alternate names (if they exist, we still bring them in)\n",
    "    'data_for_R_forest_plot.csv': ['data_for_R_forest_plot.csv', 'data_for_R_figure3_forest.csv'],\n",
    "    'data_for_R_outcomes_by_risk.csv': ['data_for_R_outcomes_by_risk.csv'],\n",
    "    'data_for_R_efficiency_raw.csv': ['data_for_R_efficiency_raw.csv', 'data_for_R_figure2_efficiency.csv'],\n",
    "}\n",
    "\n",
    "copied_r = set()\n",
    "for canonical, candidates in r_data_candidates.items():\n",
    "    copied, chosen = try_copy(candidates, f'{base_dir}/Figures/R_Data', label_prefix=\"Figures/R_Data\")\n",
    "    if copied and chosen:\n",
    "        copied_r.add(chosen)\n",
    "\n",
    "# --- Manuscript text files\n",
    "manuscript_files = ['manuscript_abstract.txt', 'manuscript_results.txt']\n",
    "for f in manuscript_files:\n",
    "    try_copy([f], f'{base_dir}/Manuscript', label_prefix=\"Manuscript\")\n",
    "\n",
    "#==========================================================================\n",
    "# CREATE TRIPOD CHECKLIST (Prediction Model Validation)\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Creating TRIPOD Checklist...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "tripod_items = [\n",
    "    ('1', 'Title', 'Identify the study as developing and/or validating a multivariable prediction model', 'Yes', 'Title includes external validation language'),\n",
    "    ('2', 'Abstract', 'Provide a summary of objectives, design, setting, participants, sample size, predictors, outcome, analysis, results, and conclusions', 'Yes', 'Structured abstract provided'),\n",
    "    ('3a', 'Background', 'Explain medical context and rationale', 'Yes', 'Introduction'),\n",
    "    ('3b', 'Objectives', 'Specify objectives, including development vs validation', 'Yes', 'External validation in ICU'),\n",
    "    ('4a', 'Source of data', 'Describe study design or data source', 'Yes', 'MIMIC-IV retrospective cohort'),\n",
    "    ('4b', 'Source of data', 'Specify key study dates', 'Yes', '2008-2019'),\n",
    "    ('5a', 'Participants', 'Specify key elements of the setting', 'Yes', 'ICU ADHF cohort'),\n",
    "    ('5b', 'Participants', 'Describe eligibility criteria', 'Yes', 'Methods'),\n",
    "    ('5c', 'Participants', 'Give details of treatments received, if relevant', 'Yes', 'IV diuretics'),\n",
    "    ('6a', 'Outcome', 'Clearly define the outcome', 'Yes', '24h diuretic efficiency (mL/mg)'),\n",
    "    ('6b', 'Outcome', 'Report blinding of outcome assessment', 'N/A', 'Retrospective database'),\n",
    "    ('7a', 'Predictors', 'Clearly define predictors', 'Yes', 'BAN-ADHF components'),\n",
    "    ('7b', 'Predictors', 'Report blinding of predictors assessment', 'N/A', 'Retrospective database'),\n",
    "    ('8', 'Sample size', 'Explain how study size was arrived at', 'Yes', 'All eligible patients'),\n",
    "    ('9', 'Missing data', 'Describe how missing data were handled', 'Yes', 'Complete-case + sensitivity analyses'),\n",
    "    ('10a', 'Statistical analysis', 'Describe how predictors were handled', 'Yes', 'Score per original algorithm'),\n",
    "    ('10b', 'Statistical analysis', 'Specify model-building procedures', 'Yes', 'External validation only'),\n",
    "    ('10c', 'Statistical analysis', 'For validation, describe how predictions were calculated', 'Yes', 'Score applied without updating'),\n",
    "    ('10d', 'Statistical analysis', 'Specify performance measures', 'Yes', 'rho, r, C-index, AUROC'),\n",
    "    ('10e', 'Statistical analysis', 'Describe any model updating', 'N/A', 'No updating'),\n",
    "    ('11', 'Risk groups', 'Provide details on risk groups', 'Yes', 'Low/Moderate/High thresholds'),\n",
    "    ('13a', 'Participants', 'Describe participant flow', 'Yes', 'Figure 1'),\n",
    "    ('13b', 'Participants', 'Describe participant characteristics', 'Yes', 'Table 1'),\n",
    "    ('13c', 'Participants', 'Compare with development data', 'Yes', 'Table 3'),\n",
    "    ('14a', 'Model development', 'Specify number of participants and events', 'Yes', 'Reported per outcome'),\n",
    "    ('14b', 'Model specification', 'Report unadjusted association', 'Yes', 'Correlations'),\n",
    "    ('15a', 'Model performance', 'Report performance measures with CIs', 'Yes', 'CIs provided'),\n",
    "    ('15b', 'Model performance', 'Report results with model updating', 'N/A', 'No updating'),\n",
    "    ('16', 'Model updating', 'Report results from updating', 'N/A', 'No updating'),\n",
    "    ('17', 'Limitations', 'Discuss limitations', 'Yes', 'Discussion'),\n",
    "    ('18', 'Interpretation', 'Discuss with reference to other studies', 'Yes', 'Comparison table'),\n",
    "    ('19a', 'Implications', 'Discuss clinical use', 'Yes', 'Discussion'),\n",
    "    ('19b', 'Implications', 'Discuss model improvement', 'Yes', 'Future directions'),\n",
    "    ('20', 'Supplementary information', 'Availability of supplementary resources', 'Yes', 'eTables/eFigures'),\n",
    "    ('21', 'Funding', 'Source of funding', 'TBD', 'To be added')\n",
    "]\n",
    "\n",
    "tripod_df = pd.DataFrame(tripod_items, columns=['Item', 'Section', 'Checklist Item', 'Reported', 'Location/Comment'])\n",
    "tripod_df.to_csv(f'{base_dir}/Checklists/TRIPOD_checklist.csv', index=False)\n",
    "tripod_df.to_excel(f'{base_dir}/Checklists/TRIPOD_checklist.xlsx', index=False)\n",
    "print(\"\u2713 TRIPOD checklist created (CSV and XLSX)\")\n",
    "\n",
    "#==========================================================================\n",
    "# CREATE STROBE CHECKLIST (Observational Study)\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Creating STROBE Checklist...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "strobe_items = [\n",
    "    ('1a', 'Title and abstract', 'Indicate the study design with a commonly used term', 'Yes', 'Retrospective cohort study'),\n",
    "    ('1b', 'Title and abstract', 'Provide an informative and balanced summary', 'Yes', 'Structured abstract'),\n",
    "    ('2', 'Background/rationale', 'Explain scientific background and rationale', 'Yes', 'Introduction'),\n",
    "    ('3', 'Objectives', 'State specific objectives', 'Yes', 'Primary objective'),\n",
    "    ('4', 'Study design', 'Present key elements early in the paper', 'Yes', 'Methods'),\n",
    "    ('5', 'Setting', 'Describe setting, locations, relevant dates', 'Yes', 'MIMIC-IV, 2008-2019'),\n",
    "    ('6a', 'Participants', 'Eligibility criteria and selection methods', 'Yes', 'Methods'),\n",
    "    ('7', 'Variables', 'Define outcomes, exposures, predictors, confounders', 'Yes', 'Methods'),\n",
    "    ('8', 'Data sources', 'Sources and assessment methods', 'Yes', 'Methods'),\n",
    "    ('9', 'Bias', 'Efforts to address bias', 'Yes', 'Sensitivity analyses'),\n",
    "    ('10', 'Study size', 'How study size arrived at', 'Yes', 'All eligible'),\n",
    "    ('11', 'Quantitative variables', 'How quantitative variables handled', 'Yes', 'Methods'),\n",
    "    ('12a', 'Statistical methods', 'All statistical methods', 'Yes', 'Methods'),\n",
    "    ('12b', 'Statistical methods', 'Methods for subgroups/interactions', 'Yes', 'Subgroup analyses'),\n",
    "    ('12c', 'Statistical methods', 'Missing data handling', 'Yes', 'Complete-case + sensitivity'),\n",
    "    ('12d', 'Statistical methods', 'Loss to follow-up', 'N/A', 'In-hospital outcomes'),\n",
    "    ('12e', 'Statistical methods', 'Sensitivity analyses', 'Yes', 'eTable 2'),\n",
    "    ('13a', 'Participants', 'Numbers at each stage', 'Yes', 'Figure 1'),\n",
    "    ('13b', 'Participants', 'Reasons for non-participation', 'Yes', 'Figure 1'),\n",
    "    ('13c', 'Participants', 'Flow diagram', 'Yes', 'Figure 1'),\n",
    "    ('14a', 'Descriptive data', 'Characteristics of participants', 'Yes', 'Table 1'),\n",
    "    ('14b', 'Descriptive data', 'Missing data counts', 'Yes', 'Tables/eTables'),\n",
    "    ('15', 'Outcome data', 'Outcome events or summary measures', 'Yes', 'Table 2'),\n",
    "    ('16a', 'Main results', 'Unadjusted estimates and precision', 'Yes', 'Correlations + CIs'),\n",
    "    ('16b', 'Main results', 'Category boundaries', 'Yes', 'Risk categories'),\n",
    "    ('16c', 'Main results', 'Meaningful time periods', 'N/A', 'Prediction at 24h/72h'),\n",
    "    ('17', 'Other analyses', 'Subgroups/interactions/sensitivity', 'Yes', 'Results'),\n",
    "    ('18', 'Key results', 'Summarize key results', 'Yes', 'Discussion'),\n",
    "    ('19', 'Limitations', 'Limitations and bias', 'Yes', 'Discussion'),\n",
    "    ('20', 'Interpretation', 'Cautious interpretation', 'Yes', 'Discussion'),\n",
    "    ('21', 'Generalisability', 'Generalisability', 'Yes', 'Discussion'),\n",
    "    ('22', 'Funding', 'Funding source and role', 'TBD', 'To be added')\n",
    "]\n",
    "\n",
    "strobe_df = pd.DataFrame(strobe_items, columns=['Item', 'Section', 'Checklist Item', 'Reported', 'Location/Comment'])\n",
    "strobe_df.to_csv(f'{base_dir}/Checklists/STROBE_checklist.csv', index=False)\n",
    "strobe_df.to_excel(f'{base_dir}/Checklists/STROBE_checklist.xlsx', index=False)\n",
    "print(\"\u2713 STROBE checklist created (CSV and XLSX)\")\n",
    "\n",
    "#==========================================================================\n",
    "# CREATE README FILE (NO KEYERRORS)\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Creating README file...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "analysis_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Pull key metrics safely for README\n",
    "n24 = int(safe_get(results_24h, 'n', 0)) if safe_get(results_24h, 'n', None) is not None else 0\n",
    "rho24 = safe_get(results_24h, 'spearman_rho', np.nan)\n",
    "rho24_ci = safe_ci(results_24h, 'spearman_ci')\n",
    "r24 = safe_get(results_24h, 'pearson_r', np.nan)\n",
    "r24_ci = safe_ci(results_24h, 'pearson_ci')\n",
    "cidx = safe_get(results_24h, 'c_index', np.nan)\n",
    "cidx_ci = safe_ci(results_24h, 'c_index_ci')\n",
    "auc20 = safe_get(results_24h, 'auroc_quintile', np.nan)\n",
    "auc20_ci = safe_ci(results_24h, 'auroc_quintile_ci')\n",
    "auc25 = safe_get(results_24h, 'auroc_quartile', np.nan)\n",
    "auc25_ci = safe_ci(results_24h, 'auroc_quartile_ci')\n",
    "\n",
    "# Risk stats (use eff_24h_by_risk if available)\n",
    "def risk_row(cat, score_label):\n",
    "    if isinstance(eff_24h_by_risk, dict) and cat in eff_24h_by_risk:\n",
    "        d = eff_24h_by_risk[cat]\n",
    "        return (cat, score_label, int(d.get('n', 0)), f\"{d.get('median', np.nan):.1f} [{d.get('q1', np.nan):.1f}-{d.get('q3', np.nan):.1f}]\")\n",
    "    # fallback: compute\n",
    "    if 'risk_category' in df.columns and 'diuretic_efficiency_24h' in df.columns:\n",
    "        sub = df[(df['risk_category']==cat) & df['diuretic_efficiency_24h'].notna() & (df['diuretic_efficiency_24h']>0)]['diuretic_efficiency_24h']\n",
    "        if len(sub)==0:\n",
    "            return (cat, score_label, 0, \"NA\")\n",
    "        return (cat, score_label, len(sub), f\"{sub.median():.1f} [{sub.quantile(0.25):.1f}-{sub.quantile(0.75):.1f}]\")\n",
    "    return (cat, score_label, 0, \"NA\")\n",
    "\n",
    "low_row = risk_row('Low', '\u22647')\n",
    "mod_row = risk_row('Moderate', '8-12')\n",
    "high_row = risk_row('High', '\u226513')\n",
    "\n",
    "# Fold diff\n",
    "try:\n",
    "    fold = (eff_24h_by_risk['Low']['median'] / eff_24h_by_risk['High']['median'])\n",
    "    fold_str = f\"{fold:.1f}-fold\" if np.isfinite(fold) else \"NA\"\n",
    "except Exception:\n",
    "    fold_str = \"NA\"\n",
    "\n",
    "# Secondary outcomes (safe)\n",
    "n72 = safe_get(results_72h, 'n', np.nan)\n",
    "rho72 = safe_get(results_72h, 'spearman_rho', np.nan)\n",
    "auc72 = safe_get(results_72h, 'auroc_quintile', np.nan)\n",
    "auc72_ci = safe_ci(results_72h, 'auroc_quintile_ci')\n",
    "\n",
    "dr_n = safe_get(results_dr, 'n', np.nan)\n",
    "dr_prev = safe_get(results_dr, 'prevalence', np.nan)\n",
    "dr_auc = safe_get(results_dr, 'auroc', np.nan)\n",
    "dr_auc_ci = safe_ci(results_dr, 'auroc_ci')\n",
    "\n",
    "mort_n = safe_get(results_mortality, 'n', np.nan)\n",
    "mort_rate = safe_get(results_mortality, 'mortality_rate', np.nan)\n",
    "mort_auc = safe_get(results_mortality, 'auroc', np.nan)\n",
    "mort_auc_ci = safe_ci(results_mortality, 'auroc_ci')\n",
    "\n",
    "# Significant interactions from interaction_data if present, else from results_subgroups dict\n",
    "sig_interactions_md = \"\"\n",
    "if 'interaction_data' in globals() and isinstance(interaction_data, list) and len(interaction_data) > 0:\n",
    "    sig = [x for x in interaction_data if x.get('significant', False)]\n",
    "    if len(sig) > 0:\n",
    "        rows = []\n",
    "        for x in sig:\n",
    "            rows.append(f\"| {x.get('subgroup','NA')} | {x.get('p_interaction', np.nan):.4f} | \u03c1 = {x.get('rho_group1', np.nan):.3f} vs {x.get('rho_group2', np.nan):.3f} |\")\n",
    "        sig_interactions_md = \"\\n\".join(rows)\n",
    "else:\n",
    "    inter = safe_get(results_subgroups, 'interaction_results', {}) or {}\n",
    "    sig = [(k,v) for k,v in inter.items() if pd.notna(safe_get(v,'p_interaction', np.nan)) and safe_get(v,'p_interaction', np.nan) < 0.05]\n",
    "    if len(sig) > 0:\n",
    "        rows = []\n",
    "        for k,v in sig:\n",
    "            rows.append(f\"| {k} | {safe_get(v,'p_interaction', np.nan):.4f} | \u03c1 = {safe_get(v,'rho_1', np.nan):.3f} vs {safe_get(v,'rho_2', np.nan):.3f} |\")\n",
    "        sig_interactions_md = \"\\n\".join(rows)\n",
    "\n",
    "if sig_interactions_md == \"\":\n",
    "    sig_interactions_md = \"| None detected | NA | NA |\"\n",
    "\n",
    "readme_content = f\"\"\"# BAN-ADHF Score External Validation in ICU Patients\n",
    "\n",
    "## Study Information\n",
    "- **Title**: External Validation of the BAN-ADHF Score for Predicting Diuretic Efficiency in Critically Ill Patients with Acute Decompensated Heart Failure\n",
    "- **Database**: MIMIC-IV (2008-2019)\n",
    "- **Analysis Date**: {analysis_date}\n",
    "\n",
    "---\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "### Primary Outcome (24-Hour Diuretic Efficiency)\n",
    "| Metric | Value | 95% CI |\n",
    "|--------|-------|--------|\n",
    "| N | {n24:,} | - |\n",
    "| Spearman \u03c1 | {fmt_num(rho24, 3)} | {fmt_ci(rho24_ci, 3)} |\n",
    "| Pearson r | {fmt_num(r24, 3)} | {fmt_ci(r24_ci, 3)} |\n",
    "| C-index | {fmt_num(cidx, 3)} | {fmt_ci(cidx_ci, 3)} |\n",
    "| AUROC (Q20) | {fmt_num(auc20, 3)} | {fmt_ci(auc20_ci, 3)} |\n",
    "| AUROC (Q25) | {fmt_num(auc25, 3)} | {fmt_ci(auc25_ci, 3)} |\n",
    "\n",
    "### Risk Stratification (24h Efficiency)\n",
    "| Risk Category | Score | N | Median [IQR] mL/mg |\n",
    "|---------------|-------|---|-------------------|\n",
    "| {low_row[0]} | {low_row[1]} | {low_row[2]} | {low_row[3]} |\n",
    "| {mod_row[0]} | {mod_row[1]} | {mod_row[2]} | {mod_row[3]} |\n",
    "| {high_row[0]} | {high_row[1]} | {high_row[2]} | {high_row[3]} |\n",
    "\n",
    "**Fold difference (Low vs High): {fold_str}**\n",
    "\n",
    "### Secondary Outcomes\n",
    "| Outcome | N | Value | AUROC (95% CI) |\n",
    "|---------|---|-------|----------------|\n",
    "| 72h Efficiency | {n72} | \u03c1 = {fmt_num(rho72, 3)} | {fmt_num(auc72, 3)} {fmt_ci(auc72_ci, 3)} |\n",
    "| Diuretic Resistance | {dr_n} | {fmt_num(dr_prev, 1)}% | {fmt_num(dr_auc, 3)} {fmt_ci(dr_auc_ci, 3)} |\n",
    "| Mortality | {mort_n} | {fmt_num(mort_rate, 1)}% | {fmt_num(mort_auc, 3)} {fmt_ci(mort_auc_ci, 3)} |\n",
    "\n",
    "---\n",
    "\n",
    "## Folder Structure\n",
    "```\n",
    "\n",
    "BAN_ADHF_Validation/\n",
    "\u251c\u2500\u2500 README.md\n",
    "\u251c\u2500\u2500 Tables/\n",
    "\u2502   \u251c\u2500\u2500 Main/\n",
    "\u2502   \u2514\u2500\u2500 Supplementary/\n",
    "\u251c\u2500\u2500 Figures/\n",
    "\u2502   \u251c\u2500\u2500 Main/\n",
    "\u2502   \u251c\u2500\u2500 Supplementary/\n",
    "\u2502   \u2514\u2500\u2500 R_Data/\n",
    "\u251c\u2500\u2500 Manuscript/\n",
    "\u251c\u2500\u2500 Checklists/\n",
    "\u2514\u2500\u2500 Data/\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Figures\n",
    "\n",
    "### Main Figures\n",
    "- Figure 1: Study flow diagram (to be created in PowerPoint/Illustrator)\n",
    "- Figure 2: Diuretic efficiency by risk category (A: 24h, B: 72h)\n",
    "- Figure 3: Subgroup forest plot\n",
    "\n",
    "### Supplementary Figures\n",
    "- eFigure 1: ROC curves for binary outcomes (Q20, diuretic resistance, mortality)\n",
    "- eFigure 2: BAN-ADHF score distribution (by risk category and mortality)\n",
    "- eFigure 3: Correlation scatter plot (score vs 24h efficiency)\n",
    "\n",
    "---\n",
    "\n",
    "## Significant Interactions (p < 0.05)\n",
    "| Subgroup | p-interaction | Summary |\n",
    "|----------|---------------|---------|\n",
    "{sig_interactions_md}\n",
    "\n",
    "---\n",
    "\n",
    "## Statistical Software\n",
    "- Python 3.x with pandas, numpy, scipy, scikit-learn\n",
    "- R (optional for publication-quality figures)\n",
    "- BigQuery for MIMIC-IV extraction\n",
    "\n",
    "---\n",
    "\n",
    "## Contact\n",
    "[Add author contact information]\n",
    "\n",
    "## License\n",
    "[Add license information]\n",
    "\n",
    "## Citation\n",
    "[Add citation once published]\n",
    "\"\"\"\n",
    "\n",
    "with open(f'{base_dir}/README.md', 'w') as f:\n",
    "    f.write(readme_content)\n",
    "print(\"\u2713 README.md created\")\n",
    "\n",
    "#==========================================================================\n",
    "# SAVE ANALYSIS COHORT\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Saving analysis cohort...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "key_vars = [\n",
    "    'hadm_id', 'age', 'gender', 'ban_adhf_total_score', 'risk_category',\n",
    "    'creatinine', 'bun', 'ntprobnp', 'dbp', 'total_furosemide_equivalent_mg',\n",
    "    'hx_atrial_fibrillation', 'hx_hypertension', 'prior_hf_hospitalization_12mo',\n",
    "    'lvef', 'hf_phenotype', 'hx_diabetes', 'hx_renal_disease',\n",
    "    'hx_myocardial_infarction', 'hx_stroke', 'hx_copd', 'cci_score',\n",
    "    'cardiogenic_shock', 'invasive_vent',\n",
    "    'diuretic_efficiency_24h', 'diuretic_efficiency_72h',\n",
    "    'urine_output_24h_ml', 'diuretic_resistance',\n",
    "    'hospital_expire_flag', 'icu_stay_ge_24h', 'icu_stay_ge_72h'\n",
    "]\n",
    "\n",
    "available_vars = [v for v in key_vars if v in df.columns]\n",
    "df_export = df[available_vars].copy()\n",
    "df_export.to_csv(f'{base_dir}/Data/analysis_cohort.csv', index=False)\n",
    "print(f\"\u2713 Analysis cohort saved ({len(df_export):,} patients, {len(available_vars)} variables)\")\n",
    "\n",
    "#==========================================================================\n",
    "# SAVE STORED RESULTS AS PICKLE (for reproducibility)\n",
    "#==========================================================================\n",
    "\n",
    "results_to_save = {\n",
    "    'results_24h': results_24h,\n",
    "    'results_72h': results_72h,\n",
    "    'results_dr': results_dr,\n",
    "    'results_mortality': results_mortality,\n",
    "    'results_sensitivity': results_sensitivity,\n",
    "    'results_secondary': results_secondary,\n",
    "    'results_subgroups': results_subgroups,\n",
    "    'eff_24h_by_risk': eff_24h_by_risk,\n",
    "    'eff_72h_by_risk': eff_72h_by_risk\n",
    "}\n",
    "\n",
    "with open(f'{base_dir}/Data/analysis_results.pkl', 'wb') as f:\n",
    "    pickle.dump(results_to_save, f)\n",
    "print(\"\u2713 Analysis results saved (pickle)\")\n",
    "\n",
    "#==========================================================================\n",
    "# CREATE ZIP FILE\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Creating ZIP archive...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "zip_out = '/content/BAN_ADHF_Validation.zip'\n",
    "if os.path.exists(zip_out):\n",
    "    os.remove(zip_out)\n",
    "\n",
    "shutil.make_archive('/content/BAN_ADHF_Validation', 'zip', '/content', 'BAN_ADHF_Validation')\n",
    "print(f\"\u2713 ZIP archive created: {zip_out}\")\n",
    "\n",
    "zip_size = os.path.getsize(zip_out) / (1024 * 1024)\n",
    "print(f\"  Size: {zip_size:.2f} MB\")\n",
    "\n",
    "#==========================================================================\n",
    "# FINAL INVENTORY\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FILE INVENTORY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def count_files(directory, extension=None):\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for f in files:\n",
    "            if extension is None or f.endswith(extension):\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "def list_files(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        level = root.replace(directory, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f'{indent}{os.path.basename(root)}/')\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for f in sorted(files):\n",
    "            print(f'{subindent}{f}')\n",
    "\n",
    "list_files(base_dir)\n",
    "\n",
    "#==========================================================================\n",
    "# SUMMARY\n",
    "#==========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PACKAGING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "n_csv = count_files(base_dir, '.csv')\n",
    "n_xlsx = count_files(base_dir, '.xlsx')\n",
    "n_png = count_files(base_dir, '.png')\n",
    "n_tiff = count_files(base_dir, '.tiff') + count_files(base_dir, '.tif')\n",
    "n_txt = count_files(base_dir, '.txt')\n",
    "n_md = count_files(base_dir, '.md')\n",
    "n_pkl = count_files(base_dir, '.pkl')\n",
    "\n",
    "print(f\"\"\"\n",
    "CONTENTS SUMMARY:\n",
    "  CSV files:   {n_csv}\n",
    "  XLSX files:  {n_xlsx}\n",
    "  PNG files:   {n_png}\n",
    "  TIFF/TIF:    {n_tiff}\n",
    "  TXT files:   {n_txt}\n",
    "  MD files:    {n_md}\n",
    "  PKL files:   {n_pkl}\n",
    "  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "  TOTAL:       {n_csv + n_xlsx + n_png + n_tiff + n_txt + n_md + n_pkl} files\n",
    "\n",
    "DOWNLOAD:\n",
    "  File: {zip_out}\n",
    "  Size: {zip_size:.2f} MB\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\u2713 ALL OUTPUTS PACKAGED SUCCESSFULLY\")\n",
    "print(\"=\"*70)"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#==========================================================================\n",
    "# DOWNLOAD ZIP FILE\n",
    "#==========================================================================\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "# Download the ZIP file\n",
    "files.download('/content/BAN_ADHF_Validation.zip')\n",
    "\n",
    "print(\"\u2713 Download initiated - check your browser's download folder\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}